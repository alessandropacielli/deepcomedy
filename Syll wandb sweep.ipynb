{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beb04733-34db-4e99-8e8a-50cad74df048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9f7410fa-bec9-4333-88f0-ff0488ffb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import wandb\n",
    "from deepcomedy.models.transformer import *\n",
    "from deepcomedy.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "76593e7f-824e-4956-950f-1f06b7a61d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO for now only char-level syllabification\n",
    "raw_text = open(\"./data/divina_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
    "raw_syll_text = (\n",
    "    open(\"./data/divina_syll_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
    ")\n",
    "syll_text = preprocess_tercets(raw_syll_text)\n",
    "text = preprocess_tercets(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf882cb6-f737-41cd-ab96-03790dc7b84d",
   "metadata": {},
   "source": [
    "Split preprocessed text into tercets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2498e9c0-1884-4f07-a1a6-13d532685f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"<EOT>\"\n",
    "input_tercets = [x + sep for x in text.split(sep)][:-1]\n",
    "target_tercets = [x + sep for x in syll_text.split(sep)][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4b019-0c83-4b08-9474-0e72195d9cdb",
   "metadata": {},
   "source": [
    "Encode with tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d001ff3c-393d-42c9-9b3b-276c351448b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=False, filters=\"\", lower=False\n",
    ")\n",
    "tokenizer.fit_on_texts(target_tercets)\n",
    "enc_input_tercets = tokenizer.texts_to_sequences(input_tercets)\n",
    "enc_target_tercets = tokenizer.texts_to_sequences(target_tercets)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b416c8-8d69-4095-8d52-447b2d612f6d",
   "metadata": {},
   "source": [
    "Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a8fc9903-a97e-46a7-a2bc-bdf4dcf4d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    enc_input_tercets, padding=\"post\"\n",
    ")\n",
    "target_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    enc_target_tercets, padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7cd401d-0fc7-4fa1-adcc-b1daeca6ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 7f44jv1h\n",
      "Sweep URL: https://wandb.ai/alessandropacielli/uncategorized/sweeps/7f44jv1h\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"sweep-test-1\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [32, 64]},\n",
    "        \"epochs\": {\"values\": [10, 20, 50, 100]},\n",
    "        \"num_layers\": {\"values\": [4, 6, 8, 12]},\n",
    "        \"num_heads\": {\"values\": [2, 4, 8]},\n",
    "        \"d_model\": {\"values\": [256, 512]},\n",
    "        \"dff\": {\"values\": [512, 1024, 2048]},\n",
    "        # TODO include architecture + dataset\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6df5adac-7f30-4e22-b9aa-6d57987de37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(input_tercets, target_tercets, batch_size):\n",
    "    buffer_size = len(input_tercets)\n",
    "    batch_size = 64\n",
    "\n",
    "    steps_per_epoch = len(input_tercets) // batch_size\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (input_tercets, target_tercets)\n",
    "    ).shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6691b191-4dbb-4b6a-8ba6-3504f45ba806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(config):\n",
    "    transformer = Transformer(\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        d_model=config[\"d_model\"],\n",
    "        num_heads=config[\"num_heads\"],\n",
    "        dff=config[\"dff\"],\n",
    "        input_vocab_size=vocab_size,\n",
    "        target_vocab_size=vocab_size,\n",
    "        pe_input=1000,\n",
    "        pe_target=1000,\n",
    "        rate=0.1,\n",
    "    )\n",
    "    transformer_trainer = TransformerTrainer(transformer, checkpoint_save_path=None)\n",
    "\n",
    "    return transformer, transformer_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8a1fb2e1-1583-46dc-b753-70ecfe5b375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5wrukb8l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 2048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">driven-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/alessandropacielli/uncategorized\" target=\"_blank\">https://wandb.ai/alessandropacielli/uncategorized</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/alessandropacielli/uncategorized/sweeps/7f44jv1h\" target=\"_blank\">https://wandb.ai/alessandropacielli/uncategorized/sweeps/7f44jv1h</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/alessandropacielli/uncategorized/runs/5wrukb8l\" target=\"_blank\">https://wandb.ai/alessandropacielli/uncategorized/runs/5wrukb8l</a><br/>\n",
       "                Run data is saved locally in <code>/home/alessandro/Desktop/DL/deepcomedy/wandb/run-20210524_001954-5wrukb8l</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24924<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/alessandro/Desktop/DL/deepcomedy/wandb/run-20210524_001954-5wrukb8l/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/alessandro/Desktop/DL/deepcomedy/wandb/run-20210524_001954-5wrukb8l/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">driven-sweep-1</strong>: <a href=\"https://wandb.ai/alessandropacielli/uncategorized/runs/5wrukb8l\" target=\"_blank\">https://wandb.ai/alessandropacielli/uncategorized/runs/5wrukb8l</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sweep():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        dataset = make_dataset(input_train, target_train, config[\"batch_size\"])\n",
    "        model, trainer = make_model(config)\n",
    "        loss = trainer.train(dataset, config[\"epochs\"])\n",
    "        wandb.log({\"loss\": loss, \"epoch\": epoch})\n",
    "\n",
    "\n",
    "count = 5\n",
    "wandb.agent(sweep_id, function=sweep, count=count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
