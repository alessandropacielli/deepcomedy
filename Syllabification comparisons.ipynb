{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxKXg2xrJrWY",
        "outputId": "a492816d-68df-4aec-c8a0-7e7400e492b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "jxKXg2xrJrWY",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8ntY7aYKdYt"
      },
      "source": [
        "!tar zxvf checkpoints.tar.gz"
      ],
      "id": "j8ntY7aYKdYt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeC3xPmEJfdF",
        "outputId": "5856ace8-650b-420d-af69-17e7d3e2fd21"
      },
      "source": [
        "!tar zxvf data.tar.gz\n",
        "!tar zxvf deepcomedy.tar.gz\n",
        "!tar zxvf nlgpoetry.tar.gz"
      ],
      "id": "UeC3xPmEJfdF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/\n",
            "data/orlando.txt\n",
            "data/divina_textonly.txt\n",
            "data/divina.txt\n",
            "data/divina_syll_textonly.txt\n",
            "data/orlando-textonly.txt\n",
            "data/divina_syll.txt\n",
            "data/.ipynb_checkpoints/\n",
            "data/.ipynb_checkpoints/orlando-checkpoint.txt\n",
            "data/.ipynb_checkpoints/orlando-textonly-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina_textonly-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina_syll-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina_syll_textonly-checkpoint.txt\n",
            "deepcomedy/\n",
            "deepcomedy/util/\n",
            "deepcomedy/util/predicate.py\n",
            "deepcomedy/util/__pycache__/\n",
            "deepcomedy/util/__pycache__/predicate.cpython-37.pyc\n",
            "deepcomedy/util/__pycache__/__init__.cpython-37.pyc\n",
            "deepcomedy/util/__init__.py\n",
            "deepcomedy/util/.ipynb_checkpoints/\n",
            "deepcomedy/util/.ipynb_checkpoints/predicate-checkpoint.py\n",
            "deepcomedy/models/\n",
            "deepcomedy/models/layers.py\n",
            "deepcomedy/models/transformer.py\n",
            "deepcomedy/models/__pycache__/\n",
            "deepcomedy/models/__pycache__/layers.cpython-37.pyc\n",
            "deepcomedy/models/__pycache__/__init__.cpython-37.pyc\n",
            "deepcomedy/models/__pycache__/transformer.cpython-37.pyc\n",
            "deepcomedy/models/__init__.py\n",
            "deepcomedy/models/.ipynb_checkpoints/\n",
            "deepcomedy/models/.ipynb_checkpoints/transformer-checkpoint.py\n",
            "deepcomedy/preprocessing.py\n",
            "deepcomedy/__pycache__/\n",
            "deepcomedy/__pycache__/__init__.cpython-37.pyc\n",
            "deepcomedy/__pycache__/preprocessing.cpython-37.pyc\n",
            "deepcomedy/__init__.py\n",
            "deepcomedy/.ipynb_checkpoints/\n",
            "nlgpoetry/\n",
            "nlgpoetry/utils.py\n",
            "nlgpoetry/hyphenation.py\n",
            "nlgpoetry/__pycache__/\n",
            "nlgpoetry/__pycache__/hyphenation.cpython-37.pyc\n",
            "nlgpoetry/__pycache__/utils.cpython-37.pyc\n",
            "nlgpoetry/.ipynb_checkpoints/\n",
            "nlgpoetry/.ipynb_checkpoints/hyphenation-checkpoint.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e335096-8f4e-4c53-8895-347ea9ac6a2d"
      },
      "source": [
        "from nlgpoetry.hyphenation import *"
      ],
      "id": "6e335096-8f4e-4c53-8895-347ea9ac6a2d",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d3d5689-9dab-44c2-8ac0-13874d5a43bd"
      },
      "source": [
        "from deepcomedy.preprocessing import load_verses\n",
        "from deepcomedy.models.transformer import *\n",
        "from deepcomedy.util.predicate import predicate\n",
        "import tqdm"
      ],
      "id": "4d3d5689-9dab-44c2-8ac0-13874d5a43bd",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ce4c30-15f0-49ab-b286-5e4a1abec29e"
      },
      "source": [
        "import re\n",
        "import tensorflow as tf"
      ],
      "id": "14ce4c30-15f0-49ab-b286-5e4a1abec29e",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3518ffc0-2e79-424b-a6fd-ee3f9ddbc64c"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "id": "3518ffc0-2e79-424b-a6fd-ee3f9ddbc64c",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c965200c-fc45-4d9a-bb3c-489af215461b"
      },
      "source": [
        "### TODO\n",
        "potremmo usare il codice del prof per trovare le discordanze dovute a sinalefe non gestita."
      ],
      "id": "c965200c-fc45-4d9a-bb3c-489af215461b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8380205-3f61-4617-8bff-e75a842d5cfa"
      },
      "source": [
        "_, verses, tokenizer = load_verses('./data/divina_textonly.txt', char_level=True, pad=True)"
      ],
      "id": "a8380205-3f61-4617-8bff-e75a842d5cfa",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a77f6433-79aa-43a1-a917-e01be003fe33"
      },
      "source": [
        "orlando_path = 'data/orlando.txt'\n",
        "orlando = open(orlando_path, \"rb\").read().decode(encoding=\"utf-8\")\n",
        "orlando = orlando.split('\\n')[44:53579]"
      ],
      "id": "a77f6433-79aa-43a1-a917-e01be003fe33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "764c20f0-4c43-49a1-9959-439ac2b4a463"
      },
      "source": [
        "@predicate\n",
        "def is_not_empty(string):\n",
        "    \"\"\"\n",
        "    Checks string is not empty\n",
        "    \"\"\"\n",
        "    return string is not None and string != ''\n",
        "\n",
        "@predicate\n",
        "def is_not_number(string):\n",
        "    try:\n",
        "        int(string)\n",
        "        return False\n",
        "    except:\n",
        "        return True\n",
        "\n",
        "@predicate\n",
        "def is_not_chapter(string):\n",
        "    return not re.match(r'CANTO .*', string)"
      ],
      "id": "764c20f0-4c43-49a1-9959-439ac2b4a463",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3193e6f3-ee83-438b-8dc7-db104c70d364"
      },
      "source": [
        "orlando_textonly = list(map(lambda x: x.strip(), filter(is_not_empty & is_not_number & is_not_chapter, orlando)))\n",
        "orlando_syll = list(map(hyphenation, orlando_textonly))"
      ],
      "id": "3193e6f3-ee83-438b-8dc7-db104c70d364",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c42c37c4-bf9b-4575-a68d-67266f3bc1c0"
      },
      "source": [
        "orlando_syll"
      ],
      "id": "c42c37c4-bf9b-4575-a68d-67266f3bc1c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12cc3975-7397-4b2d-9f8e-2b9b6c3f410b"
      },
      "source": [
        "orlando_textonly"
      ],
      "id": "12cc3975-7397-4b2d-9f8e-2b9b6c3f410b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ed2b2c2-5318-4e36-915d-b6d79db89ab0"
      },
      "source": [
        "set(''.join(orlando))"
      ],
      "id": "0ed2b2c2-5318-4e36-915d-b6d79db89ab0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "843b4791-a446-43c2-90b5-547897a77933"
      },
      "source": [
        "num_layers = 6\n",
        "d_model = 256\n",
        "dff = 1024\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "\n",
        "vocab_size = 82"
      ],
      "id": "843b4791-a446-43c2-90b5-547897a77933",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32f99ed5-fbdf-48e2-9748-cb4b8d9ccb4c"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=vocab_size,\n",
        "    target_vocab_size=vocab_size,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate,\n",
        ")\n",
        "learning_rate = TransformerCustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
        ")"
      ],
      "id": "32f99ed5-fbdf-48e2-9748-cb4b8d9ccb4c",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4798d284-f934-4c27-b409-a52b945a4610",
        "outputId": "ba525ca7-9446-4084-8c6c-0c6756f0b2c5"
      },
      "source": [
        "ckpt = tf.train.Checkpoint(\n",
        "    transformer=transformer, optimizer=optimizer\n",
        ")\n",
        "\n",
        "checkpoint_manager = tf.train.CheckpointManager(\n",
        "    ckpt, '/content/drive/MyDrive/checkpoints/train', max_to_keep=5\n",
        ")\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if checkpoint_manager.latest_checkpoint:\n",
        "    ckpt.restore(checkpoint_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "id": "4798d284-f934-4c27-b409-a52b945a4610",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fee5ce2-b7fe-4f0f-bd7d-afe4891ae8da"
      },
      "source": [
        "def evaluate(sentence, max_length=200):\n",
        "\n",
        "    encoder_input = tf.expand_dims(sentence, 0)\n",
        "    output = tf.convert_to_tensor([tokenizer.word_index[\"^\"]])\n",
        "    output = tf.expand_dims(output, 0)\n",
        "    result = \"\"\n",
        "\n",
        "    for i in range(max_length):\n",
        "        \n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output\n",
        "        )\n",
        "\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask,\n",
        "        )\n",
        "\n",
        "        # select the last character from the seq_len dimension\n",
        "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
        "        output = tf.concat(\n",
        "            [tf.cast(output, dtype=tf.int32), tf.cast(predicted_id, dtype=tf.int32)],\n",
        "            axis=-1,\n",
        "        )\n",
        "        result += tokenizer.index_word[predicted_id.numpy()[0][0]] + \" \"\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == tokenizer.word_index[\"$\"]:\n",
        "            break\n",
        "\n",
        "    # output.shape (1, tokens)\n",
        "\n",
        "    return result"
      ],
      "id": "0fee5ce2-b7fe-4f0f-bd7d-afe4891ae8da",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f765259-682f-4dd4-849e-fdcbb98f6221"
      },
      "source": [
        "neural_syll = list(map(evaluate, verses))"
      ],
      "id": "4f765259-682f-4dd4-849e-fdcbb98f6221",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a02e9f2-874a-435c-826c-7e290472a36f",
        "outputId": "08a8df52-a698-407e-a470-1ccceaead80e"
      },
      "source": [
        "neural_syll = []\n",
        "\n",
        "for i, verse in tqdm.tqdm(enumerate(verses), total=len(verses)):\n",
        "    neural_syll.append(evaluate(verse))"
      ],
      "id": "2a02e9f2-874a-435c-826c-7e290472a36f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/14233 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}