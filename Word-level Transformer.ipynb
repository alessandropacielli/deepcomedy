{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Word-level Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "54j16swJY1dW"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRKGBdAtVIfZ"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/wordlevel\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "8RuMqNB4ujuT"
      },
      "source": [
        "## 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "lsuXc5StY1dY"
      },
      "source": [
        "input_file = \"data/divina_textonly.txt\"\n",
        "target_file = \"data/divina_syll_textonly.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "ACAEUyITY1dY",
        "outputId": "757a5afa-98ac-44a5-993a-dd76757e61d4"
      },
      "source": [
        "input_text_raw = open(input_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
        "target_text_raw = open(target_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
        "print(\"Length of input text: {} characters\".format(len(input_text_raw)))\n",
        "print(\"Length of target text: {} characters\".format(len(target_text_raw)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of input text: 578077 characters\n",
            "Length of target text: 892871 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "RDRNHkB-VIfc"
      },
      "source": [
        "def preprocess(text):\n",
        "    \"\"\"\n",
        "    For each line in the file, add start symbol \"^\" in the beginning and end symbol \"$\" in the end\n",
        "    \"\"\"\n",
        "    return [\"^ \" + line.strip() + \" $\" for line in text.split(\"\\n\") if line.strip() != \"\"]\n",
        "\n",
        "\n",
        "input_text_prepr = preprocess(input_text_raw)\n",
        "target_text_prepr = preprocess(target_text_raw)\n",
        "target_text_prepr = list(map(lambda x: re.sub('\\|', ' ', x), target_text_prepr))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cowh73Lum0bx",
        "outputId": "891d8f4a-f812-4290-a3d4-71a117f397ca"
      },
      "source": [
        "input_text_prepr"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['^ Nel mezzo del cammin di nostra vita $',\n",
              " '^ mi ritrovai per una selva oscura, $',\n",
              " '^ ché la diritta via era smarrita. $',\n",
              " '^ Ahi quanto a dir qual era è cosa dura $',\n",
              " '^ esta selva selvaggia e aspra e forte $',\n",
              " '^ che nel pensier rinova la paura! $',\n",
              " '^ Tant’ è amara che poco è più morte; $',\n",
              " '^ ma per trattar del ben ch’i’ vi trovai, $',\n",
              " '^ dirò de l’altre cose ch’i’ v’ho scorte. $',\n",
              " '^ Io non so ben ridir com’ i’ v’intrai, $',\n",
              " '^ tant’ era pien di sonno a quel punto $',\n",
              " '^ che la verace via abbandonai. $',\n",
              " '^ Ma poi ch’i’ fui al piè d’un colle giunto, $',\n",
              " '^ là dove terminava quella valle $',\n",
              " '^ che m’avea di paura il cor compunto, $',\n",
              " '^ guardai in alto e vidi le sue spalle $',\n",
              " '^ vestite già de’ raggi del pianeta $',\n",
              " '^ che mena dritto altrui per ogne calle. $',\n",
              " '^ Allor fu la paura un poco queta, $',\n",
              " '^ che nel lago del cor m’era durata $',\n",
              " '^ la notte ch’i’ passai con tanta pieta. $',\n",
              " '^ E come quei che con lena affannata, $',\n",
              " '^ uscito fuor del pelago a la riva, $',\n",
              " '^ si volge a l’acqua perigliosa e guata, $',\n",
              " '^ così l’animo mio, ch’ancor fuggiva, $',\n",
              " '^ si volse a retro a rimirar lo passo $',\n",
              " '^ che non lasciò già mai persona viva. $',\n",
              " '^ Poi ch’èi posato un poco il corpo lasso, $',\n",
              " '^ ripresi via per la piaggia diserta, $',\n",
              " '^ sì che ’l piè fermo sempre era ’l più basso. $',\n",
              " '^ Ed ecco, quasi al cominciar de l’erta, $',\n",
              " '^ una lonza leggera e presta molto, $',\n",
              " '^ che di pel macolato era coverta; $',\n",
              " '^ e non mi si partia dinanzi al volto, $',\n",
              " '^ anzi ’mpediva tanto il mio cammino, $',\n",
              " '^ ch’i’ fui per ritornar più volte vòlto. $',\n",
              " '^ Temp’ era dal principio del mattino, $',\n",
              " '^ e ’l sol montava ’n sù con quelle stelle $',\n",
              " '^ ch’eran con lui quando l’amor divino $',\n",
              " '^ mosse di prima quelle cose belle; $',\n",
              " '^ sì ch’a bene sperar m’era cagione $',\n",
              " '^ di quella fiera a la gaetta pelle $',\n",
              " '^ l’ora del tempo e la dolce stagione; $',\n",
              " '^ ma non sì che paura non mi desse $',\n",
              " '^ la vista che m’apparve d’un leone. $',\n",
              " '^ Questi parea che contra me venisse $',\n",
              " '^ con la test’ alta e con rabbiosa fame, $',\n",
              " '^ sì che parea che l’aere ne tremesse. $',\n",
              " '^ Ed una lupa, che di tutte brame $',\n",
              " '^ sembiava carca ne la sua magrezza, $',\n",
              " '^ e molte genti fé già viver grame, $',\n",
              " '^ questa mi porse tanto di gravezza $',\n",
              " '^ con la paura ch’uscia di sua vista, $',\n",
              " '^ ch’io perdei la speranza de l’altezza. $',\n",
              " '^ E qual è quei che volontieri acquista, $',\n",
              " '^ e giugne ’l tempo che perder lo face, $',\n",
              " '^ che ’n tutti suoi pensier piange e s’attrista; $',\n",
              " '^ tal mi fece la bestia sanza pace, $',\n",
              " '^ che, venendomi ’ncontro, a poco a poco $',\n",
              " '^ mi ripigneva là dove ’l sol tace. $',\n",
              " '^ Mentre ch’i’ rovinava in basso loco, $',\n",
              " '^ dinanzi a li occhi mi si fu offerto $',\n",
              " '^ chi per lungo silenzio parea fioco. $',\n",
              " '^ Quando vidi costui nel gran diserto, $',\n",
              " '^ «Miserere di me», gridai a lui, $',\n",
              " '^ «qual che tu sii, od ombra od omo certo!». $',\n",
              " '^ Rispuosemi: «Non omo, omo già fui, $',\n",
              " '^ e li parenti miei furon lombardi, $',\n",
              " '^ mantoani per patrïa ambedui. $',\n",
              " '^ Nacqui sub Iulio, ancor che fosse tardi, $',\n",
              " '^ e vissi a Roma sotto ’l buono Augusto $',\n",
              " '^ nel tempo de li dèi falsi e bugiardi. $',\n",
              " '^ Poeta fui, e cantai di quel giusto $',\n",
              " '^ figliuol d’Anchise che venne di Troia, $',\n",
              " '^ poi che ’l superbo Ilïón fu combusto. $',\n",
              " '^ Ma tu perché ritorni a tanta noia? $',\n",
              " '^ perché non sali il dilettoso monte $',\n",
              " '^ ch’è principio e cagion di tutta gioia?». $',\n",
              " '^ «Or se’ tu quel Virgilio e quella fonte $',\n",
              " '^ che spandi di parlar sì largo fiume?», $',\n",
              " '^ rispuos’ io lui con vergognosa fronte. $',\n",
              " '^ «O de li altri poeti onore e lume, $',\n",
              " '^ vagliami ’l lungo studio e ’l grande amore $',\n",
              " '^ che m’ha fatto cercar lo tuo volume. $',\n",
              " '^ Tu se’ lo mio maestro e ’l mio autore, $',\n",
              " '^ tu se’ solo colui da cu’ io tolsi $',\n",
              " '^ lo bello stilo che m’ha fatto onore. $',\n",
              " '^ Vedi la bestia per cu’ io mi volsi; $',\n",
              " '^ aiutami da lei, famoso saggio, $',\n",
              " '^ ch’ella mi fa tremar le vene e i polsi». $',\n",
              " '^ «A te convien tenere altro vïaggio», $',\n",
              " '^ rispuose, poi che lagrimar mi vide, $',\n",
              " '^ «se vuo’ campar d’esto loco selvaggio; $',\n",
              " '^ ché questa bestia, per la qual tu gride, $',\n",
              " '^ non lascia altrui passar per la sua via, $',\n",
              " '^ ma tanto lo ’mpedisce che l’uccide; $',\n",
              " '^ e ha natura sì malvagia e ria, $',\n",
              " '^ che mai non empie la bramosa voglia, $',\n",
              " '^ e dopo ’l pasto ha più fame che pria. $',\n",
              " '^ Molti son li animali a cui s’ammoglia, $',\n",
              " '^ e più saranno ancora, infin che ’l veltro $',\n",
              " '^ verrà, che la farà morir con doglia. $',\n",
              " '^ Questi non ciberà terra né peltro, $',\n",
              " '^ ma sapïenza, amore e virtute, $',\n",
              " '^ e sua nazion sarà tra feltro e feltro. $',\n",
              " '^ Di quella umile Italia fia salute $',\n",
              " '^ per cui morì la vergine Cammilla, $',\n",
              " '^ Eurialo e Turno e Niso di ferute. $',\n",
              " '^ Questi la caccerà per ogne villa, $',\n",
              " '^ fin che l’avrà rimessa ne lo ’nferno, $',\n",
              " '^ là onde ’nvidia prima dipartilla. $',\n",
              " '^ Ond’ io per lo tuo me’ penso e discerno $',\n",
              " '^ che tu mi segui, e io sarò tua guida, $',\n",
              " '^ e trarrotti di qui per loco etterno; $',\n",
              " '^ ove udirai le disperate strida, $',\n",
              " '^ vedrai li antichi spiriti dolenti, $',\n",
              " '^ ch’a la seconda morte ciascun grida; $',\n",
              " '^ e vederai color che son contenti $',\n",
              " '^ nel foco, perché speran di venire $',\n",
              " '^ quando che sia a le beate genti. $',\n",
              " '^ A le quai poi se tu vorrai salire, $',\n",
              " '^ anima fia a ciò più di me degna: $',\n",
              " '^ con lei ti lascerò nel mio partire; $',\n",
              " '^ ché quello imperador che là sù regna, $',\n",
              " '^ perch’ i’ fu’ ribellante a la sua legge, $',\n",
              " '^ non vuol che ’n sua città per me si vegna. $',\n",
              " '^ In tutte parti impera e quivi regge; $',\n",
              " '^ quivi è la sua città e l’alto seggio: $',\n",
              " '^ oh felice colui cu’ ivi elegge!». $',\n",
              " '^ E io a lui: «Poeta, io ti richeggio $',\n",
              " '^ per quello Dio che tu non conoscesti, $',\n",
              " '^ acciò ch’io fugga questo male e peggio, $',\n",
              " '^ che tu mi meni là dov’ or dicesti, $',\n",
              " '^ sì ch’io veggia la porta di san Pietro $',\n",
              " '^ e color cui tu fai cotanto mesti». $',\n",
              " '^ Allor si mosse, e io li tenni dietro. $',\n",
              " '^ Lo giorno se n’andava, e l’aere bruno $',\n",
              " '^ toglieva li animai che sono in terra $',\n",
              " '^ da le fatiche loro; e io sol uno $',\n",
              " '^ m’apparecchiava a sostener la guerra $',\n",
              " '^ sì del cammino e sì de la pietate, $',\n",
              " '^ che ritrarrà la mente che non erra. $',\n",
              " '^ O muse, o alto ingegno, or m’aiutate; $',\n",
              " '^ o mente che scrivesti ciò ch’io vidi, $',\n",
              " '^ qui si parrà la tua nobilitate. $',\n",
              " '^ Io cominciai: «Poeta che mi guidi, $',\n",
              " '^ guarda la mia virtù s’ell’ è possente, $',\n",
              " '^ prima ch’a l’alto passo tu mi fidi. $',\n",
              " '^ Tu dici che di Silvïo il parente, $',\n",
              " '^ corruttibile ancora, ad immortale $',\n",
              " '^ secolo andò, e fu sensibilmente. $',\n",
              " '^ Però, se l’avversario d’ogne male $',\n",
              " '^ cortese i fu, pensando l’alto effetto $',\n",
              " '^ ch’uscir dovea di lui, e ’l chi e ’l quale $',\n",
              " '^ non pare indegno ad omo d’intelletto; $',\n",
              " '^ ch’e’ fu de l’alma Roma e di suo impero $',\n",
              " '^ ne l’empirëo ciel per padre eletto: $',\n",
              " '^ la quale e ’l quale, a voler dir lo vero, $',\n",
              " '^ fu stabilita per lo loco santo $',\n",
              " '^ u’ siede il successor del maggior Piero. $',\n",
              " '^ Per quest’ andata onde li dai tu vanto, $',\n",
              " '^ intese cose che furon cagione $',\n",
              " '^ di sua vittoria e del papale ammanto. $',\n",
              " '^ Andovvi poi lo Vas d’elezïone, $',\n",
              " '^ per recarne conforto a quella fede $',\n",
              " '^ ch’è principio a la via di salvazione. $',\n",
              " '^ Ma io, perché venirvi? o chi ’l concede? $',\n",
              " '^ Io non Enëa, io non Paulo sono; $',\n",
              " '^ me degno a ciò né io né altri ’l crede. $',\n",
              " '^ Per che, se del venire io m’abbandono, $',\n",
              " '^ temo che la venuta non sia folle. $',\n",
              " '^ Se’ savio; intendi me’ ch’i’ non ragiono». $',\n",
              " '^ E qual è quei che disvuol ciò che volle $',\n",
              " '^ e per novi pensier cangia proposta, $',\n",
              " '^ sì che dal cominciar tutto si tolle, $',\n",
              " '^ tal mi fec’ ïo ’n quella oscura costa, $',\n",
              " '^ perché, pensando, consumai la ’mpresa $',\n",
              " '^ che fu nel cominciar cotanto tosta. $',\n",
              " '^ «S’i’ ho ben la parola tua intesa», $',\n",
              " '^ rispuose del magnanimo quell’ ombra, $',\n",
              " '^ «l’anima tua è da viltade offesa; $',\n",
              " '^ la qual molte fïate l’omo ingombra $',\n",
              " '^ sì che d’onrata impresa lo rivolve, $',\n",
              " '^ come falso veder bestia quand’ ombra. $',\n",
              " '^ Da questa tema acciò che tu ti solve, $',\n",
              " '^ dirotti perch’ io venni e quel ch’io ’ntesi $',\n",
              " '^ nel primo punto che di te mi dolve. $',\n",
              " '^ Io era tra color che son sospesi, $',\n",
              " '^ e donna mi chiamò beata e bella, $',\n",
              " '^ tal che di comandare io la richiesi. $',\n",
              " '^ Lucevan li occhi suoi più che la stella; $',\n",
              " '^ e cominciommi a dir soave e piana, $',\n",
              " '^ con angelica voce, in sua favella: $',\n",
              " '^ “O anima cortese mantoana, $',\n",
              " '^ di cui la fama ancor nel mondo dura, $',\n",
              " '^ e durerà quanto ’l mondo lontana, $',\n",
              " '^ l’amico mio, e non de la ventura, $',\n",
              " '^ ne la diserta piaggia è impedito $',\n",
              " '^ sì nel cammin, che vòlt’ è per paura; $',\n",
              " '^ e temo che non sia già sì smarrito, $',\n",
              " '^ ch’io mi sia tardi al soccorso levata, $',\n",
              " '^ per quel ch’i’ ho di lui nel cielo udito. $',\n",
              " '^ Or movi, e con la tua parola ornata $',\n",
              " '^ e con ciò c’ha mestieri al suo campare, $',\n",
              " '^ l’aiuta sì ch’i’ ne sia consolata. $',\n",
              " '^ I’ son Beatrice che ti faccio andare; $',\n",
              " '^ vegno del loco ove tornar disio; $',\n",
              " '^ amor mi mosse, che mi fa parlare. $',\n",
              " '^ Quando sarò dinanzi al segnor mio, $',\n",
              " '^ di te mi loderò sovente a lui”. $',\n",
              " '^ Tacette allora, e poi comincia’ io: $',\n",
              " '^ “O donna di virtù sola per cui $',\n",
              " '^ l’umana spezie eccede ogne contento $',\n",
              " '^ di quel ciel c’ha minor li cerchi sui, $',\n",
              " '^ tanto m’aggrada il tuo comandamento, $',\n",
              " '^ che l’ubidir, se già fosse, m’è tardi; $',\n",
              " '^ più non t’è uo’ ch’aprirmi il tuo talento. $',\n",
              " '^ Ma dimmi la cagion che non ti guardi $',\n",
              " '^ de lo scender qua giuso in questo centro $',\n",
              " '^ de l’ampio loco ove tornar tu ardi”. $',\n",
              " '^ “Da che tu vuo’ saver cotanto a dentro, $',\n",
              " '^ dirotti brievemente”, mi rispuose, $',\n",
              " '^ “perch’ i’ non temo di venir qua entro. $',\n",
              " '^ Temer si dee di sole quelle cose $',\n",
              " '^ c’hanno potenza di fare altrui male; $',\n",
              " '^ de l’altre no, ché non son paurose. $',\n",
              " '^ I’ son fatta da Dio, sua mercé, tale, $',\n",
              " '^ che la vostra miseria non mi tange, $',\n",
              " '^ né fiamma d’esto ’ncendio non m’assale. $',\n",
              " '^ Donna è gentil nel ciel che si compiange $',\n",
              " '^ di questo ’mpedimento ov’ io ti mando, $',\n",
              " '^ sì che duro giudicio là sù frange. $',\n",
              " '^ Questa chiese Lucia in suo dimando $',\n",
              " '^ e disse:—Or ha bisogno il tuo fedele $',\n",
              " '^ di te, e io a te lo raccomando—. $',\n",
              " '^ Lucia, nimica di ciascun crudele, $',\n",
              " '^ si mosse, e venne al loco dov’ i’ era, $',\n",
              " '^ che mi sedea con l’antica Rachele. $',\n",
              " '^ Disse:—Beatrice, loda di Dio vera, $',\n",
              " '^ ché non soccorri quei che t’amò tanto, $',\n",
              " '^ ch’uscì per te de la volgare schiera? $',\n",
              " '^ Non odi tu la pieta del suo pianto, $',\n",
              " '^ non vedi tu la morte che ’l combatte $',\n",
              " '^ su la fiumana ove ’l mar non ha vanto?-. $',\n",
              " '^ Al mondo non fur mai persone ratte $',\n",
              " '^ a far lor pro o a fuggir lor danno, $',\n",
              " '^ com’ io, dopo cotai parole fatte, $',\n",
              " '^ venni qua giù del mio beato scanno, $',\n",
              " '^ fidandomi del tuo parlare onesto, $',\n",
              " '^ ch’onora te e quei ch’udito l’hanno”. $',\n",
              " '^ Poscia che m’ebbe ragionato questo, $',\n",
              " '^ li occhi lucenti lagrimando volse, $',\n",
              " '^ per che mi fece del venir più presto. $',\n",
              " '^ E venni a te così com’ ella volse: $',\n",
              " '^ d’inanzi a quella fiera ti levai $',\n",
              " '^ che del bel monte il corto andar ti tolse. $',\n",
              " '^ Dunque: che è? perché, perché restai, $',\n",
              " '^ perché tanta viltà nel core allette, $',\n",
              " '^ perché ardire e franchezza non hai, $',\n",
              " '^ poscia che tai tre donne benedette $',\n",
              " '^ curan di te ne la corte del cielo, $',\n",
              " '^ e ’l mio parlar tanto ben ti promette?». $',\n",
              " '^ Quali fioretti dal notturno gelo $',\n",
              " '^ chinati e chiusi, poi che ’l sol li ’mbianca, $',\n",
              " '^ si drizzan tutti aperti in loro stelo, $',\n",
              " '^ tal mi fec’ io di mia virtude stanca, $',\n",
              " '^ e tanto buono ardire al cor mi corse, $',\n",
              " '^ ch’i’ cominciai come persona franca: $',\n",
              " '^ «Oh pietosa colei che mi soccorse! $',\n",
              " '^ e te cortese ch’ubidisti tosto $',\n",
              " '^ a le vere parole che ti porse! $',\n",
              " '^ Tu m’hai con disiderio il cor disposto $',\n",
              " '^ sì al venir con le parole tue, $',\n",
              " '^ ch’i’ son tornato nel primo proposto. $',\n",
              " '^ Or va, ch’un sol volere è d’ambedue: $',\n",
              " '^ tu duca, tu segnore e tu maestro». $',\n",
              " '^ Così li dissi; e poi che mosso fue, $',\n",
              " '^ intrai per lo cammino alto e silvestro. $',\n",
              " '^ “Per me si va ne la città dolente, $',\n",
              " '^ per me si va ne l’etterno dolore, $',\n",
              " '^ per me si va tra la perduta gente. $',\n",
              " '^ Giustizia mosse il mio alto fattore; $',\n",
              " '^ fecemi la divina podestate, $',\n",
              " '^ la somma sapïenza e ’l primo amore. $',\n",
              " '^ Dinanzi a me non fuor cose create $',\n",
              " '^ se non etterne, e io etterno duro. $',\n",
              " '^ Lasciate ogne speranza, voi ch’intrate”. $',\n",
              " '^ Queste parole di colore oscuro $',\n",
              " '^ vid’ ïo scritte al sommo d’una porta; $',\n",
              " '^ per ch’io: «Maestro, il senso lor m’è duro». $',\n",
              " '^ Ed elli a me, come persona accorta: $',\n",
              " '^ «Qui si convien lasciare ogne sospetto; $',\n",
              " '^ ogne viltà convien che qui sia morta. $',\n",
              " '^ Noi siam venuti al loco ov’ i’ t’ho detto $',\n",
              " '^ che tu vedrai le genti dolorose $',\n",
              " '^ c’hanno perduto il ben de l’intelletto». $',\n",
              " '^ E poi che la sua mano a la mia puose $',\n",
              " '^ con lieto volto, ond’ io mi confortai, $',\n",
              " '^ mi mise dentro a le segrete cose. $',\n",
              " '^ Quivi sospiri, pianti e alti guai $',\n",
              " '^ risonavan per l’aere sanza stelle, $',\n",
              " '^ per ch’io al cominciar ne lagrimai. $',\n",
              " '^ Diverse lingue, orribili favelle, $',\n",
              " '^ parole di dolore, accenti d’ira, $',\n",
              " '^ voci alte e fioche, e suon di man con elle $',\n",
              " '^ facevano un tumulto, il qual s’aggira $',\n",
              " '^ sempre in quell’ aura sanza tempo tinta, $',\n",
              " '^ come la rena quando turbo spira. $',\n",
              " '^ E io ch’avea d’error la testa cinta, $',\n",
              " '^ dissi: «Maestro, che è quel ch’i’ odo? $',\n",
              " '^ e che gent’ è che par nel duol sì vinta?». $',\n",
              " '^ Ed elli a me: «Questo misero modo $',\n",
              " '^ tegnon l’anime triste di coloro $',\n",
              " '^ che visser sanza ’nfamia e sanza lodo. $',\n",
              " '^ Mischiate sono a quel cattivo coro $',\n",
              " '^ de li angeli che non furon ribelli $',\n",
              " '^ né fur fedeli a Dio, ma per sé fuoro. $',\n",
              " '^ Caccianli i ciel per non esser men belli, $',\n",
              " '^ né lo profondo inferno li riceve, $',\n",
              " '^ ch’alcuna gloria i rei avrebber d’elli». $',\n",
              " '^ E io: «Maestro, che è tanto greve $',\n",
              " '^ a lor che lamentar li fa sì forte?». $',\n",
              " '^ Rispuose: «Dicerolti molto breve. $',\n",
              " '^ Questi non hanno speranza di morte, $',\n",
              " '^ e la lor cieca vita è tanto bassa, $',\n",
              " '^ che ’nvidïosi son d’ogne altra sorte. $',\n",
              " '^ Fama di loro il mondo esser non lassa; $',\n",
              " '^ misericordia e giustizia li sdegna: $',\n",
              " '^ non ragioniam di lor, ma guarda e passa». $',\n",
              " '^ E io, che riguardai, vidi una ’nsegna $',\n",
              " '^ che girando correva tanto ratta, $',\n",
              " '^ che d’ogne posa mi parea indegna; $',\n",
              " '^ e dietro le venìa sì lunga tratta $',\n",
              " '^ di gente, ch’i’ non averei creduto $',\n",
              " '^ che morte tanta n’avesse disfatta. $',\n",
              " '^ Poscia ch’io v’ebbi alcun riconosciuto, $',\n",
              " '^ vidi e conobbi l’ombra di colui $',\n",
              " '^ che fece per viltade il gran rifiuto. $',\n",
              " '^ Incontanente intesi e certo fui $',\n",
              " '^ che questa era la setta d’i cattivi, $',\n",
              " '^ a Dio spiacenti e a’ nemici sui. $',\n",
              " '^ Questi sciaurati, che mai non fur vivi, $',\n",
              " '^ erano ignudi e stimolati molto $',\n",
              " '^ da mosconi e da vespe ch’eran ivi. $',\n",
              " '^ Elle rigavan lor di sangue il volto, $',\n",
              " '^ che, mischiato di lagrime, a’ lor piedi $',\n",
              " '^ da fastidiosi vermi era ricolto. $',\n",
              " '^ E poi ch’a riguardar oltre mi diedi, $',\n",
              " '^ vidi genti a la riva d’un gran fiume; $',\n",
              " '^ per ch’io dissi: «Maestro, or mi concedi $',\n",
              " '^ ch’i’ sappia quali sono, e qual costume $',\n",
              " '^ le fa di trapassar parer sì pronte, $',\n",
              " '^ com’ i’ discerno per lo fioco lume». $',\n",
              " '^ Ed elli a me: «Le cose ti fier conte $',\n",
              " '^ quando noi fermerem li nostri passi $',\n",
              " '^ su la trista riviera d’Acheronte». $',\n",
              " '^ Allor con li occhi vergognosi e bassi, $',\n",
              " '^ temendo no ’l mio dir li fosse grave, $',\n",
              " '^ infino al fiume del parlar mi trassi. $',\n",
              " '^ Ed ecco verso noi venir per nave $',\n",
              " '^ un vecchio, bianco per antico pelo, $',\n",
              " '^ gridando: «Guai a voi, anime prave! $',\n",
              " '^ Non isperate mai veder lo cielo: $',\n",
              " '^ i’ vegno per menarvi a l’altra riva $',\n",
              " '^ ne le tenebre etterne, in caldo e ’n gelo. $',\n",
              " '^ E tu che se’ costì, anima viva, $',\n",
              " '^ pàrtiti da cotesti che son morti». $',\n",
              " '^ Ma poi che vide ch’io non mi partiva, $',\n",
              " '^ disse: «Per altra via, per altri porti $',\n",
              " '^ verrai a piaggia, non qui, per passare: $',\n",
              " '^ più lieve legno convien che ti porti». $',\n",
              " '^ E ’l duca lui: «Caron, non ti crucciare: $',\n",
              " '^ vuolsi così colà dove si puote $',\n",
              " '^ ciò che si vuole, e più non dimandare». $',\n",
              " '^ Quinci fuor quete le lanose gote $',\n",
              " '^ al nocchier de la livida palude, $',\n",
              " '^ che ’ntorno a li occhi avea di fiamme rote. $',\n",
              " '^ Ma quell’ anime, ch’eran lasse e nude, $',\n",
              " '^ cangiar colore e dibattero i denti, $',\n",
              " '^ ratto che ’nteser le parole crude. $',\n",
              " '^ Bestemmiavano Dio e lor parenti, $',\n",
              " '^ l’umana spezie e ’l loco e ’l tempo e ’l seme $',\n",
              " '^ di lor semenza e di lor nascimenti. $',\n",
              " '^ Poi si ritrasser tutte quante insieme, $',\n",
              " '^ forte piangendo, a la riva malvagia $',\n",
              " '^ ch’attende ciascun uom che Dio non teme. $',\n",
              " '^ Caron dimonio, con occhi di bragia $',\n",
              " '^ loro accennando, tutte le raccoglie; $',\n",
              " '^ batte col remo qualunque s’adagia. $',\n",
              " '^ Come d’autunno si levan le foglie $',\n",
              " '^ l’una appresso de l’altra, fin che ’l ramo $',\n",
              " '^ vede a la terra tutte le sue spoglie, $',\n",
              " '^ similemente il mal seme d’Adamo $',\n",
              " '^ gittansi di quel lito ad una ad una, $',\n",
              " '^ per cenni come augel per suo richiamo. $',\n",
              " '^ Così sen vanno su per l’onda bruna, $',\n",
              " '^ e avanti che sien di là discese, $',\n",
              " '^ anche di qua nuova schiera s’auna. $',\n",
              " '^ «Figliuol mio», disse ’l maestro cortese, $',\n",
              " '^ «quelli che muoion ne l’ira di Dio $',\n",
              " '^ tutti convegnon qui d’ogne paese; $',\n",
              " '^ e pronti sono a trapassar lo rio, $',\n",
              " '^ ché la divina giustizia li sprona, $',\n",
              " '^ sì che la tema si volve in disio. $',\n",
              " '^ Quinci non passa mai anima buona; $',\n",
              " '^ e però, se Caron di te si lagna, $',\n",
              " '^ ben puoi sapere omai che ’l suo dir suona». $',\n",
              " '^ Finito questo, la buia campagna $',\n",
              " '^ tremò sì forte, che de lo spavento $',\n",
              " '^ la mente di sudore ancor mi bagna. $',\n",
              " '^ La terra lagrimosa diede vento, $',\n",
              " '^ che balenò una luce vermiglia $',\n",
              " '^ la qual mi vinse ciascun sentimento; $',\n",
              " '^ e caddi come l’uom cui sonno piglia. $',\n",
              " '^ Ruppemi l’alto sonno ne la testa $',\n",
              " '^ un greve truono, sì ch’io mi riscossi $',\n",
              " '^ come persona ch’è per forza desta; $',\n",
              " '^ e l’occhio riposato intorno mossi, $',\n",
              " '^ dritto levato, e fiso riguardai $',\n",
              " '^ per conoscer lo loco dov’ io fossi. $',\n",
              " '^ Vero è che ’n su la proda mi trovai $',\n",
              " '^ de la valle d’abisso dolorosa $',\n",
              " '^ che ’ntrono accoglie d’infiniti guai. $',\n",
              " '^ Oscura e profonda era e nebulosa $',\n",
              " '^ tanto che, per ficcar lo viso a fondo, $',\n",
              " '^ io non vi discernea alcuna cosa. $',\n",
              " '^ «Or discendiam qua giù nel cieco mondo», $',\n",
              " '^ cominciò il poeta tutto smorto. $',\n",
              " '^ «Io sarò primo, e tu sarai secondo». $',\n",
              " '^ E io, che del color mi fui accorto, $',\n",
              " '^ dissi: «Come verrò, se tu paventi $',\n",
              " '^ che suoli al mio dubbiare esser conforto?». $',\n",
              " '^ Ed elli a me: «L’angoscia de le genti $',\n",
              " '^ che son qua giù, nel viso mi dipigne $',\n",
              " '^ quella pietà che tu per tema senti. $',\n",
              " '^ Andiam, ché la via lunga ne sospigne». $',\n",
              " '^ Così si mise e così mi fé intrare $',\n",
              " '^ nel primo cerchio che l’abisso cigne. $',\n",
              " '^ Quivi, secondo che per ascoltare, $',\n",
              " '^ non avea pianto mai che di sospiri $',\n",
              " '^ che l’aura etterna facevan tremare; $',\n",
              " '^ ciò avvenia di duol sanza martìri, $',\n",
              " '^ ch’avean le turbe, ch’eran molte e grandi, $',\n",
              " '^ d’infanti e di femmine e di viri. $',\n",
              " '^ Lo buon maestro a me: «Tu non dimandi $',\n",
              " '^ che spiriti son questi che tu vedi? $',\n",
              " '^ Or vo’ che sappi, innanzi che più andi, $',\n",
              " '^ ch’ei non peccaro; e s’elli hanno mercedi, $',\n",
              " '^ non basta, perché non ebber battesmo, $',\n",
              " '^ ch’è porta de la fede che tu credi; $',\n",
              " '^ e s’e’ furon dinanzi al cristianesmo, $',\n",
              " '^ non adorar debitamente a Dio: $',\n",
              " '^ e di questi cotai son io medesmo. $',\n",
              " '^ Per tai difetti, non per altro rio, $',\n",
              " '^ semo perduti, e sol di tanto offesi $',\n",
              " '^ che sanza speme vivemo in disio». $',\n",
              " '^ Gran duol mi prese al cor quando lo ’ntesi, $',\n",
              " '^ però che gente di molto valore $',\n",
              " '^ conobbi che ’n quel limbo eran sospesi. $',\n",
              " '^ «Dimmi, maestro mio, dimmi, segnore», $',\n",
              " '^ comincia’ io per voler esser certo $',\n",
              " '^ di quella fede che vince ogne errore: $',\n",
              " '^ «uscicci mai alcuno, o per suo merto $',\n",
              " '^ o per altrui, che poi fosse beato?». $',\n",
              " '^ E quei che ’ntese il mio parlar coverto, $',\n",
              " '^ rispuose: «Io era nuovo in questo stato, $',\n",
              " '^ quando ci vidi venire un possente, $',\n",
              " '^ con segno di vittoria coronato. $',\n",
              " '^ Trasseci l’ombra del primo parente, $',\n",
              " '^ d’Abèl suo figlio e quella di Noè, $',\n",
              " '^ di Moïsè legista e ubidente; $',\n",
              " '^ Abraàm patrïarca e Davìd re, $',\n",
              " '^ Israèl con lo padre e co’ suoi nati $',\n",
              " '^ e con Rachele, per cui tanto fé, $',\n",
              " '^ e altri molti, e feceli beati. $',\n",
              " '^ E vo’ che sappi che, dinanzi ad essi, $',\n",
              " '^ spiriti umani non eran salvati». $',\n",
              " '^ Non lasciavam l’andar perch’ ei dicessi, $',\n",
              " '^ ma passavam la selva tuttavia, $',\n",
              " '^ la selva, dico, di spiriti spessi. $',\n",
              " '^ Non era lunga ancor la nostra via $',\n",
              " '^ di qua dal sonno, quand’ io vidi un foco $',\n",
              " '^ ch’emisperio di tenebre vincia. $',\n",
              " '^ Di lungi n’eravamo ancora un poco, $',\n",
              " '^ ma non sì ch’io non discernessi in parte $',\n",
              " '^ ch’orrevol gente possedea quel loco. $',\n",
              " '^ «O tu ch’onori scïenzïa e arte, $',\n",
              " '^ questi chi son c’hanno cotanta onranza, $',\n",
              " '^ che dal modo de li altri li diparte?». $',\n",
              " '^ E quelli a me: «L’onrata nominanza $',\n",
              " '^ che di lor suona sù ne la tua vita, $',\n",
              " '^ grazïa acquista in ciel che sì li avanza». $',\n",
              " '^ Intanto voce fu per me udita: $',\n",
              " '^ «Onorate l’altissimo poeta; $',\n",
              " '^ l’ombra sua torna, ch’era dipartita». $',\n",
              " '^ Poi che la voce fu restata e queta, $',\n",
              " '^ vidi quattro grand’ ombre a noi venire: $',\n",
              " '^ sembianz’ avevan né trista né lieta. $',\n",
              " '^ Lo buon maestro cominciò a dire: $',\n",
              " '^ «Mira colui con quella spada in mano, $',\n",
              " '^ che vien dinanzi ai tre sì come sire: $',\n",
              " '^ quelli è Omero poeta sovrano; $',\n",
              " '^ l’altro è Orazio satiro che vene; $',\n",
              " '^ Ovidio è ’l terzo, e l’ultimo Lucano. $',\n",
              " '^ Però che ciascun meco si convene $',\n",
              " '^ nel nome che sonò la voce sola, $',\n",
              " '^ fannomi onore, e di ciò fanno bene». $',\n",
              " '^ Così vid’ i’ adunar la bella scola $',\n",
              " '^ di quel segnor de l’altissimo canto $',\n",
              " '^ che sovra li altri com’ aquila vola. $',\n",
              " '^ Da ch’ebber ragionato insieme alquanto, $',\n",
              " '^ volsersi a me con salutevol cenno, $',\n",
              " '^ e ’l mio maestro sorrise di tanto; $',\n",
              " '^ e più d’onore ancora assai mi fenno, $',\n",
              " '^ ch’e’ sì mi fecer de la loro schiera, $',\n",
              " '^ sì ch’io fui sesto tra cotanto senno. $',\n",
              " '^ Così andammo infino a la lumera, $',\n",
              " '^ parlando cose che ’l tacere è bello, $',\n",
              " '^ sì com’ era ’l parlar colà dov’ era. $',\n",
              " '^ Venimmo al piè d’un nobile castello, $',\n",
              " '^ sette volte cerchiato d’alte mura, $',\n",
              " '^ difeso intorno d’un bel fiumicello. $',\n",
              " '^ Questo passammo come terra dura; $',\n",
              " '^ per sette porte intrai con questi savi: $',\n",
              " '^ giugnemmo in prato di fresca verdura. $',\n",
              " '^ Genti v’eran con occhi tardi e gravi, $',\n",
              " '^ di grande autorità ne’ lor sembianti: $',\n",
              " '^ parlavan rado, con voci soavi. $',\n",
              " '^ Traemmoci così da l’un de’ canti, $',\n",
              " '^ in loco aperto, luminoso e alto, $',\n",
              " '^ sì che veder si potien tutti quanti. $',\n",
              " '^ Colà diritto, sovra ’l verde smalto, $',\n",
              " '^ mi fuor mostrati li spiriti magni, $',\n",
              " '^ che del vedere in me stesso m’essalto. $',\n",
              " '^ I’ vidi Eletra con molti compagni, $',\n",
              " '^ tra ’ quai conobbi Ettòr ed Enea, $',\n",
              " '^ Cesare armato con li occhi grifagni. $',\n",
              " '^ Vidi Cammilla e la Pantasilea; $',\n",
              " '^ da l’altra parte vidi ’l re Latino $',\n",
              " '^ che con Lavina sua figlia sedea. $',\n",
              " '^ Vidi quel Bruto che cacciò Tarquino, $',\n",
              " '^ Lucrezia, Iulia, Marzïa e Corniglia; $',\n",
              " '^ e solo, in parte, vidi ’l Saladino. $',\n",
              " '^ Poi ch’innalzai un poco più le ciglia, $',\n",
              " '^ vidi ’l maestro di color che sanno $',\n",
              " '^ seder tra filosofica famiglia. $',\n",
              " '^ Tutti lo miran, tutti onor li fanno: $',\n",
              " '^ quivi vid’ ïo Socrate e Platone, $',\n",
              " '^ che ’nnanzi a li altri più presso li stanno; $',\n",
              " '^ Democrito che ’l mondo a caso pone, $',\n",
              " '^ Dïogenès, Anassagora e Tale, $',\n",
              " '^ Empedoclès, Eraclito e Zenone; $',\n",
              " '^ e vidi il buono accoglitor del quale, $',\n",
              " '^ Dïascoride dico; e vidi Orfeo, $',\n",
              " '^ Tulïo e Lino e Seneca morale; $',\n",
              " '^ Euclide geomètra e Tolomeo, $',\n",
              " '^ Ipocràte, Avicenna e Galïeno, $',\n",
              " '^ Averoìs, che ’l gran comento feo. $',\n",
              " '^ Io non posso ritrar di tutti a pieno, $',\n",
              " '^ però che sì mi caccia il lungo tema, $',\n",
              " '^ che molte volte al fatto il dir vien meno. $',\n",
              " '^ La sesta compagnia in due si scema: $',\n",
              " '^ per altra via mi mena il savio duca, $',\n",
              " '^ fuor de la queta, ne l’aura che trema. $',\n",
              " '^ E vegno in parte ove non è che luca. $',\n",
              " '^ Così discesi del cerchio primaio $',\n",
              " '^ giù nel secondo, che men loco cinghia $',\n",
              " '^ e tanto più dolor, che punge a guaio. $',\n",
              " '^ Stavvi Minòs orribilmente, e ringhia: $',\n",
              " '^ essamina le colpe ne l’intrata; $',\n",
              " '^ giudica e manda secondo ch’avvinghia. $',\n",
              " '^ Dico che quando l’anima mal nata $',\n",
              " '^ li vien dinanzi, tutta si confessa; $',\n",
              " '^ e quel conoscitor de le peccata $',\n",
              " '^ vede qual loco d’inferno è da essa; $',\n",
              " '^ cignesi con la coda tante volte $',\n",
              " '^ quantunque gradi vuol che giù sia messa. $',\n",
              " '^ Sempre dinanzi a lui ne stanno molte: $',\n",
              " '^ vanno a vicenda ciascuna al giudizio, $',\n",
              " '^ dicono e odono e poi son giù volte. $',\n",
              " '^ «O tu che vieni al doloroso ospizio», $',\n",
              " '^ disse Minòs a me quando mi vide, $',\n",
              " '^ lasciando l’atto di cotanto offizio, $',\n",
              " '^ «guarda com’ entri e di cui tu ti fide; $',\n",
              " '^ non t’inganni l’ampiezza de l’intrare!». $',\n",
              " '^ E ’l duca mio a lui: «Perché pur gride? $',\n",
              " '^ Non impedir lo suo fatale andare: $',\n",
              " '^ vuolsi così colà dove si puote $',\n",
              " '^ ciò che si vuole, e più non dimandare». $',\n",
              " '^ Or incomincian le dolenti note $',\n",
              " '^ a farmisi sentire; or son venuto $',\n",
              " '^ là dove molto pianto mi percuote. $',\n",
              " '^ Io venni in loco d’ogne luce muto, $',\n",
              " '^ che mugghia come fa mar per tempesta, $',\n",
              " '^ se da contrari venti è combattuto. $',\n",
              " '^ La bufera infernal, che mai non resta, $',\n",
              " '^ mena li spirti con la sua rapina; $',\n",
              " '^ voltando e percotendo li molesta. $',\n",
              " '^ Quando giungon davanti a la ruina, $',\n",
              " '^ quivi le strida, il compianto, il lamento; $',\n",
              " '^ bestemmian quivi la virtù divina. $',\n",
              " '^ Intesi ch’a così fatto tormento $',\n",
              " '^ enno dannati i peccator carnali, $',\n",
              " '^ che la ragion sommettono al talento. $',\n",
              " '^ E come li stornei ne portan l’ali $',\n",
              " '^ nel freddo tempo, a schiera larga e piena, $',\n",
              " '^ così quel fiato li spiriti mali $',\n",
              " '^ di qua, di là, di giù, di sù li mena; $',\n",
              " '^ nulla speranza li conforta mai, $',\n",
              " '^ non che di posa, ma di minor pena. $',\n",
              " '^ E come i gru van cantando lor lai, $',\n",
              " '^ faccendo in aere di sé lunga riga, $',\n",
              " '^ così vid’ io venir, traendo guai, $',\n",
              " '^ ombre portate da la detta briga; $',\n",
              " '^ per ch’i’ dissi: «Maestro, chi son quelle $',\n",
              " '^ genti che l’aura nera sì gastiga?». $',\n",
              " '^ «La prima di color di cui novelle $',\n",
              " '^ tu vuo’ saper», mi disse quelli allotta, $',\n",
              " '^ «fu imperadrice di molte favelle. $',\n",
              " '^ A vizio di lussuria fu sì rotta, $',\n",
              " '^ che libito fé licito in sua legge, $',\n",
              " '^ per tòrre il biasmo in che era condotta. $',\n",
              " '^ Ell’ è Semiramìs, di cui si legge $',\n",
              " '^ che succedette a Nino e fu sua sposa: $',\n",
              " '^ tenne la terra che ’l Soldan corregge. $',\n",
              " '^ L’altra è colei che s’ancise amorosa, $',\n",
              " '^ e ruppe fede al cener di Sicheo; $',\n",
              " '^ poi è Cleopatràs lussurïosa. $',\n",
              " '^ Elena vedi, per cui tanto reo $',\n",
              " '^ tempo si volse, e vedi ’l grande Achille, $',\n",
              " '^ che con amore al fine combatteo. $',\n",
              " '^ Vedi Parìs, Tristano»; e più di mille $',\n",
              " '^ ombre mostrommi e nominommi a dito, $',\n",
              " '^ ch’amor di nostra vita dipartille. $',\n",
              " '^ Poscia ch’io ebbi ’l mio dottore udito $',\n",
              " '^ nomar le donne antiche e ’ cavalieri, $',\n",
              " '^ pietà mi giunse, e fui quasi smarrito. $',\n",
              " '^ I’ cominciai: «Poeta, volontieri $',\n",
              " '^ parlerei a quei due che ’nsieme vanno, $',\n",
              " '^ e paion sì al vento esser leggeri». $',\n",
              " '^ Ed elli a me: «Vedrai quando saranno $',\n",
              " '^ più presso a noi; e tu allor li priega $',\n",
              " '^ per quello amor che i mena, ed ei verranno». $',\n",
              " '^ Sì tosto come il vento a noi li piega, $',\n",
              " '^ mossi la voce: «O anime affannate, $',\n",
              " '^ venite a noi parlar, s’altri nol niega!». $',\n",
              " '^ Quali colombe dal disio chiamate $',\n",
              " '^ con l’ali alzate e ferme al dolce nido $',\n",
              " '^ vegnon per l’aere, dal voler portate; $',\n",
              " '^ cotali uscir de la schiera ov’ è Dido, $',\n",
              " '^ a noi venendo per l’aere maligno, $',\n",
              " '^ sì forte fu l’affettüoso grido. $',\n",
              " '^ «O animal grazïoso e benigno $',\n",
              " '^ che visitando vai per l’aere perso $',\n",
              " '^ noi che tignemmo il mondo di sanguigno, $',\n",
              " '^ se fosse amico il re de l’universo, $',\n",
              " '^ noi pregheremmo lui de la tua pace, $',\n",
              " '^ poi c’hai pietà del nostro mal perverso. $',\n",
              " '^ Di quel che udire e che parlar vi piace, $',\n",
              " '^ noi udiremo e parleremo a voi, $',\n",
              " '^ mentre che ’l vento, come fa, ci tace. $',\n",
              " '^ Siede la terra dove nata fui $',\n",
              " '^ su la marina dove ’l Po discende $',\n",
              " '^ per aver pace co’ seguaci sui. $',\n",
              " '^ Amor, ch’al cor gentil ratto s’apprende, $',\n",
              " '^ prese costui de la bella persona $',\n",
              " '^ che mi fu tolta; e ’l modo ancor m’offende. $',\n",
              " '^ Amor, ch’a nullo amato amar perdona, $',\n",
              " '^ mi prese del costui piacer sì forte, $',\n",
              " '^ che, come vedi, ancor non m’abbandona. $',\n",
              " '^ Amor condusse noi ad una morte. $',\n",
              " '^ Caina attende chi a vita ci spense». $',\n",
              " '^ Queste parole da lor ci fuor porte. $',\n",
              " '^ Quand’ io intesi quell’ anime offense, $',\n",
              " '^ china’ il viso, e tanto il tenni basso, $',\n",
              " '^ fin che ’l poeta mi disse: «Che pense?». $',\n",
              " '^ Quando rispuosi, cominciai: «Oh lasso, $',\n",
              " '^ quanti dolci pensier, quanto disio $',\n",
              " '^ menò costoro al doloroso passo!». $',\n",
              " '^ Poi mi rivolsi a loro e parla’ io, $',\n",
              " '^ e cominciai: «Francesca, i tuoi martìri $',\n",
              " '^ a lagrimar mi fanno tristo e pio. $',\n",
              " '^ Ma dimmi: al tempo d’i dolci sospiri, $',\n",
              " '^ a che e come concedette amore $',\n",
              " '^ che conosceste i dubbiosi disiri?». $',\n",
              " '^ E quella a me: «Nessun maggior dolore $',\n",
              " '^ che ricordarsi del tempo felice $',\n",
              " '^ ne la miseria; e ciò sa ’l tuo dottore. $',\n",
              " '^ Ma s’a conoscer la prima radice $',\n",
              " '^ del nostro amor tu hai cotanto affetto, $',\n",
              " '^ dirò come colui che piange e dice. $',\n",
              " '^ Noi leggiavamo un giorno per diletto $',\n",
              " '^ di Lancialotto come amor lo strinse; $',\n",
              " '^ soli eravamo e sanza alcun sospetto. $',\n",
              " '^ Per più fïate li occhi ci sospinse $',\n",
              " '^ quella lettura, e scolorocci il viso; $',\n",
              " '^ ma solo un punto fu quel che ci vinse. $',\n",
              " '^ Quando leggemmo il disïato riso $',\n",
              " '^ esser basciato da cotanto amante, $',\n",
              " '^ questi, che mai da me non fia diviso, $',\n",
              " '^ la bocca mi basciò tutto tremante. $',\n",
              " '^ Galeotto fu ’l libro e chi lo scrisse: $',\n",
              " '^ quel giorno più non vi leggemmo avante». $',\n",
              " '^ Mentre che l’uno spirto questo disse, $',\n",
              " '^ l’altro piangëa; sì che di pietade $',\n",
              " '^ io venni men così com’ io morisse. $',\n",
              " '^ E caddi come corpo morto cade. $',\n",
              " '^ Al tornar de la mente, che si chiuse $',\n",
              " '^ dinanzi a la pietà d’i due cognati, $',\n",
              " '^ che di trestizia tutto mi confuse, $',\n",
              " '^ novi tormenti e novi tormentati $',\n",
              " '^ mi veggio intorno, come ch’io mi mova $',\n",
              " '^ e ch’io mi volga, e come che io guati. $',\n",
              " '^ Io sono al terzo cerchio, de la piova $',\n",
              " '^ etterna, maladetta, fredda e greve; $',\n",
              " '^ regola e qualità mai non l’è nova. $',\n",
              " '^ Grandine grossa, acqua tinta e neve $',\n",
              " '^ per l’aere tenebroso si riversa; $',\n",
              " '^ pute la terra che questo riceve. $',\n",
              " '^ Cerbero, fiera crudele e diversa, $',\n",
              " '^ con tre gole caninamente latra $',\n",
              " '^ sovra la gente che quivi è sommersa. $',\n",
              " '^ Li occhi ha vermigli, la barba unta e atra, $',\n",
              " '^ e ’l ventre largo, e unghiate le mani; $',\n",
              " '^ graffia li spirti ed iscoia ed isquatra. $',\n",
              " '^ Urlar li fa la pioggia come cani; $',\n",
              " '^ de l’un de’ lati fanno a l’altro schermo; $',\n",
              " '^ volgonsi spesso i miseri profani. $',\n",
              " '^ Quando ci scorse Cerbero, il gran vermo, $',\n",
              " '^ le bocche aperse e mostrocci le sanne; $',\n",
              " '^ non avea membro che tenesse fermo. $',\n",
              " '^ E ’l duca mio distese le sue spanne, $',\n",
              " '^ prese la terra, e con piene le pugna $',\n",
              " '^ la gittò dentro a le bramose canne. $',\n",
              " '^ Qual è quel cane ch’abbaiando agogna, $',\n",
              " '^ e si racqueta poi che ’l pasto morde, $',\n",
              " '^ ché solo a divorarlo intende e pugna, $',\n",
              " '^ cotai si fecer quelle facce lorde $',\n",
              " '^ de lo demonio Cerbero, che ’ntrona $',\n",
              " '^ l’anime sì, ch’esser vorrebber sorde. $',\n",
              " '^ Noi passavam su per l’ombre che adona $',\n",
              " '^ la greve pioggia, e ponavam le piante $',\n",
              " '^ sovra lor vanità che par persona. $',\n",
              " '^ Elle giacean per terra tutte quante, $',\n",
              " '^ fuor d’una ch’a seder si levò, ratto $',\n",
              " '^ ch’ella ci vide passarsi davante. $',\n",
              " '^ «O tu che se’ per questo ’nferno tratto», $',\n",
              " '^ mi disse, «riconoscimi, se sai: $',\n",
              " '^ tu fosti, prima ch’io disfatto, fatto». $',\n",
              " '^ E io a lui: «L’angoscia che tu hai $',\n",
              " '^ forse ti tira fuor de la mia mente, $',\n",
              " '^ sì che non par ch’i’ ti vedessi mai. $',\n",
              " '^ Ma dimmi chi tu se’ che ’n sì dolente $',\n",
              " '^ loco se’ messo, e hai sì fatta pena, $',\n",
              " '^ che, s’altra è maggio, nulla è sì spiacente». $',\n",
              " '^ Ed elli a me: «La tua città, ch’è piena $',\n",
              " '^ d’invidia sì che già trabocca il sacco, $',\n",
              " '^ seco mi tenne in la vita serena. $',\n",
              " '^ Voi cittadini mi chiamaste Ciacco: $',\n",
              " '^ per la dannosa colpa de la gola, $',\n",
              " '^ come tu vedi, a la pioggia mi fiacco. $',\n",
              " '^ E io anima trista non son sola, $',\n",
              " '^ ché tutte queste a simil pena stanno $',\n",
              " '^ per simil colpa». E più non fé parola. $',\n",
              " '^ Io li rispuosi: «Ciacco, il tuo affanno $',\n",
              " '^ mi pesa sì, ch’a lagrimar mi ’nvita; $',\n",
              " '^ ma dimmi, se tu sai, a che verranno $',\n",
              " '^ li cittadin de la città partita; $',\n",
              " '^ s’alcun v’è giusto; e dimmi la cagione $',\n",
              " '^ per che l’ha tanta discordia assalita». $',\n",
              " '^ E quelli a me: «Dopo lunga tencione $',\n",
              " '^ verranno al sangue, e la parte selvaggia $',\n",
              " '^ caccerà l’altra con molta offensione. $',\n",
              " '^ Poi appresso convien che questa caggia $',\n",
              " '^ infra tre soli, e che l’altra sormonti $',\n",
              " '^ con la forza di tal che testé piaggia. $',\n",
              " '^ Alte terrà lungo tempo le fronti, $',\n",
              " '^ tenendo l’altra sotto gravi pesi, $',\n",
              " '^ come che di ciò pianga o che n’aonti. $',\n",
              " '^ Giusti son due, e non vi sono intesi; $',\n",
              " '^ superbia, invidia e avarizia sono $',\n",
              " '^ le tre faville c’hanno i cuori accesi». $',\n",
              " '^ Qui puose fine al lagrimabil suono. $',\n",
              " '^ E io a lui: «Ancor vo’ che mi ’nsegni $',\n",
              " '^ e che di più parlar mi facci dono. $',\n",
              " '^ Farinata e ’l Tegghiaio, che fuor sì degni, $',\n",
              " '^ Iacopo Rusticucci, Arrigo e ’l Mosca $',\n",
              " '^ e li altri ch’a ben far puoser li ’ngegni, $',\n",
              " '^ dimmi ove sono e fa ch’io li conosca; $',\n",
              " '^ ché gran disio mi stringe di savere $',\n",
              " '^ se ’l ciel li addolcia o lo ’nferno li attosca». $',\n",
              " '^ E quelli: «Ei son tra l’anime più nere; $',\n",
              " '^ diverse colpe giù li grava al fondo: $',\n",
              " '^ se tanto scendi, là i potrai vedere. $',\n",
              " '^ Ma quando tu sarai nel dolce mondo, $',\n",
              " '^ priegoti ch’a la mente altrui mi rechi: $',\n",
              " '^ più non ti dico e più non ti rispondo». $',\n",
              " '^ Li diritti occhi torse allora in biechi; $',\n",
              " '^ guardommi un poco e poi chinò la testa: $',\n",
              " '^ cadde con essa a par de li altri ciechi. $',\n",
              " '^ E ’l duca disse a me: «Più non si desta $',\n",
              " '^ di qua dal suon de l’angelica tromba, $',\n",
              " '^ quando verrà la nimica podesta: $',\n",
              " '^ ciascun rivederà la trista tomba, $',\n",
              " '^ ripiglierà sua carne e sua figura, $',\n",
              " '^ udirà quel ch’in etterno rimbomba». $',\n",
              " '^ Sì trapassammo per sozza mistura $',\n",
              " '^ de l’ombre e de la pioggia, a passi lenti, $',\n",
              " '^ toccando un poco la vita futura; $',\n",
              " '^ per ch’io dissi: «Maestro, esti tormenti $',\n",
              " '^ crescerann’ ei dopo la gran sentenza, $',\n",
              " '^ o fier minori, o saran sì cocenti?». $',\n",
              " '^ Ed elli a me: «Ritorna a tua scïenza, $',\n",
              " '^ che vuol, quanto la cosa è più perfetta, $',\n",
              " '^ più senta il bene, e così la doglienza. $',\n",
              " '^ Tutto che questa gente maladetta $',\n",
              " '^ in vera perfezion già mai non vada, $',\n",
              " '^ di là più che di qua essere aspetta». $',\n",
              " '^ Noi aggirammo a tondo quella strada, $',\n",
              " '^ parlando più assai ch’i’ non ridico; $',\n",
              " '^ venimmo al punto dove si digrada: $',\n",
              " '^ quivi trovammo Pluto, il gran nemico. $',\n",
              " '^ «Pape Satàn, pape Satàn aleppe!», $',\n",
              " '^ cominciò Pluto con la voce chioccia; $',\n",
              " '^ e quel savio gentil, che tutto seppe, $',\n",
              " '^ disse per confortarmi: «Non ti noccia $',\n",
              " '^ la tua paura; ché, poder ch’elli abbia, $',\n",
              " '^ non ci torrà lo scender questa roccia». $',\n",
              " '^ Poi si rivolse a quella ’nfiata labbia, $',\n",
              " '^ e disse: «Taci, maladetto lupo! $',\n",
              " '^ consuma dentro te con la tua rabbia. $',\n",
              " '^ Non è sanza cagion l’andare al cupo: $',\n",
              " '^ vuolsi ne l’alto, là dove Michele $',\n",
              " '^ fé la vendetta del superbo strupo». $',\n",
              " '^ Quali dal vento le gonfiate vele $',\n",
              " '^ caggiono avvolte, poi che l’alber fiacca, $',\n",
              " '^ tal cadde a terra la fiera crudele. $',\n",
              " '^ Così scendemmo ne la quarta lacca, $',\n",
              " '^ pigliando più de la dolente ripa $',\n",
              " '^ che ’l mal de l’universo tutto insacca. $',\n",
              " '^ Ahi giustizia di Dio! tante chi stipa $',\n",
              " '^ nove travaglie e pene quant’ io viddi? $',\n",
              " '^ e perché nostra colpa sì ne scipa? $',\n",
              " '^ Come fa l’onda là sovra Cariddi, $',\n",
              " '^ che si frange con quella in cui s’intoppa, $',\n",
              " '^ così convien che qui la gente riddi. $',\n",
              " '^ Qui vid’ i’ gente più ch’altrove troppa, $',\n",
              " '^ e d’una parte e d’altra, con grand’ urli, $',\n",
              " '^ voltando pesi per forza di poppa. $',\n",
              " '^ Percotëansi ’ncontro; e poscia pur lì $',\n",
              " '^ si rivolgea ciascun, voltando a retro, $',\n",
              " '^ gridando: «Perché tieni?» e «Perché burli?». $',\n",
              " '^ Così tornavan per lo cerchio tetro $',\n",
              " '^ da ogne mano a l’opposito punto, $',\n",
              " '^ gridandosi anche loro ontoso metro; $',\n",
              " '^ poi si volgea ciascun, quand’ era giunto, $',\n",
              " '^ per lo suo mezzo cerchio a l’altra giostra. $',\n",
              " '^ E io, ch’avea lo cor quasi compunto, $',\n",
              " '^ dissi: «Maestro mio, or mi dimostra $',\n",
              " '^ che gente è questa, e se tutti fuor cherci $',\n",
              " '^ questi chercuti a la sinistra nostra». $',\n",
              " '^ Ed elli a me: «Tutti quanti fuor guerci $',\n",
              " '^ sì de la mente in la vita primaia, $',\n",
              " '^ che con misura nullo spendio ferci. $',\n",
              " '^ Assai la voce lor chiaro l’abbaia, $',\n",
              " '^ quando vegnono a’ due punti del cerchio $',\n",
              " '^ dove colpa contraria li dispaia. $',\n",
              " '^ Questi fuor cherci, che non han coperchio $',\n",
              " '^ piloso al capo, e papi e cardinali, $',\n",
              " '^ in cui usa avarizia il suo soperchio». $',\n",
              " '^ E io: «Maestro, tra questi cotali $',\n",
              " '^ dovre’ io ben riconoscere alcuni $',\n",
              " '^ che furo immondi di cotesti mali». $',\n",
              " '^ Ed elli a me: «Vano pensiero aduni: $',\n",
              " '^ la sconoscente vita che i fé sozzi, $',\n",
              " '^ ad ogne conoscenza or li fa bruni. $',\n",
              " '^ In etterno verranno a li due cozzi: $',\n",
              " '^ questi resurgeranno del sepulcro $',\n",
              " '^ col pugno chiuso, e questi coi crin mozzi. $',\n",
              " '^ Mal dare e mal tener lo mondo pulcro $',\n",
              " '^ ha tolto loro, e posti a questa zuffa: $',\n",
              " '^ qual ella sia, parole non ci appulcro. $',\n",
              " '^ Or puoi, figliuol, veder la corta buffa $',\n",
              " '^ d’i ben che son commessi a la fortuna, $',\n",
              " '^ per che l’umana gente si rabbuffa; $',\n",
              " '^ ché tutto l’oro ch’è sotto la luna $',\n",
              " '^ e che già fu, di quest’ anime stanche $',\n",
              " '^ non poterebbe farne posare una». $',\n",
              " '^ «Maestro mio», diss’ io, «or mi dì anche: $',\n",
              " '^ questa fortuna di che tu mi tocche, $',\n",
              " '^ che è, che i ben del mondo ha sì tra branche?». $',\n",
              " '^ E quelli a me: «Oh creature sciocche, $',\n",
              " '^ quanta ignoranza è quella che v’offende! $',\n",
              " '^ Or vo’ che tu mia sentenza ne ’mbocche. $',\n",
              " '^ Colui lo cui saver tutto trascende, $',\n",
              " '^ fece li cieli e diè lor chi conduce $',\n",
              " '^ sì, ch’ogne parte ad ogne parte splende, $',\n",
              " '^ distribuendo igualmente la luce. $',\n",
              " '^ Similemente a li splendor mondani $',\n",
              " '^ ordinò general ministra e duce $',\n",
              " '^ che permutasse a tempo li ben vani $',\n",
              " '^ di gente in gente e d’uno in altro sangue, $',\n",
              " '^ oltre la difension d’i senni umani; $',\n",
              " '^ per ch’una gente impera e l’altra langue, $',\n",
              " '^ seguendo lo giudicio di costei, $',\n",
              " '^ che è occulto come in erba l’angue. $',\n",
              " '^ Vostro saver non ha contasto a lei: $',\n",
              " '^ questa provede, giudica, e persegue $',\n",
              " '^ suo regno come il loro li altri dèi. $',\n",
              " '^ Le sue permutazion non hanno triegue: $',\n",
              " '^ necessità la fa esser veloce; $',\n",
              " '^ sì spesso vien chi vicenda consegue. $',\n",
              " '^ Quest’ è colei ch’è tanto posta in croce $',\n",
              " '^ pur da color che le dovrien dar lode, $',\n",
              " '^ dandole biasmo a torto e mala voce; $',\n",
              " '^ ma ella s’è beata e ciò non ode: $',\n",
              " '^ con l’altre prime creature lieta $',\n",
              " '^ volve sua spera e beata si gode. $',\n",
              " '^ Or discendiamo omai a maggior pieta; $',\n",
              " '^ già ogne stella cade che saliva $',\n",
              " '^ quand’ io mi mossi, e ’l troppo star si vieta». $',\n",
              " '^ Noi ricidemmo il cerchio a l’altra riva $',\n",
              " '^ sovr’ una fonte che bolle e riversa $',\n",
              " '^ per un fossato che da lei deriva. $',\n",
              " '^ L’acqua era buia assai più che persa; $',\n",
              " '^ e noi, in compagnia de l’onde bige, $',\n",
              " '^ intrammo giù per una via diversa. $',\n",
              " '^ In la palude va c’ha nome Stige $',\n",
              " '^ questo tristo ruscel, quand’ è disceso $',\n",
              " '^ al piè de le maligne piagge grige. $',\n",
              " '^ E io, che di mirare stava inteso, $',\n",
              " '^ vidi genti fangose in quel pantano, $',\n",
              " '^ ignude tutte, con sembiante offeso. $',\n",
              " '^ Queste si percotean non pur con mano, $',\n",
              " '^ ma con la testa e col petto e coi piedi, $',\n",
              " '^ troncandosi co’ denti a brano a brano. $',\n",
              " '^ Lo buon maestro disse: «Figlio, or vedi $',\n",
              " '^ l’anime di color cui vinse l’ira; $',\n",
              " '^ e anche vo’ che tu per certo credi $',\n",
              " '^ che sotto l’acqua è gente che sospira, $',\n",
              " '^ e fanno pullular quest’ acqua al summo, $',\n",
              " '^ come l’occhio ti dice, u’ che s’aggira. $',\n",
              " '^ Fitti nel limo dicon: “Tristi fummo $',\n",
              " '^ ne l’aere dolce che dal sol s’allegra, $',\n",
              " '^ portando dentro accidïoso fummo: $',\n",
              " '^ or ci attristiam ne la belletta negra”. $',\n",
              " '^ Quest’ inno si gorgoglian ne la strozza, $',\n",
              " '^ ché dir nol posson con parola integra». $',\n",
              " '^ Così girammo de la lorda pozza $',\n",
              " '^ grand’ arco tra la ripa secca e ’l mézzo, $',\n",
              " '^ con li occhi vòlti a chi del fango ingozza. $',\n",
              " '^ Venimmo al piè d’una torre al da sezzo. $',\n",
              " '^ Io dico, seguitando, ch’assai prima $',\n",
              " '^ che noi fossimo al piè de l’alta torre, $',\n",
              " '^ li occhi nostri n’andar suso a la cima $',\n",
              " '^ per due fiammette che i vedemmo porre, $',\n",
              " '^ e un’altra da lungi render cenno, $',\n",
              " '^ tanto ch’a pena il potea l’occhio tòrre. $',\n",
              " '^ E io mi volsi al mar di tutto ’l senno; $',\n",
              " '^ dissi: «Questo che dice? e che risponde $',\n",
              " '^ quell’ altro foco? e chi son quei che ’l fenno?». $',\n",
              " '^ Ed elli a me: «Su per le sucide onde $',\n",
              " '^ già scorgere puoi quello che s’aspetta, $',\n",
              " '^ se ’l fummo del pantan nol ti nasconde». $',\n",
              " '^ Corda non pinse mai da sé saetta $',\n",
              " '^ che sì corresse via per l’aere snella, $',\n",
              " '^ com’ io vidi una nave piccioletta $',\n",
              " '^ venir per l’acqua verso noi in quella, $',\n",
              " '^ sotto ’l governo d’un sol galeoto, $',\n",
              " '^ che gridava: «Or se’ giunta, anima fella!». $',\n",
              " '^ «Flegïàs, Flegïàs, tu gridi a vòto», $',\n",
              " '^ disse lo mio segnore, «a questa volta: $',\n",
              " '^ più non ci avrai che sol passando il loto». $',\n",
              " '^ Qual è colui che grande inganno ascolta $',\n",
              " '^ che li sia fatto, e poi se ne rammarca, $',\n",
              " '^ fecesi Flegïàs ne l’ira accolta. $',\n",
              " '^ Lo duca mio discese ne la barca, $',\n",
              " '^ e poi mi fece intrare appresso lui; $',\n",
              " '^ e sol quand’ io fui dentro parve carca. $',\n",
              " '^ Tosto che ’l duca e io nel legno fui, $',\n",
              " '^ segando se ne va l’antica prora $',\n",
              " '^ de l’acqua più che non suol con altrui. $',\n",
              " '^ Mentre noi corravam la morta gora, $',\n",
              " '^ dinanzi mi si fece un pien di fango, $',\n",
              " '^ e disse: «Chi se’ tu che vieni anzi ora?». $',\n",
              " '^ E io a lui: «S’i’ vegno, non rimango; $',\n",
              " '^ ma tu chi se’, che sì se’ fatto brutto?». $',\n",
              " '^ Rispuose: «Vedi che son un che piango». $',\n",
              " '^ E io a lui: «Con piangere e con lutto, $',\n",
              " '^ spirito maladetto, ti rimani; $',\n",
              " '^ ch’i’ ti conosco, ancor sie lordo tutto». $',\n",
              " '^ Allor distese al legno ambo le mani; $',\n",
              " '^ per che ’l maestro accorto lo sospinse, $',\n",
              " '^ dicendo: «Via costà con li altri cani!». $',\n",
              " '^ Lo collo poi con le braccia mi cinse; $',\n",
              " '^ basciommi ’l volto e disse: «Alma sdegnosa, $',\n",
              " '^ benedetta colei che ’n te s’incinse! $',\n",
              " '^ Quei fu al mondo persona orgogliosa; $',\n",
              " '^ bontà non è che sua memoria fregi: $',\n",
              " '^ così s’è l’ombra sua qui furïosa. $',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "gradient": {},
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "cXfpaCecVIfd"
      },
      "source": [
        "target_text_prepr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "XLL3lSlvVIfe"
      },
      "source": [
        "input_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\", lower=False, oov_token='<UNK>')\n",
        "input_tokenizer.fit_on_texts(input_text_prepr)\n",
        "\n",
        "input_text_lines_enc = input_tokenizer.texts_to_sequences(input_text_prepr)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzjoJiDwm-X2",
        "outputId": "dfda5bef-fd69-4022-cd21-d785551d6e9f"
      },
      "source": [
        "input_text_lines_enc"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 796, 229, 25, 620, 7, 194, 179, 3],\n",
              " [2, 16, 6277, 10, 98, 657, 6278, 3],\n",
              " [2, 59, 6, 6279, 197, 54, 3656, 3],\n",
              " [2, 621, 87, 8, 203, 58, 54, 21, 204, 1100, 3],\n",
              " [2, 1421, 657, 2013, 4, 3657, 4, 344, 3],\n",
              " [2, 5, 35, 413, 3658, 6, 6280, 3],\n",
              " [2, 2590, 21, 3659, 5, 103, 21, 19, 2591, 3],\n",
              " [2, 33, 10, 6281, 25, 63, 80, 138, 6282, 3],\n",
              " [2, 1101, 22, 268, 205, 80, 6283, 6284, 3],\n",
              " [2, 99, 9, 365, 63, 3660, 69, 323, 6285, 3],\n",
              " [2, 1669, 54, 658, 7, 622, 8, 34, 275, 3],\n",
              " [2, 5, 6, 706, 197, 6286, 3],\n",
              " [2, 77, 52, 80, 149, 28, 186, 154, 2014, 2015, 3],\n",
              " [2, 42, 90, 6287, 50, 414, 3],\n",
              " [2, 5, 430, 7, 482, 18, 345, 2016, 3],\n",
              " [2, 3661, 11, 331, 4, 78, 14, 167, 975, 3],\n",
              " [2, 3662, 43, 185, 483, 25, 6288, 3],\n",
              " [2, 5, 875, 535, 360, 10, 112, 2017, 3],\n",
              " [2, 366, 41, 6, 482, 36, 103, 1670, 3],\n",
              " [2, 5, 35, 2592, 25, 345, 431, 6289, 3],\n",
              " [2, 6, 396, 80, 3663, 20, 299, 6290, 3],\n",
              " [2, 30, 24, 128, 5, 20, 2593, 6291, 3],\n",
              " [2, 6292, 85, 25, 3664, 8, 6, 1671, 3],\n",
              " [2, 12, 797, 8, 307, 6293, 4, 6294, 3],\n",
              " [2, 51, 659, 199, 876, 6295, 3],\n",
              " [2, 12, 308, 8, 313, 8, 2594, 27, 397, 3],\n",
              " [2, 5, 9, 660, 43, 92, 415, 1672, 3],\n",
              " [2, 158, 6296, 3665, 36, 103, 18, 256, 1251, 3],\n",
              " [2, 6297, 197, 10, 6, 2595, 3666, 3],\n",
              " [2, 17, 5, 13, 186, 1673, 171, 54, 13, 19, 2596, 3],\n",
              " [2, 164, 2597, 221, 28, 976, 22, 3667, 3],\n",
              " [2, 98, 3668, 3669, 4, 1674, 1422, 3],\n",
              " [2, 5, 7, 1252, 6298, 54, 6299, 3],\n",
              " [2, 4, 9, 16, 12, 6300, 210, 28, 977, 3],\n",
              " [2, 447, 6301, 49, 18, 45, 1423, 3],\n",
              " [2, 80, 149, 10, 2598, 19, 289, 2599, 3],\n",
              " [2, 3670, 54, 64, 507, 25, 2600, 3],\n",
              " [2, 4, 13, 127, 6302, 119, 104, 20, 187, 536, 3],\n",
              " [2, 877, 20, 70, 46, 623, 978, 3],\n",
              " [2, 432, 7, 83, 187, 205, 3671, 3],\n",
              " [2, 17, 100, 213, 3672, 431, 979, 3],\n",
              " [2, 7, 50, 624, 8, 6, 6303, 1102, 3],\n",
              " [2, 625, 25, 150, 4, 6, 133, 6304, 3],\n",
              " [2, 33, 9, 17, 5, 482, 9, 16, 3673, 3],\n",
              " [2, 6, 208, 5, 1424, 154, 6305, 3],\n",
              " [2, 561, 237, 5, 314, 47, 2018, 3],\n",
              " [2, 20, 6, 6306, 2019, 4, 20, 6307, 2020, 3],\n",
              " [2, 17, 5, 237, 5, 300, 32, 6308, 3],\n",
              " [2, 164, 98, 3674, 5, 7, 153, 3675, 3],\n",
              " [2, 1675, 2601, 32, 6, 38, 6309, 3],\n",
              " [2, 4, 484, 346, 135, 43, 707, 6310, 3],\n",
              " [2, 81, 16, 2602, 49, 7, 3676, 3],\n",
              " [2, 20, 6, 482, 6311, 7, 38, 626, 3],\n",
              " [2, 48, 2021, 6, 627, 22, 6312, 3],\n",
              " [2, 30, 58, 21, 128, 5, 2603, 2022, 3],\n",
              " [2, 4, 2604, 13, 150, 5, 1103, 27, 2605, 3],\n",
              " [2, 5, 119, 124, 155, 413, 1104, 4, 6313, 3],\n",
              " [2, 88, 16, 143, 6, 1105, 86, 1676, 3],\n",
              " [2, 93, 6314, 6315, 8, 103, 8, 103, 3],\n",
              " [2, 16, 6316, 42, 90, 13, 127, 2023, 3],\n",
              " [2, 708, 80, 6317, 11, 661, 1106, 3],\n",
              " [2, 210, 8, 15, 53, 16, 12, 41, 3677, 3],\n",
              " [2, 62, 10, 367, 1425, 237, 3678, 3],\n",
              " [2, 282, 78, 416, 35, 117, 3679, 3],\n",
              " [2, 6318, 7, 6319, 3680, 8, 238, 3],\n",
              " [2, 3681, 5, 29, 6320, 2024, 709, 2024, 980, 6321, 3],\n",
              " [2, 3682, 485, 3683, 980, 43, 486, 3],\n",
              " [2, 4, 15, 2606, 165, 417, 6322, 3],\n",
              " [2, 6323, 10, 3684, 6324, 3],\n",
              " [2, 6325, 6326, 6327, 94, 5, 172, 3685, 3],\n",
              " [2, 4, 6328, 8, 710, 118, 13, 1107, 6329, 3],\n",
              " [2, 35, 150, 22, 15, 3686, 3687, 4, 6330, 3],\n",
              " [2, 6331, 486, 4, 3688, 7, 34, 562, 3],\n",
              " [2, 2025, 3689, 5, 379, 7, 6332, 3],\n",
              " [2, 52, 5, 13, 2607, 6333, 41, 6334, 3],\n",
              " [2, 77, 29, 60, 3690, 8, 299, 6335, 3],\n",
              " [2, 60, 9, 6336, 18, 6337, 250, 3],\n",
              " [2, 140, 507, 4, 332, 7, 159, 6338, 3],\n",
              " [2, 347, 156, 29, 34, 433, 4, 50, 981, 3],\n",
              " [2, 5, 6339, 7, 257, 17, 2026, 6340, 3],\n",
              " [2, 741, 26, 70, 20, 6341, 1253, 3],\n",
              " [2, 137, 22, 15, 120, 2608, 1677, 4, 982, 3],\n",
              " [2, 6342, 13, 367, 2027, 4, 13, 290, 336, 3],\n",
              " [2, 5, 508, 168, 2609, 27, 105, 6343, 3],\n",
              " [2, 291, 156, 27, 45, 209, 4, 13, 45, 3691, 3],\n",
              " [2, 29, 156, 283, 115, 23, 742, 26, 6344, 3],\n",
              " [2, 27, 878, 3692, 5, 508, 168, 6345, 3],\n",
              " [2, 509, 6, 1105, 10, 742, 26, 16, 6346, 3],\n",
              " [2, 6347, 23, 466, 6348, 6349, 3],\n",
              " [2, 711, 16, 66, 2028, 14, 2029, 4, 40, 6350, 3],\n",
              " [2, 983, 97, 195, 3693, 130, 3694, 3],\n",
              " [2, 586, 52, 5, 1678, 16, 2610, 3],\n",
              " [2, 984, 434, 3695, 798, 160, 6351, 3],\n",
              " [2, 59, 81, 2611, 10, 6, 58, 29, 6352, 3],\n",
              " [2, 9, 510, 360, 1679, 10, 6, 38, 662, 3],\n",
              " [2, 33, 49, 27, 6353, 5, 6354, 3],\n",
              " [2, 4, 113, 224, 17, 2030, 4, 3696, 3],\n",
              " [2, 5, 92, 9, 6355, 6, 6356, 1426, 3],\n",
              " [2, 4, 418, 13, 1254, 113, 19, 879, 5, 2031, 3],\n",
              " [2, 1680, 44, 15, 3697, 8, 68, 6357, 3],\n",
              " [2, 4, 19, 1108, 799, 587, 5, 13, 6358, 3],\n",
              " [2, 6359, 5, 6, 663, 1427, 20, 6360, 3],\n",
              " [2, 561, 9, 6361, 102, 74, 6362, 3],\n",
              " [2, 33, 3698, 336, 4, 2612, 3],\n",
              " [2, 4, 38, 6363, 368, 89, 6364, 4, 6365, 3],\n",
              " [2, 222, 50, 2613, 1428, 206, 1429, 3],\n",
              " [2, 10, 68, 1681, 6, 1682, 6366, 3],\n",
              " [2, 6367, 4, 6368, 4, 6369, 7, 6370, 3],\n",
              " [2, 561, 6, 2614, 10, 112, 3699, 3],\n",
              " [2, 309, 5, 6371, 6372, 32, 27, 3700, 3],\n",
              " [2, 42, 91, 2615, 83, 6373, 3],\n",
              " [2, 301, 26, 10, 27, 105, 3701, 6374, 4, 1255, 3],\n",
              " [2, 5, 29, 16, 6375, 4, 26, 1256, 101, 1683, 3],\n",
              " [2, 4, 6376, 7, 72, 10, 160, 3702, 3],\n",
              " [2, 214, 2032, 14, 6377, 3703, 3],\n",
              " [2, 369, 15, 1684, 563, 3704, 3],\n",
              " [2, 100, 6, 985, 419, 183, 3705, 3],\n",
              " [2, 4, 1430, 230, 5, 44, 1431, 3],\n",
              " [2, 35, 986, 60, 6378, 7, 743, 3],\n",
              " [2, 46, 5, 177, 8, 14, 6379, 2616, 3],\n",
              " [2, 348, 14, 467, 52, 31, 29, 6380, 6381, 3],\n",
              " [2, 398, 206, 8, 75, 19, 7, 47, 6382, 3],\n",
              " [2, 20, 141, 37, 2617, 35, 45, 6383, 3],\n",
              " [2, 59, 215, 3706, 5, 42, 104, 6384, 3],\n",
              " [2, 239, 323, 448, 6385, 8, 6, 38, 1432, 3],\n",
              " [2, 9, 435, 5, 119, 38, 588, 10, 47, 12, 6386, 3],\n",
              " [2, 511, 153, 664, 3707, 4, 200, 6387, 3],\n",
              " [2, 200, 21, 6, 38, 588, 4, 292, 6388, 3],\n",
              " [2, 880, 2618, 115, 742, 665, 6389, 3],\n",
              " [2, 30, 26, 8, 315, 3708, 26, 37, 6390, 3],\n",
              " [2, 10, 215, 116, 5, 29, 9, 6391, 3],\n",
              " [2, 881, 48, 6392, 73, 882, 4, 2619, 3],\n",
              " [2, 5, 29, 16, 6393, 42, 251, 136, 6394, 3],\n",
              " [2, 17, 48, 1433, 6, 337, 7, 3709, 589, 3],\n",
              " [2, 4, 230, 68, 29, 800, 436, 6395, 3],\n",
              " [2, 366, 12, 744, 4, 26, 15, 2620, 6396, 3],\n",
              " [2, 174, 487, 31, 6397, 4, 300, 2621, 3],\n",
              " [2, 3710, 15, 6398, 5, 211, 11, 102, 3],\n",
              " [2, 23, 14, 6399, 3711, 4, 26, 127, 338, 3],\n",
              " [2, 6400, 8, 2033, 6, 987, 3],\n",
              " [2, 17, 25, 988, 4, 17, 22, 6, 3712, 3],\n",
              " [2, 5, 6401, 6, 142, 5, 9, 6402, 3],\n",
              " [2, 258, 2622, 56, 331, 1685, 136, 6403, 3],\n",
              " [2, 56, 142, 5, 6404, 75, 48, 745, 3],\n",
              " [2, 72, 12, 2034, 6, 101, 6405, 3],\n",
              " [2, 99, 666, 6406, 5, 16, 6407, 3],\n",
              " [2, 420, 6, 61, 201, 6408, 21, 2623, 3],\n",
              " [2, 83, 100, 292, 397, 29, 16, 6409, 3],\n",
              " [2, 291, 3713, 5, 7, 6410, 18, 3714, 3],\n",
              " [2, 6411, 799, 76, 6412, 3],\n",
              " [2, 6413, 6414, 4, 41, 6415, 3],\n",
              " [2, 989, 31, 6416, 225, 882, 3],\n",
              " [2, 1109, 40, 746, 1257, 292, 1434, 3],\n",
              " [2, 3715, 990, 7, 238, 4, 13, 62, 4, 13, 231, 3],\n",
              " [2, 9, 628, 6417, 76, 980, 6418, 3],\n",
              " [2, 512, 41, 22, 1435, 710, 4, 7, 39, 6419, 3],\n",
              " [2, 32, 6420, 126, 10, 310, 6421, 3],\n",
              " [2, 6, 231, 4, 13, 2624, 8, 269, 203, 27, 991, 3],\n",
              " [2, 41, 6422, 10, 27, 160, 449, 3],\n",
              " [2, 667, 668, 18, 2035, 25, 252, 6423, 3],\n",
              " [2, 232, 437, 6424, 91, 15, 1686, 29, 6425, 3],\n",
              " [2, 3716, 205, 5, 417, 979, 3],\n",
              " [2, 7, 38, 2036, 4, 25, 6426, 6427, 3],\n",
              " [2, 6428, 52, 27, 6429, 6430, 3],\n",
              " [2, 10, 6431, 2037, 8, 50, 361, 3],\n",
              " [2, 140, 507, 8, 6, 197, 7, 6432, 3],\n",
              " [2, 77, 131, 60, 6433, 56, 62, 13, 6434, 3],\n",
              " [2, 99, 9, 6435, 26, 9, 6436, 2625, 3],\n",
              " [2, 47, 992, 8, 75, 74, 26, 74, 120, 13, 3717, 3],\n",
              " [2, 232, 93, 31, 25, 743, 26, 6437, 3],\n",
              " [2, 883, 5, 6, 2038, 9, 177, 6438, 3],\n",
              " [2, 3718, 6439, 1687, 3701, 80, 9, 6440, 3],\n",
              " [2, 30, 58, 21, 128, 5, 6441, 75, 5, 669, 3],\n",
              " [2, 4, 10, 1436, 413, 3719, 6442, 3],\n",
              " [2, 17, 5, 64, 976, 65, 12, 3720, 3],\n",
              " [2, 88, 16, 590, 380, 119, 50, 2626, 1110, 3],\n",
              " [2, 1437, 2039, 6443, 6, 3721, 3],\n",
              " [2, 5, 41, 35, 976, 436, 3722, 3],\n",
              " [2, 2040, 450, 63, 6, 629, 101, 6444, 3],\n",
              " [2, 370, 25, 6445, 228, 3723, 3],\n",
              " [2, 6446, 101, 21, 23, 3724, 6447, 3],\n",
              " [2, 6, 58, 484, 801, 993, 6448, 3],\n",
              " [2, 17, 5, 6449, 3725, 27, 3726, 3],\n",
              " [2, 24, 1438, 114, 1105, 233, 6450, 3],\n",
              " [2, 381, 81, 994, 881, 5, 29, 37, 6451, 3],\n",
              " [2, 3727, 239, 26, 747, 4, 34, 48, 3728, 3],\n",
              " [2, 35, 178, 275, 5, 7, 97, 16, 6452, 3],\n",
              " [2, 99, 54, 89, 230, 5, 44, 3729, 3],\n",
              " [2, 4, 180, 16, 2627, 884, 4, 1258, 3],\n",
              " [2, 88, 5, 7, 6453, 26, 6, 6454, 3],\n",
              " [2, 6455, 15, 53, 155, 19, 5, 6, 2628, 3],\n",
              " [2, 4, 6456, 8, 203, 1439, 4, 6457, 3],\n",
              " [2, 20, 6458, 1688, 11, 38, 2629, 3],\n",
              " [2, 1689, 398, 1109, 3730, 3],\n",
              " [2, 7, 68, 6, 670, 94, 35, 95, 1259, 3],\n",
              " [2, 4, 3731, 87, 13, 95, 3732, 3],\n",
              " [2, 3733, 199, 4, 9, 22, 6, 6459, 3],\n",
              " [2, 32, 6, 3734, 2595, 21, 2041, 3],\n",
              " [2, 17, 35, 3735, 5, 6460, 21, 10, 2042, 3],\n",
              " [2, 4, 883, 5, 9, 177, 43, 17, 2630, 3],\n",
              " [2, 48, 16, 177, 885, 28, 3736, 6461, 3],\n",
              " [2, 10, 34, 80, 450, 7, 70, 35, 276, 6462, 3],\n",
              " [2, 240, 6463, 4, 20, 6, 101, 629, 6464, 3],\n",
              " [2, 4, 20, 75, 382, 6465, 28, 39, 6466, 3],\n",
              " [2, 6467, 17, 80, 32, 177, 6468, 3],\n",
              " [2, 488, 44, 399, 5, 37, 6469, 6470, 3],\n",
              " [2, 2043, 25, 160, 214, 591, 2631, 3],\n",
              " [2, 245, 16, 744, 5, 16, 66, 6471, 3],\n",
              " [2, 282, 1256, 210, 28, 748, 199, 3],\n",
              " [2, 7, 97, 16, 6472, 2044, 8, 6473, 3],\n",
              " [2, 6474, 1440, 4, 52, 1441, 324, 3],\n",
              " [2, 1689, 180, 7, 201, 451, 10, 68, 3],\n",
              " [2, 564, 3737, 6475, 112, 1690, 3],\n",
              " [2, 7, 34, 126, 382, 802, 15, 712, 6476, 3],\n",
              " [2, 49, 6477, 18, 105, 6478, 3],\n",
              " [2, 5, 6479, 31, 43, 592, 400, 6480, 3],\n",
              " [2, 19, 9, 995, 6481, 6482, 18, 105, 3738, 3],\n",
              " [2, 77, 565, 6, 332, 5, 9, 37, 1691, 3],\n",
              " [2, 22, 27, 886, 139, 468, 11, 73, 1111, 3],\n",
              " [2, 22, 3739, 160, 214, 591, 29, 6483, 3],\n",
              " [2, 6484, 5, 29, 434, 1692, 436, 8, 2045, 3],\n",
              " [2, 3727, 6485, 16, 586, 3],\n",
              " [2, 6486, 323, 9, 883, 7, 401, 139, 3740, 3],\n",
              " [2, 6487, 12, 749, 7, 270, 187, 205, 3],\n",
              " [2, 803, 996, 7, 421, 360, 6488, 3],\n",
              " [2, 22, 268, 2632, 59, 9, 44, 6489, 3],\n",
              " [2, 488, 44, 438, 23, 489, 38, 6490, 2633, 3],\n",
              " [2, 5, 6, 277, 1693, 9, 16, 6491, 3],\n",
              " [2, 74, 316, 798, 2046, 9, 6492, 3],\n",
              " [2, 3741, 21, 1442, 35, 126, 5, 12, 6493, 3],\n",
              " [2, 7, 73, 6494, 371, 26, 37, 6495, 3],\n",
              " [2, 17, 5, 887, 997, 42, 104, 6496, 3],\n",
              " [2, 888, 1694, 6497, 11, 39, 3742, 3],\n",
              " [2, 4, 6498, 113, 3743, 18, 105, 2634, 3],\n",
              " [2, 7, 593, 4, 26, 8, 97, 27, 6499, 3],\n",
              " [2, 3744, 2047, 7, 183, 3745, 3],\n",
              " [2, 12, 744, 4, 379, 28, 160, 251, 323, 713, 3],\n",
              " [2, 5, 16, 2048, 20, 1260, 6500, 3],\n",
              " [2, 6501, 6502, 7, 116, 1261, 3],\n",
              " [2, 59, 9, 6503, 128, 5, 6504, 490, 3],\n",
              " [2, 3746, 10, 97, 22, 6, 6505, 6506, 3],\n",
              " [2, 132, 2049, 29, 6, 3747, 25, 39, 2635, 3],\n",
              " [2, 9, 202, 29, 6, 419, 5, 13, 6507, 3],\n",
              " [2, 84, 6, 2636, 214, 13, 439, 9, 113, 6508, 3],\n",
              " [2, 1695, 95, 9, 513, 92, 1443, 6509, 3],\n",
              " [2, 8, 144, 55, 2637, 56, 8, 998, 55, 3748, 3],\n",
              " [2, 69, 131, 418, 1262, 175, 6510, 3],\n",
              " [2, 747, 139, 79, 25, 45, 750, 6511, 3],\n",
              " [2, 3749, 25, 105, 630, 3750, 3],\n",
              " [2, 6512, 97, 4, 128, 3751, 6513, 3],\n",
              " [2, 349, 5, 2050, 3752, 999, 3],\n",
              " [2, 15, 53, 2638, 3753, 1696, 3],\n",
              " [2, 10, 5, 16, 143, 25, 401, 19, 2639, 3],\n",
              " [2, 30, 747, 8, 97, 51, 69, 242, 3754, 3],\n",
              " [2, 6514, 8, 50, 624, 37, 1112, 3],\n",
              " [2, 5, 25, 491, 250, 18, 1000, 452, 37, 6515, 3],\n",
              " [2, 6516, 5, 3755, 1437, 60, 6517, 3],\n",
              " [2, 60, 299, 2051, 35, 714, 6518, 3],\n",
              " [2, 60, 3756, 4, 6519, 9, 2052, 3],\n",
              " [2, 219, 5, 804, 161, 751, 3757, 3],\n",
              " [2, 6520, 7, 97, 32, 6, 805, 25, 514, 3],\n",
              " [2, 4, 13, 45, 257, 49, 63, 37, 6521, 3],\n",
              " [2, 806, 2053, 64, 3758, 2054, 3],\n",
              " [2, 3759, 4, 3760, 52, 5, 13, 127, 15, 6522, 3],\n",
              " [2, 12, 2640, 124, 3761, 11, 220, 6523, 3],\n",
              " [2, 88, 16, 590, 26, 7, 61, 6524, 6525, 3],\n",
              " [2, 4, 49, 1107, 3756, 28, 345, 16, 3762, 3],\n",
              " [2, 80, 2641, 24, 415, 6526, 3],\n",
              " [2, 2055, 6527, 566, 5, 16, 6528, 3],\n",
              " [2, 4, 97, 1109, 6529, 181, 3],\n",
              " [2, 8, 14, 1444, 175, 5, 37, 6530, 3],\n",
              " [2, 291, 1001, 20, 3763, 18, 345, 1113, 3],\n",
              " [2, 17, 28, 401, 20, 14, 175, 3764, 3],\n",
              " [2, 80, 44, 2056, 35, 178, 6531, 3],\n",
              " [2, 240, 752, 631, 127, 1114, 21, 6532, 3],\n",
              " [2, 29, 715, 29, 3765, 4, 29, 6533, 3],\n",
              " [2, 146, 15, 6534, 4, 52, 5, 1697, 2057, 3],\n",
              " [2, 3766, 10, 27, 988, 331, 4, 6535, 3],\n",
              " [2, 3767, 47, 12, 188, 32, 6, 588, 1698, 3],\n",
              " [2, 10, 47, 12, 188, 32, 402, 2642, 3],\n",
              " [2, 10, 47, 12, 188, 89, 6, 3768, 1445, 3],\n",
              " [2, 6536, 432, 18, 45, 331, 6537, 3],\n",
              " [2, 3769, 6, 372, 6538, 3],\n",
              " [2, 6, 1115, 2643, 4, 13, 178, 1263, 3],\n",
              " [2, 1699, 8, 47, 9, 85, 205, 3770, 3],\n",
              " [2, 31, 9, 2058, 4, 26, 671, 6539, 3],\n",
              " [2, 6540, 112, 2644, 125, 6541, 3],\n",
              " [2, 1116, 175, 7, 1264, 6542, 3],\n",
              " [2, 243, 380, 6543, 28, 350, 383, 6544, 3],\n",
              " [2, 10, 2645, 492, 18, 1446, 55, 400, 6545, 3],\n",
              " [2, 164, 121, 8, 284, 24, 415, 6546, 3],\n",
              " [2, 889, 12, 195, 3771, 112, 3772, 3],\n",
              " [2, 112, 2051, 195, 5, 72, 177, 6547, 3],\n",
              " [2, 253, 1002, 3773, 28, 160, 371, 323, 1117, 515, 3],\n",
              " [2, 5, 29, 369, 14, 346, 6548, 3],\n",
              " [2, 803, 2646, 18, 63, 22, 6549, 3],\n",
              " [2, 30, 52, 5, 6, 38, 469, 8, 6, 61, 753, 3],\n",
              " [2, 20, 890, 977, 122, 26, 16, 6550, 3],\n",
              " [2, 16, 807, 110, 8, 14, 6551, 2647, 3],\n",
              " [2, 493, 1700, 3774, 4, 754, 3775, 3],\n",
              " [2, 6552, 10, 300, 86, 2059, 3],\n",
              " [2, 10, 48, 28, 976, 32, 6553, 3],\n",
              " [2, 3776, 3777, 2648, 2649, 3],\n",
              " [2, 175, 7, 2642, 6554, 3778, 3],\n",
              " [2, 808, 1265, 4, 3779, 4, 594, 7, 259, 20, 3780, 3],\n",
              " [2, 6555, 36, 6556, 18, 58, 6557, 3],\n",
              " [2, 171, 11, 228, 6558, 86, 150, 3781, 3],\n",
              " [2, 24, 6, 1118, 46, 2650, 2651, 3],\n",
              " [2, 30, 26, 632, 6559, 6, 384, 3782, 3],\n",
              " [2, 440, 492, 5, 21, 34, 80, 6560, 3],\n",
              " [2, 4, 5, 3783, 21, 5, 191, 35, 755, 17, 6561, 3],\n",
              " [2, 164, 121, 8, 184, 1447, 1448, 302, 3],\n",
              " [2, 3784, 567, 1701, 7, 2060, 3],\n",
              " [2, 5, 6562, 86, 6563, 4, 86, 6564, 3],\n",
              " [2, 6565, 211, 8, 34, 6566, 1449, 3],\n",
              " [2, 22, 15, 809, 5, 9, 417, 6567, 3],\n",
              " [2, 74, 513, 6568, 8, 489, 33, 10, 57, 2652, 3],\n",
              " [2, 6569, 40, 126, 10, 9, 82, 176, 3785, 3],\n",
              " [2, 74, 27, 1450, 2061, 15, 3786, 3],\n",
              " [2, 1702, 516, 40, 2653, 3787, 6570, 3],\n",
              " [2, 30, 324, 492, 5, 21, 49, 2062, 3],\n",
              " [2, 8, 55, 5, 6571, 15, 66, 17, 6572, 3],\n",
              " [2, 2063, 6573, 351, 6574, 3],\n",
              " [2, 561, 9, 385, 627, 7, 891, 3],\n",
              " [2, 4, 6, 55, 2654, 179, 21, 49, 6575, 3],\n",
              " [2, 5, 6576, 44, 225, 246, 3788, 3],\n",
              " [2, 6577, 7, 220, 18, 95, 82, 9, 6578, 3],\n",
              " [2, 2655, 4, 352, 15, 6579, 3],\n",
              " [2, 9, 3789, 7, 1003, 33, 420, 4, 6580, 3],\n",
              " [2, 30, 131, 5, 6581, 78, 98, 3790, 3],\n",
              " [2, 5, 1451, 3791, 49, 6582, 3],\n",
              " [2, 5, 225, 1266, 16, 237, 6583, 3],\n",
              " [2, 4, 134, 14, 716, 17, 403, 2064, 3],\n",
              " [2, 7, 1703, 80, 9, 6584, 6585, 3],\n",
              " [2, 5, 419, 299, 6586, 6587, 3],\n",
              " [2, 349, 48, 6588, 234, 6589, 3],\n",
              " [2, 78, 4, 892, 333, 7, 115, 3],\n",
              " [2, 5, 143, 10, 3724, 18, 117, 6590, 3],\n",
              " [2, 6591, 2656, 4, 422, 149, 3],\n",
              " [2, 5, 81, 54, 6, 3792, 163, 6592, 3],\n",
              " [2, 8, 116, 6593, 4, 147, 1704, 2657, 3],\n",
              " [2, 561, 6594, 5, 92, 9, 513, 2065, 3],\n",
              " [2, 893, 3793, 4, 6595, 351, 3],\n",
              " [2, 23, 6596, 4, 23, 6597, 877, 6598, 3],\n",
              " [2, 3794, 6599, 55, 7, 271, 18, 977, 3],\n",
              " [2, 93, 6600, 7, 3795, 147, 55, 404, 3],\n",
              " [2, 23, 6601, 3796, 54, 2658, 3],\n",
              " [2, 30, 52, 100, 633, 373, 16, 3797, 3],\n",
              " [2, 78, 346, 8, 6, 494, 154, 117, 6602, 3],\n",
              " [2, 10, 48, 440, 492, 136, 16, 6603, 3],\n",
              " [2, 80, 6604, 537, 1705, 4, 58, 2066, 3],\n",
              " [2, 14, 66, 7, 1267, 595, 17, 6605, 3],\n",
              " [2, 69, 323, 1255, 10, 27, 3798, 6606, 3],\n",
              " [2, 164, 121, 8, 184, 1004, 205, 37, 1005, 1119, 3],\n",
              " [2, 46, 67, 6607, 15, 423, 317, 3],\n",
              " [2, 84, 6, 568, 3799, 6608, 3],\n",
              " [2, 366, 20, 15, 53, 6609, 4, 2659, 3],\n",
              " [2, 2067, 1006, 13, 45, 203, 15, 172, 2068, 3],\n",
              " [2, 303, 28, 596, 25, 257, 16, 6610, 3],\n",
              " [2, 164, 517, 226, 67, 401, 10, 1007, 3],\n",
              " [2, 36, 6611, 1120, 10, 2069, 2660, 3],\n",
              " [2, 1268, 6612, 8, 1008, 538, 6613, 3],\n",
              " [2, 132, 6614, 92, 114, 27, 6615, 3],\n",
              " [2, 323, 2043, 10, 6616, 8, 189, 494, 3],\n",
              " [2, 32, 14, 1452, 2058, 11, 539, 4, 119, 3800, 3],\n",
              " [2, 30, 29, 5, 156, 6617, 398, 1453, 3],\n",
              " [2, 6618, 23, 2070, 5, 44, 2661, 3],\n",
              " [2, 77, 52, 5, 353, 48, 9, 16, 6619, 3],\n",
              " [2, 109, 810, 246, 662, 10, 120, 811, 3],\n",
              " [2, 3801, 8, 3802, 9, 1009, 10, 6620, 3],\n",
              " [2, 19, 1121, 597, 195, 5, 37, 6621, 3],\n",
              " [2, 30, 13, 162, 315, 6622, 9, 37, 6623, 3],\n",
              " [2, 2071, 51, 812, 90, 12, 374, 3],\n",
              " [2, 75, 5, 12, 2072, 4, 19, 9, 3803, 3],\n",
              " [2, 1010, 85, 6624, 14, 6625, 2662, 3],\n",
              " [2, 28, 2663, 22, 6, 3804, 3805, 3],\n",
              " [2, 5, 894, 8, 15, 53, 173, 7, 1269, 2664, 3],\n",
              " [2, 77, 228, 6626, 877, 3806, 4, 3807, 3],\n",
              " [2, 6627, 1264, 4, 6628, 40, 1706, 3],\n",
              " [2, 1454, 5, 6629, 14, 175, 6630, 3],\n",
              " [2, 6631, 116, 4, 55, 6632, 3],\n",
              " [2, 564, 3737, 4, 13, 160, 4, 13, 150, 4, 13, 470, 3],\n",
              " [2, 7, 55, 2665, 4, 7, 55, 6633, 3],\n",
              " [2, 158, 12, 6634, 153, 756, 1270, 3],\n",
              " [2, 344, 2666, 8, 6, 494, 2030, 3],\n",
              " [2, 3808, 183, 540, 5, 116, 9, 3809, 3],\n",
              " [2, 3810, 6635, 20, 53, 7, 6636, 3],\n",
              " [2, 220, 3811, 153, 14, 6637, 3],\n",
              " [2, 1271, 106, 3812, 634, 6638, 3],\n",
              " [2, 198, 6639, 12, 3813, 14, 1272, 3],\n",
              " [2, 334, 672, 22, 1455, 309, 5, 13, 1707, 3],\n",
              " [2, 386, 8, 6, 102, 153, 14, 167, 2073, 3],\n",
              " [2, 2667, 18, 151, 470, 3814, 3],\n",
              " [2, 6640, 7, 34, 1273, 76, 98, 76, 2668, 3],\n",
              " [2, 10, 2074, 24, 6641, 10, 39, 3815, 3],\n",
              " [2, 146, 236, 453, 84, 10, 1708, 6642, 3],\n",
              " [2, 4, 1456, 5, 717, 7, 42, 2669, 3],\n",
              " [2, 635, 7, 139, 1709, 813, 6643, 3],\n",
              " [2, 1457, 1011, 192, 13, 209, 6644, 3],\n",
              " [2, 6645, 5, 6646, 32, 1274, 7, 116, 3],\n",
              " [2, 124, 3816, 72, 225, 6647, 3],\n",
              " [2, 4, 6648, 211, 8, 1267, 27, 2075, 3],\n",
              " [2, 59, 6, 372, 352, 15, 6649, 3],\n",
              " [2, 17, 5, 6, 994, 12, 2670, 11, 2076, 3],\n",
              " [2, 1010, 9, 2671, 92, 398, 3817, 3],\n",
              " [2, 4, 1275, 31, 3810, 7, 97, 12, 2672, 3],\n",
              " [2, 63, 387, 2077, 354, 5, 13, 39, 203, 3818, 3],\n",
              " [2, 3819, 999, 6, 2673, 2078, 3],\n",
              " [2, 2079, 17, 673, 5, 22, 27, 3820, 3],\n",
              " [2, 6, 142, 7, 6650, 94, 16, 3821, 3],\n",
              " [2, 148, 102, 6651, 1012, 1122, 3],\n",
              " [2, 5, 6652, 98, 169, 6653, 3],\n",
              " [2, 6, 58, 16, 1123, 183, 6654, 3],\n",
              " [2, 4, 2080, 24, 318, 68, 622, 6655, 3],\n",
              " [2, 6656, 292, 622, 32, 6, 384, 3],\n",
              " [2, 36, 2062, 6657, 17, 48, 16, 3822, 3],\n",
              " [2, 24, 415, 140, 10, 471, 6658, 3],\n",
              " [2, 4, 254, 3823, 278, 3824, 3],\n",
              " [2, 535, 3825, 4, 2081, 6659, 3],\n",
              " [2, 10, 2082, 27, 160, 251, 26, 6660, 3],\n",
              " [2, 1710, 21, 5, 119, 84, 6, 1458, 16, 1711, 3],\n",
              " [2, 22, 6, 414, 3826, 1712, 3],\n",
              " [2, 5, 6661, 2674, 6662, 6663, 3],\n",
              " [2, 6664, 4, 895, 54, 4, 6665, 3],\n",
              " [2, 49, 93, 10, 3827, 27, 152, 8, 1013, 3],\n",
              " [2, 26, 9, 138, 6666, 375, 6667, 3],\n",
              " [2, 347, 6668, 139, 79, 35, 1276, 6669, 3],\n",
              " [2, 293, 18, 896, 65, 6670, 3],\n",
              " [2, 454, 1256, 1277, 4, 29, 757, 3828, 3],\n",
              " [2, 30, 131, 5, 25, 230, 16, 149, 3829, 3],\n",
              " [2, 440, 2083, 6671, 31, 29, 6672, 3],\n",
              " [2, 5, 6673, 28, 45, 6674, 82, 6675, 3],\n",
              " [2, 164, 121, 8, 184, 3830, 22, 14, 346, 3],\n",
              " [2, 5, 44, 139, 598, 35, 152, 16, 2084, 3],\n",
              " [2, 50, 718, 5, 29, 10, 994, 6676, 3],\n",
              " [2, 6677, 59, 6, 197, 403, 32, 6678, 3],\n",
              " [2, 146, 12, 807, 4, 51, 16, 135, 2675, 3],\n",
              " [2, 35, 178, 294, 5, 2085, 6679, 3],\n",
              " [2, 6680, 272, 5, 10, 6681, 3],\n",
              " [2, 9, 173, 814, 92, 5, 7, 1459, 3],\n",
              " [2, 5, 897, 1124, 1713, 6682, 3],\n",
              " [2, 75, 6683, 7, 755, 86, 2676, 3],\n",
              " [2, 6684, 14, 6685, 877, 484, 4, 6686, 3],\n",
              " [2, 6687, 4, 7, 2086, 4, 7, 6688, 3],\n",
              " [2, 174, 190, 209, 8, 184, 636, 9, 2087, 3],\n",
              " [2, 5, 563, 44, 182, 5, 29, 6689, 3],\n",
              " [2, 240, 569, 5, 6690, 285, 5, 19, 6691, 3],\n",
              " [2, 599, 9, 6692, 4, 1125, 385, 6693, 3],\n",
              " [2, 9, 6694, 60, 9, 1714, 6695, 3],\n",
              " [2, 140, 337, 22, 6, 361, 5, 29, 2677, 3],\n",
              " [2, 4, 2088, 417, 210, 28, 6696, 3],\n",
              " [2, 9, 6697, 6698, 8, 2089, 3],\n",
              " [2, 4, 7, 182, 1262, 44, 26, 6699, 3],\n",
              " [2, 232, 804, 6700, 9, 10, 130, 2075, 3],\n",
              " [2, 2678, 6701, 4, 127, 7, 49, 6702, 3],\n",
              " [2, 5, 86, 3831, 6703, 11, 3832, 3],\n",
              " [2, 6704, 755, 16, 518, 28, 345, 46, 27, 1715, 3],\n",
              " [2, 96, 5, 108, 7, 351, 1460, 3],\n",
              " [2, 892, 5, 119, 34, 3833, 235, 6705, 3],\n",
              " [2, 6706, 209, 199, 1461, 6707, 3],\n",
              " [2, 1441, 26, 10, 269, 82, 422, 3],\n",
              " [2, 7, 50, 361, 5, 898, 112, 6708, 3],\n",
              " [2, 6709, 92, 6710, 56, 10, 39, 1462, 3],\n",
              " [2, 56, 10, 1463, 5, 52, 172, 6711, 3],\n",
              " [2, 30, 128, 5, 3834, 18, 45, 257, 6712, 3],\n",
              " [2, 674, 454, 54, 1464, 11, 73, 1465, 3],\n",
              " [2, 46, 145, 78, 743, 36, 2623, 3],\n",
              " [2, 20, 304, 7, 2036, 6713, 3],\n",
              " [2, 6714, 333, 25, 178, 3714, 3],\n",
              " [2, 6715, 39, 570, 4, 50, 7, 6716, 3],\n",
              " [2, 7, 3835, 6717, 4, 6718, 3],\n",
              " [2, 6719, 6720, 4, 3836, 2679, 3],\n",
              " [2, 6721, 20, 27, 310, 4, 541, 155, 1716, 3],\n",
              " [2, 4, 20, 6722, 10, 68, 49, 2680, 3],\n",
              " [2, 4, 120, 2681, 4, 6723, 6724, 3],\n",
              " [2, 30, 569, 5, 519, 93, 210, 76, 2682, 3],\n",
              " [2, 563, 2683, 9, 235, 6725, 3],\n",
              " [2, 132, 6726, 1466, 239, 295, 6727, 3],\n",
              " [2, 33, 3837, 6, 657, 3838, 3],\n",
              " [2, 6, 2684, 675, 7, 563, 6728, 3],\n",
              " [2, 132, 54, 403, 94, 6, 194, 197, 3],\n",
              " [2, 7, 139, 64, 2090, 233, 26, 78, 36, 227, 3],\n",
              " [2, 6729, 7, 1452, 6730, 3],\n",
              " [2, 222, 1467, 6731, 325, 36, 542, 3],\n",
              " [2, 33, 9, 17, 48, 9, 6732, 11, 123, 3],\n",
              " [2, 6733, 108, 6734, 34, 1468, 3],\n",
              " [2, 137, 29, 6735, 6736, 4, 1469, 3],\n",
              " [2, 182, 62, 44, 803, 2685, 6737, 3],\n",
              " [2, 5, 64, 302, 22, 15, 120, 15, 6738, 3],\n",
              " [2, 30, 339, 8, 184, 6739, 3839, 3],\n",
              " [2, 5, 7, 55, 2686, 104, 32, 6, 101, 815, 3],\n",
              " [2, 6740, 6741, 11, 126, 5, 17, 15, 6742, 3],\n",
              " [2, 6743, 193, 41, 10, 47, 6744, 3],\n",
              " [2, 6745, 2687, 6746, 3],\n",
              " [2, 333, 38, 3840, 388, 6747, 3],\n",
              " [2, 158, 5, 6, 193, 41, 6748, 4, 1670, 3],\n",
              " [2, 78, 495, 1717, 719, 8, 67, 6749, 3],\n",
              " [2, 6750, 6751, 74, 568, 74, 6752, 3],\n",
              " [2, 174, 190, 209, 293, 8, 2091, 3],\n",
              " [2, 3841, 115, 20, 50, 1278, 11, 1126, 3],\n",
              " [2, 5, 296, 210, 355, 161, 17, 24, 6753, 3],\n",
              " [2, 339, 21, 6754, 896, 6755, 3],\n",
              " [2, 107, 21, 6756, 6757, 5, 3842, 3],\n",
              " [2, 6758, 21, 13, 2092, 4, 758, 6759, 3],\n",
              " [2, 405, 5, 183, 571, 12, 1470, 3],\n",
              " [2, 35, 247, 5, 1471, 6, 193, 1014, 3],\n",
              " [2, 6760, 3843, 4, 7, 75, 286, 6761, 3],\n",
              " [2, 146, 243, 323, 6762, 6, 326, 6763, 3],\n",
              " [2, 7, 34, 748, 22, 2687, 520, 3],\n",
              " [2, 5, 170, 15, 120, 69, 6764, 6765, 3],\n",
              " [2, 381, 2688, 3752, 376, 2093, 3],\n",
              " [2, 6766, 8, 47, 20, 6767, 3844, 3],\n",
              " [2, 4, 13, 45, 209, 1279, 7, 6768, 3],\n",
              " [2, 4, 19, 6769, 325, 212, 16, 2094, 3],\n",
              " [2, 512, 17, 16, 1280, 22, 6, 220, 2095, 3],\n",
              " [2, 17, 48, 149, 1472, 89, 436, 6770, 3],\n",
              " [2, 146, 6771, 303, 8, 6, 6772, 3],\n",
              " [2, 899, 205, 5, 13, 3845, 21, 2096, 3],\n",
              " [2, 17, 69, 54, 13, 257, 812, 251, 1127, 3],\n",
              " [2, 2097, 28, 186, 154, 3846, 6773, 3],\n",
              " [2, 455, 289, 3847, 3848, 6774, 3],\n",
              " [2, 6775, 278, 154, 491, 6776, 3],\n",
              " [2, 637, 2689, 24, 102, 3849, 3],\n",
              " [2, 10, 455, 1473, 3766, 20, 182, 6777, 3],\n",
              " [2, 3850, 11, 3851, 7, 3852, 3853, 3],\n",
              " [2, 3854, 6778, 20, 53, 885, 4, 1474, 3],\n",
              " [2, 7, 290, 3855, 260, 55, 6779, 3],\n",
              " [2, 3856, 6780, 20, 808, 6781, 3],\n",
              " [2, 6782, 51, 23, 196, 185, 3857, 3],\n",
              " [2, 11, 160, 3858, 6783, 4, 2098, 3],\n",
              " [2, 17, 5, 114, 12, 6784, 124, 6785, 3],\n",
              " [2, 6786, 6787, 170, 13, 900, 6788, 3],\n",
              " [2, 16, 85, 6789, 15, 563, 6790, 3],\n",
              " [2, 5, 25, 456, 11, 47, 543, 6791, 3],\n",
              " [2, 488, 78, 6792, 20, 816, 2099, 3],\n",
              " [2, 89, 216, 467, 892, 6793, 129, 6794, 3],\n",
              " [2, 1281, 6795, 20, 15, 53, 6796, 3],\n",
              " [2, 901, 6797, 4, 6, 6798, 3],\n",
              " [2, 23, 189, 123, 78, 13, 817, 2690, 3],\n",
              " [2, 5, 20, 3859, 38, 720, 6799, 3],\n",
              " [2, 901, 34, 3860, 5, 6800, 6801, 3],\n",
              " [2, 6802, 6803, 6804, 4, 6805, 3],\n",
              " [2, 4, 1475, 11, 600, 78, 13, 6806, 3],\n",
              " [2, 158, 6807, 36, 103, 19, 14, 1476, 3],\n",
              " [2, 78, 13, 209, 7, 230, 5, 2691, 3],\n",
              " [2, 818, 89, 6808, 3861, 3],\n",
              " [2, 1128, 27, 6809, 124, 1718, 15, 6810, 3],\n",
              " [2, 200, 243, 380, 6811, 4, 6812, 3],\n",
              " [2, 5, 2692, 8, 15, 120, 19, 261, 15, 6813, 3],\n",
              " [2, 6814, 5, 13, 95, 8, 3862, 3863, 3],\n",
              " [2, 6815, 6816, 4, 3864, 3],\n",
              " [2, 6817, 6818, 4, 6819, 3],\n",
              " [2, 4, 78, 18, 1107, 6820, 25, 2624, 3],\n",
              " [2, 6821, 2100, 4, 78, 6822, 3],\n",
              " [2, 6823, 4, 6824, 4, 6825, 6826, 3],\n",
              " [2, 6827, 3865, 4, 6828, 3],\n",
              " [2, 6829, 6830, 4, 6831, 3],\n",
              " [2, 6832, 5, 13, 117, 6833, 3866, 3],\n",
              " [2, 99, 9, 819, 2693, 7, 124, 8, 2101, 3],\n",
              " [2, 96, 5, 17, 16, 2102, 18, 367, 6834, 3],\n",
              " [2, 5, 484, 289, 28, 168, 18, 203, 296, 1719, 3],\n",
              " [2, 148, 6835, 902, 11, 111, 12, 6836, 3],\n",
              " [2, 10, 246, 197, 16, 875, 18, 1015, 715, 3],\n",
              " [2, 85, 22, 6, 1670, 32, 897, 5, 3867, 3],\n",
              " [2, 30, 2043, 11, 123, 214, 9, 21, 5, 3868, 3],\n",
              " [2, 146, 2694, 25, 294, 1720, 3],\n",
              " [2, 79, 35, 2695, 5, 176, 160, 6837, 3],\n",
              " [2, 4, 49, 19, 3869, 5, 3870, 8, 6838, 3],\n",
              " [2, 6839, 1477, 6840, 4, 6841, 3],\n",
              " [2, 6842, 14, 2696, 32, 6843, 3],\n",
              " [2, 6844, 4, 3871, 272, 6845, 3],\n",
              " [2, 6846, 5, 46, 305, 151, 2697, 3],\n",
              " [2, 15, 296, 1478, 159, 12, 6847, 3],\n",
              " [2, 4, 34, 6848, 22, 14, 2103, 3],\n",
              " [2, 386, 58, 160, 2104, 21, 23, 3872, 3],\n",
              " [2, 6849, 20, 6, 676, 572, 289, 3],\n",
              " [2, 677, 820, 435, 5, 79, 177, 6850, 3],\n",
              " [2, 2105, 210, 8, 70, 32, 759, 6851, 3],\n",
              " [2, 453, 8, 3873, 389, 28, 6852, 3],\n",
              " [2, 6853, 4, 6854, 4, 52, 44, 79, 3874, 3],\n",
              " [2, 137, 29, 5, 1479, 28, 1480, 6855, 3],\n",
              " [2, 192, 1477, 8, 47, 46, 16, 2610, 3],\n",
              " [2, 1721, 760, 7, 436, 3875, 3],\n",
              " [2, 6856, 69, 6857, 4, 7, 68, 29, 37, 6858, 3],\n",
              " [2, 9, 6859, 3876, 22, 6860, 3],\n",
              " [2, 30, 13, 162, 45, 8, 315, 496, 71, 6861, 3],\n",
              " [2, 132, 6862, 27, 39, 6863, 6864, 3],\n",
              " [2, 2071, 51, 812, 90, 12, 374, 3],\n",
              " [2, 75, 5, 12, 2072, 4, 19, 9, 3803, 3],\n",
              " [2, 240, 6865, 14, 2106, 1481, 3],\n",
              " [2, 8, 6866, 6867, 136, 44, 821, 3],\n",
              " [2, 42, 90, 351, 814, 16, 3877, 3],\n",
              " [2, 99, 747, 11, 160, 225, 169, 3878, 3],\n",
              " [2, 5, 6868, 24, 66, 439, 10, 3879, 3],\n",
              " [2, 31, 23, 6869, 1722, 21, 6870, 3],\n",
              " [2, 148, 6871, 6872, 5, 92, 9, 3880, 3],\n",
              " [2, 875, 15, 761, 20, 6, 38, 3881, 3],\n",
              " [2, 2107, 4, 6873, 15, 6874, 3],\n",
              " [2, 282, 6875, 6876, 8, 6, 2108, 3],\n",
              " [2, 200, 14, 3703, 18, 6877, 18, 6878, 3],\n",
              " [2, 6879, 200, 6, 201, 6880, 3],\n",
              " [2, 6881, 100, 51, 168, 1723, 3],\n",
              " [2, 3882, 6882, 40, 1724, 6883, 3],\n",
              " [2, 5, 6, 601, 6884, 28, 3738, 3],\n",
              " [2, 30, 24, 15, 6885, 32, 3883, 497, 3],\n",
              " [2, 35, 1282, 1725, 8, 813, 1726, 4, 2109, 3],\n",
              " [2, 51, 34, 2110, 15, 563, 2111, 3],\n",
              " [2, 7, 1016, 7, 521, 7, 598, 7, 104, 15, 6886, 3],\n",
              " [2, 255, 627, 15, 2112, 1129, 3],\n",
              " [2, 9, 5, 7, 2113, 33, 7, 802, 6887, 3],\n",
              " [2, 30, 24, 40, 6888, 1727, 721, 55, 6889, 3],\n",
              " [2, 2114, 11, 1283, 7, 57, 403, 2698, 3],\n",
              " [2, 51, 243, 26, 2115, 2116, 2699, 3],\n",
              " [2, 719, 6890, 23, 6, 3884, 3885, 3],\n",
              " [2, 10, 80, 440, 492, 62, 44, 187, 3],\n",
              " [2, 346, 5, 897, 2700, 17, 6891, 3],\n",
              " [2, 457, 83, 7, 230, 7, 68, 1482, 3],\n",
              " [2, 29, 434, 6892, 16, 192, 339, 1728, 3],\n",
              " [2, 3886, 6893, 7, 484, 6894, 3],\n",
              " [2, 348, 3887, 7, 2117, 41, 17, 3888, 3],\n",
              " [2, 5, 3889, 135, 1729, 11, 38, 1432, 3],\n",
              " [2, 10, 1483, 18, 2701, 11, 5, 54, 6895, 3],\n",
              " [2, 3890, 21, 6896, 7, 68, 12, 762, 3],\n",
              " [2, 5, 6897, 8, 6898, 4, 41, 38, 6899, 3],\n",
              " [2, 1017, 6, 102, 5, 13, 3891, 6900, 3],\n",
              " [2, 1484, 21, 566, 5, 6901, 6902, 3],\n",
              " [2, 4, 2702, 361, 28, 2118, 7, 6903, 3],\n",
              " [2, 52, 21, 6904, 6905, 3],\n",
              " [2, 6906, 722, 10, 68, 49, 2119, 3],\n",
              " [2, 150, 12, 1696, 4, 202, 13, 290, 6907, 3],\n",
              " [2, 5, 20, 336, 28, 406, 6908, 3],\n",
              " [2, 509, 6909, 6910, 4, 19, 7, 424, 3],\n",
              " [2, 719, 2703, 4, 6911, 8, 1485, 3],\n",
              " [2, 3892, 7, 194, 179, 6912, 3],\n",
              " [2, 349, 48, 1130, 13, 45, 3893, 2704, 3],\n",
              " [2, 1730, 14, 751, 2705, 4, 216, 3894, 3],\n",
              " [2, 718, 16, 6913, 4, 149, 221, 6914, 3],\n",
              " [2, 488, 666, 3708, 2603, 3],\n",
              " [2, 6915, 8, 128, 111, 5, 2120, 1731, 3],\n",
              " [2, 4, 2706, 17, 28, 472, 82, 6916, 3],\n",
              " [2, 164, 121, 8, 184, 6917, 46, 1108, 3],\n",
              " [2, 19, 261, 8, 1732, 4, 29, 390, 15, 6918, 3],\n",
              " [2, 10, 215, 245, 5, 40, 6919, 129, 295, 6920, 3],\n",
              " [2, 311, 181, 24, 18, 472, 8, 67, 15, 2707, 3],\n",
              " [2, 1131, 6, 2708, 137, 538, 6921, 3],\n",
              " [2, 2121, 8, 67, 3895, 2122, 248, 6922, 3],\n",
              " [2, 806, 6923, 64, 340, 6924, 3],\n",
              " [2, 20, 497, 6925, 4, 6926, 28, 133, 1284, 3],\n",
              " [2, 1486, 10, 2123, 64, 269, 6927, 3],\n",
              " [2, 1285, 1018, 22, 6, 813, 371, 21, 6928, 3],\n",
              " [2, 8, 67, 822, 10, 300, 6929, 3],\n",
              " [2, 17, 344, 41, 6930, 6931, 3],\n",
              " [2, 137, 2709, 2124, 4, 1733, 3],\n",
              " [2, 5, 6932, 1286, 10, 300, 6933, 3],\n",
              " [2, 67, 5, 6934, 18, 95, 7, 6935, 3],\n",
              " [2, 31, 172, 2710, 18, 817, 22, 2711, 3],\n",
              " [2, 67, 6936, 70, 22, 6, 101, 1676, 3],\n",
              " [2, 52, 1734, 718, 25, 217, 151, 6937, 3],\n",
              " [2, 222, 34, 5, 1019, 4, 5, 257, 138, 903, 3],\n",
              " [2, 67, 6938, 4, 3896, 8, 1008, 3],\n",
              " [2, 391, 5, 13, 1122, 24, 1132, 145, 2023, 3],\n",
              " [2, 3897, 6, 102, 90, 2697, 149, 3],\n",
              " [2, 84, 6, 1735, 90, 13, 2712, 1133, 3],\n",
              " [2, 10, 327, 544, 541, 2713, 2657, 3],\n",
              " [2, 3898, 262, 345, 1442, 1454, 6939, 3],\n",
              " [2, 518, 416, 22, 6, 326, 415, 3],\n",
              " [2, 5, 16, 41, 3899, 4, 13, 302, 94, 6940, 3],\n",
              " [2, 3898, 100, 904, 6941, 2714, 3900, 3],\n",
              " [2, 16, 518, 25, 416, 473, 17, 673, 3],\n",
              " [2, 93, 24, 722, 94, 9, 6942, 3],\n",
              " [2, 2125, 2715, 67, 76, 98, 2716, 3],\n",
              " [2, 3901, 6943, 62, 8, 179, 145, 6944, 3],\n",
              " [2, 1116, 175, 23, 55, 145, 85, 6945, 3],\n",
              " [2, 1134, 26, 2656, 228, 538, 6946, 3],\n",
              " [2, 6947, 18, 1020, 4, 49, 18, 2620, 1487, 3],\n",
              " [2, 309, 5, 13, 896, 16, 109, 678, 6948, 3],\n",
              " [2, 282, 6949, 666, 2055, 1251, 3],\n",
              " [2, 1287, 602, 1736, 87, 340, 3],\n",
              " [2, 3902, 1288, 28, 1480, 6950, 3],\n",
              " [2, 158, 16, 905, 8, 220, 4, 6951, 131, 3],\n",
              " [2, 4, 666, 6952, 40, 407, 2126, 3],\n",
              " [2, 8, 1678, 16, 286, 679, 4, 3903, 3],\n",
              " [2, 77, 1737, 28, 150, 163, 602, 1700, 3],\n",
              " [2, 8, 5, 4, 24, 6953, 336, 3],\n",
              " [2, 5, 6954, 40, 6955, 6956, 3],\n",
              " [2, 30, 50, 8, 184, 2127, 252, 2717, 3],\n",
              " [2, 5, 6957, 25, 150, 2618, 3],\n",
              " [2, 32, 6, 6958, 4, 75, 638, 13, 105, 6959, 3],\n",
              " [2, 77, 1488, 2082, 6, 83, 1738, 3],\n",
              " [2, 25, 217, 245, 29, 356, 436, 2718, 3],\n",
              " [2, 1101, 24, 115, 5, 1104, 4, 3904, 3],\n",
              " [2, 253, 6960, 36, 487, 10, 823, 3],\n",
              " [2, 7, 6961, 24, 245, 27, 3905, 3],\n",
              " [2, 1739, 1289, 4, 86, 234, 3906, 3],\n",
              " [2, 232, 19, 801, 15, 53, 145, 3907, 3],\n",
              " [2, 50, 6962, 4, 6963, 18, 2719, 3],\n",
              " [2, 33, 283, 36, 275, 41, 34, 5, 145, 3908, 3],\n",
              " [2, 282, 3909, 18, 6964, 545, 3],\n",
              " [2, 82, 6965, 23, 436, 3910, 3],\n",
              " [2, 2720, 5, 92, 23, 47, 9, 206, 2721, 3],\n",
              " [2, 6, 498, 16, 6966, 65, 6967, 3],\n",
              " [2, 6968, 41, 13, 3911, 4, 62, 27, 6969, 3],\n",
              " [2, 34, 487, 19, 9, 138, 3909, 6970, 3],\n",
              " [2, 708, 5, 458, 459, 73, 263, 3],\n",
              " [2, 107, 6971, 17, 5, 7, 2722, 3],\n",
              " [2, 26, 747, 176, 51, 69, 26, 6972, 3],\n",
              " [2, 30, 2080, 24, 256, 1489, 3912, 3],\n",
              " [2, 1695, 591, 22, 6, 573, 5, 12, 2723, 3],\n",
              " [2, 210, 8, 6, 718, 163, 111, 6973, 3],\n",
              " [2, 5, 7, 2724, 65, 16, 6974, 3],\n",
              " [2, 1436, 3913, 4, 1436, 6975, 3],\n",
              " [2, 16, 319, 1740, 24, 48, 16, 1741, 3],\n",
              " [2, 4, 48, 16, 6976, 4, 24, 5, 26, 6977, 3],\n",
              " [2, 99, 211, 28, 763, 2128, 22, 6, 6978, 3],\n",
              " [2, 2129, 6979, 1742, 4, 6980, 3],\n",
              " [2, 3914, 4, 6981, 92, 9, 1290, 6982, 3],\n",
              " [2, 6983, 6984, 546, 6985, 4, 1135, 3],\n",
              " [2, 10, 300, 6986, 12, 6987, 3],\n",
              " [2, 6988, 6, 102, 5, 73, 6989, 3],\n",
              " [2, 2725, 624, 3915, 4, 6990, 3],\n",
              " [2, 20, 161, 6991, 6992, 6993, 3],\n",
              " [2, 170, 6, 108, 5, 200, 21, 6994, 3],\n",
              " [2, 392, 53, 113, 6995, 6, 1291, 6996, 4, 6997, 3],\n",
              " [2, 4, 13, 906, 3916, 4, 6998, 14, 2130, 3],\n",
              " [2, 3917, 15, 761, 129, 6999, 129, 7000, 3],\n",
              " [2, 7001, 15, 66, 6, 907, 24, 7002, 3],\n",
              " [2, 22, 196, 185, 2726, 286, 8, 107, 7003, 3],\n",
              " [2, 7004, 1021, 40, 1292, 7005, 3],\n",
              " [2, 282, 145, 7006, 2725, 18, 117, 3918, 3],\n",
              " [2, 14, 3919, 1293, 4, 7007, 14, 7008, 3],\n",
              " [2, 9, 173, 2727, 5, 7009, 7010, 3],\n",
              " [2, 30, 13, 162, 45, 2728, 14, 167, 7011, 3],\n",
              " [2, 518, 6, 460, 4, 20, 1294, 14, 2729, 3],\n",
              " [2, 6, 2131, 110, 8, 14, 3920, 7012, 3],\n",
              " [2, 461, 21, 34, 2730, 7013, 3921, 3],\n",
              " [2, 4, 12, 7014, 52, 5, 13, 1254, 3922, 3],\n",
              " [2, 59, 283, 8, 7015, 1743, 4, 7016, 3],\n",
              " [2, 1262, 12, 1280, 187, 2132, 7017, 3],\n",
              " [2, 22, 27, 2133, 2725, 5, 7018, 3],\n",
              " [2, 567, 241, 908, 7019, 7020, 3],\n",
              " [2, 253, 3837, 84, 10, 909, 5, 7021, 3],\n",
              " [2, 6, 2062, 2134, 4, 7022, 14, 824, 3],\n",
              " [2, 170, 55, 3923, 5, 191, 3924, 3],\n",
              " [2, 3794, 3925, 10, 102, 153, 3926, 3],\n",
              " [2, 85, 383, 100, 818, 12, 7023, 1454, 3],\n",
              " [2, 711, 145, 353, 3927, 2731, 3],\n",
              " [2, 137, 29, 5, 156, 10, 73, 1136, 7024, 3],\n",
              " [2, 16, 263, 7025, 31, 2732, 3],\n",
              " [2, 29, 1744, 83, 48, 7026, 7027, 3],\n",
              " [2, 30, 26, 8, 315, 3830, 5, 29, 356, 3],\n",
              " [2, 223, 37, 1490, 85, 22, 6, 61, 573, 3],\n",
              " [2, 17, 5, 9, 191, 80, 37, 1745, 2733, 3],\n",
              " [2, 77, 565, 62, 29, 156, 5, 119, 17, 1491, 3],\n",
              " [2, 160, 156, 1746, 4, 356, 17, 438, 1492, 3],\n",
              " [2, 93, 2135, 21, 7028, 255, 21, 17, 7029, 3],\n",
              " [2, 164, 121, 8, 184, 457, 101, 2734, 140, 825, 3],\n",
              " [2, 3928, 17, 5, 43, 7030, 18, 7031, 3],\n",
              " [2, 1022, 16, 1017, 11, 6, 179, 3929, 3],\n",
              " [2, 2735, 3930, 16, 7032, 7033, 3],\n",
              " [2, 10, 6, 7034, 320, 22, 6, 2136, 3],\n",
              " [2, 24, 29, 722, 8, 6, 907, 16, 7035, 3],\n",
              " [2, 30, 26, 398, 568, 9, 44, 1014, 3],\n",
              " [2, 59, 153, 264, 8, 1747, 408, 759, 3],\n",
              " [2, 10, 1747, 7036, 30, 19, 9, 135, 3931, 3],\n",
              " [2, 99, 15, 2736, 7037, 18, 105, 3932, 3],\n",
              " [2, 16, 2737, 241, 100, 1678, 16, 7038, 3],\n",
              " [2, 33, 1461, 31, 29, 1295, 8, 5, 2137, 3],\n",
              " [2, 15, 2138, 22, 6, 588, 7039, 3],\n",
              " [2, 2139, 764, 7040, 4, 565, 6, 979, 3],\n",
              " [2, 10, 5, 1137, 299, 7041, 7042, 3],\n",
              " [2, 30, 339, 8, 184, 7043, 403, 7044, 3],\n",
              " [2, 2137, 28, 1748, 4, 6, 123, 2013, 3],\n",
              " [2, 2614, 189, 20, 1493, 7045, 3],\n",
              " [2, 158, 672, 195, 5, 81, 3933, 3],\n",
              " [2, 7046, 161, 1749, 4, 5, 189, 7047, 3],\n",
              " [2, 20, 6, 471, 7, 88, 5, 2140, 7048, 3],\n",
              " [2, 7049, 2738, 367, 150, 14, 7050, 3],\n",
              " [2, 1750, 189, 118, 1138, 7051, 3],\n",
              " [2, 24, 5, 7, 75, 3934, 56, 5, 7052, 3],\n",
              " [2, 7053, 44, 1023, 4, 9, 138, 211, 7054, 3],\n",
              " [2, 3935, 2739, 4, 2141, 211, 3],\n",
              " [2, 14, 161, 1494, 803, 40, 7055, 7056, 3],\n",
              " [2, 603, 753, 406, 28, 7057, 2740, 3],\n",
              " [2, 30, 26, 8, 315, 2741, 569, 5, 16, 7058, 3],\n",
              " [2, 4, 5, 7, 19, 257, 16, 2142, 3936, 3],\n",
              " [2, 3937, 4, 13, 7059, 5, 85, 17, 3938, 3],\n",
              " [2, 2742, 7060, 2143, 4, 13, 7061, 3],\n",
              " [2, 4, 15, 120, 100, 63, 144, 2743, 15, 7062, 3],\n",
              " [2, 565, 214, 211, 4, 66, 48, 15, 7063, 3],\n",
              " [2, 59, 117, 340, 16, 2744, 7, 3939, 3],\n",
              " [2, 31, 13, 126, 15, 7064, 56, 27, 1136, 15, 7065, 3],\n",
              " [2, 30, 2745, 7066, 44, 89, 567, 19, 7067, 3],\n",
              " [2, 680, 2696, 79, 15, 3940, 28, 7068, 3],\n",
              " [2, 31, 49, 7069, 42, 40, 2144, 7070, 3],\n",
              " [2, 77, 46, 29, 757, 35, 133, 547, 3],\n",
              " [2, 7071, 100, 6, 142, 360, 16, 7072, 3],\n",
              " [2, 19, 9, 37, 522, 4, 19, 9, 37, 7073, 3],\n",
              " [2, 392, 3941, 53, 1296, 639, 11, 7074, 3],\n",
              " [2, 2746, 36, 103, 4, 52, 2747, 6, 7075, 3],\n",
              " [2, 1024, 20, 306, 8, 191, 22, 15, 120, 7076, 3],\n",
              " [2, 30, 13, 162, 192, 8, 184, 1495, 9, 12, 3942, 3],\n",
              " [2, 7, 139, 64, 594, 22, 1751, 3943, 3],\n",
              " [2, 46, 826, 6, 2047, 7077, 3],\n",
              " [2, 183, 7078, 6, 568, 3944, 3],\n",
              " [2, 7079, 38, 499, 4, 38, 2145, 3],\n",
              " [2, 7080, 34, 2146, 671, 7081, 3],\n",
              " [2, 311, 7082, 10, 2748, 3945, 3],\n",
              " [2, 22, 909, 4, 22, 6, 2134, 8, 317, 3946, 3],\n",
              " [2, 7083, 36, 103, 6, 179, 3947, 3],\n",
              " [2, 10, 48, 440, 492, 7084, 3913, 3],\n",
              " [2, 7085, 295, 418, 6, 117, 3948, 3],\n",
              " [2, 56, 1005, 7086, 56, 1752, 17, 7087, 3],\n",
              " [2, 164, 121, 8, 184, 7088, 8, 101, 3949, 3],\n",
              " [2, 5, 1753, 87, 6, 204, 21, 19, 2749, 3],\n",
              " [2, 19, 2147, 18, 1297, 4, 51, 6, 7089, 3],\n",
              " [2, 3950, 5, 81, 108, 3951, 3],\n",
              " [2, 11, 723, 2750, 43, 92, 9, 2148, 3],\n",
              " [2, 7, 42, 19, 5, 7, 139, 724, 7090, 3],\n",
              " [2, 253, 7091, 8, 1754, 50, 1496, 3],\n",
              " [2, 899, 19, 212, 80, 9, 7092, 3],\n",
              " [2, 765, 28, 275, 90, 12, 7093, 3],\n",
              " [2, 200, 1497, 7094, 18, 117, 3952, 3],\n",
              " [2, 7095, 7096, 7097, 7098, 7099, 3],\n",
              " [2, 293, 7100, 20, 6, 193, 7101, 3],\n",
              " [2, 4, 34, 1015, 2751, 5, 65, 7102, 3],\n",
              " [2, 192, 10, 7103, 485, 37, 7104, 3],\n",
              " [2, 6, 101, 2042, 725, 2752, 328, 7105, 3],\n",
              " [2, 9, 145, 3953, 27, 886, 81, 7106, 3],\n",
              " [2, 158, 12, 1139, 8, 50, 7107, 2753, 3],\n",
              " [2, 4, 109, 7108, 2754, 7109, 3],\n",
              " [2, 7110, 110, 97, 20, 6, 101, 7111, 3],\n",
              " [2, 132, 21, 86, 332, 1140, 28, 7112, 3],\n",
              " [2, 2071, 32, 7113, 42, 90, 3954, 3],\n",
              " [2, 135, 6, 523, 25, 2607, 7114, 3],\n",
              " [2, 806, 64, 472, 14, 7115, 2149, 3],\n",
              " [2, 7116, 3955, 52, 5, 2755, 3956, 3],\n",
              " [2, 88, 1024, 8, 102, 6, 624, 7117, 3],\n",
              " [2, 146, 3957, 32, 6, 2756, 3958, 3],\n",
              " [2, 7118, 19, 22, 6, 1491, 425, 3],\n",
              " [2, 5, 13, 151, 22, 1141, 65, 7119, 3],\n",
              " [2, 621, 352, 7, 7120, 572, 62, 3959, 3],\n",
              " [2, 827, 7121, 4, 7122, 312, 26, 7123, 3],\n",
              " [2, 4, 60, 194, 320, 17, 32, 7124, 3],\n",
              " [2, 198, 66, 1708, 42, 170, 7125, 3],\n",
              " [2, 5, 12, 2757, 20, 50, 11, 68, 7126, 3],\n",
              " [2, 51, 195, 5, 72, 6, 108, 7127, 3],\n",
              " [2, 603, 243, 323, 108, 19, 7128, 7129, 3],\n",
              " [2, 4, 383, 123, 4, 7130, 20, 1717, 7131, 3],\n",
              " [2, 2107, 2758, 10, 471, 7, 7132, 3],\n",
              " [2, 7133, 7134, 4, 219, 71, 207, 3],\n",
              " [2, 12, 7135, 2759, 2107, 8, 1755, 3],\n",
              " [2, 1268, 496, 7136, 4, 496, 7137, 3],\n",
              " [2, 146, 7138, 10, 27, 294, 2760, 3],\n",
              " [2, 23, 112, 469, 8, 7139, 1756, 3],\n",
              " [2, 7140, 635, 220, 7141, 3960, 3],\n",
              " [2, 52, 12, 3961, 2759, 233, 54, 2015, 3],\n",
              " [2, 10, 27, 39, 229, 294, 8, 189, 7142, 3],\n",
              " [2, 30, 131, 632, 27, 345, 221, 2016, 3],\n",
              " [2, 440, 1298, 199, 136, 16, 1498, 3],\n",
              " [2, 5, 108, 21, 2150, 4, 31, 124, 85, 3962, 3],\n",
              " [2, 182, 7143, 8, 6, 548, 7144, 3],\n",
              " [2, 164, 121, 8, 184, 2151, 1287, 85, 7145, 3],\n",
              " [2, 17, 22, 6, 142, 11, 6, 179, 7146, 3],\n",
              " [2, 5, 20, 3963, 904, 7147, 7148, 3],\n",
              " [2, 2152, 6, 193, 55, 524, 7149, 3],\n",
              " [2, 46, 7150, 147, 111, 3964, 25, 294, 3],\n",
              " [2, 90, 320, 2153, 15, 3965, 3],\n",
              " [2, 561, 85, 7151, 5, 9, 1142, 2761, 3],\n",
              " [2, 7152, 28, 2762, 4, 7153, 4, 7154, 3],\n",
              " [2, 11, 68, 7155, 2141, 18, 39, 7156, 3],\n",
              " [2, 30, 324, 492, 89, 182, 1285, 3],\n",
              " [2, 7157, 26, 63, 7158, 7159, 3],\n",
              " [2, 5, 1143, 7160, 7, 2070, 7161, 3],\n",
              " [2, 164, 121, 8, 184, 7162, 2763, 7163, 3],\n",
              " [2, 6, 7164, 179, 5, 40, 135, 7165, 3],\n",
              " [2, 76, 112, 1499, 136, 15, 66, 7166, 3],\n",
              " [2, 511, 671, 2137, 8, 15, 111, 7167, 3],\n",
              " [2, 182, 7168, 25, 3966, 3],\n",
              " [2, 106, 3967, 1757, 4, 182, 441, 3968, 7169, 3],\n",
              " [2, 7170, 2154, 4, 151, 1025, 27, 95, 7171, 3],\n",
              " [2, 113, 1144, 1145, 4, 7172, 8, 81, 7173, 3],\n",
              " [2, 58, 242, 828, 175, 9, 145, 7174, 3],\n",
              " [2, 240, 1299, 3969, 114, 6, 2155, 7175, 3],\n",
              " [2, 163, 63, 5, 44, 7176, 8, 6, 2764, 3],\n",
              " [2, 10, 5, 564, 108, 12, 7177, 3],\n",
              " [2, 59, 65, 1758, 140, 118, 6, 1300, 3],\n",
              " [2, 4, 5, 43, 746, 7, 437, 538, 7178, 3],\n",
              " [2, 9, 7179, 3970, 7180, 7181, 3],\n",
              " [2, 1298, 1011, 218, 131, 2156, 16, 249, 7182, 3],\n",
              " [2, 81, 910, 7, 5, 29, 16, 7183, 3],\n",
              " [2, 5, 766, 5, 40, 63, 25, 95, 113, 17, 89, 7184, 3],\n",
              " [2, 30, 339, 8, 184, 2055, 1301, 7185, 3],\n",
              " [2, 829, 3971, 21, 50, 5, 7186, 3],\n",
              " [2, 240, 569, 5, 29, 61, 1302, 32, 7187, 3],\n",
              " [2, 1759, 27, 68, 1692, 65, 7188, 3],\n",
              " [2, 143, 15, 2157, 4, 1146, 55, 62, 2765, 3],\n",
              " [2, 241, 681, 123, 76, 112, 123, 3972, 3],\n",
              " [2, 7189, 1500, 6, 3973, 3],\n",
              " [2, 3974, 8, 15, 1147, 7190, 3],\n",
              " [2, 3975, 3976, 2766, 4, 2158, 3],\n",
              " [2, 5, 7191, 8, 150, 15, 63, 2767, 3],\n",
              " [2, 7, 108, 11, 108, 4, 1760, 11, 130, 1748, 3],\n",
              " [2, 373, 6, 3977, 163, 7192, 7193, 3],\n",
              " [2, 10, 1761, 108, 3707, 4, 189, 3978, 3],\n",
              " [2, 1148, 27, 997, 7, 7194, 3],\n",
              " [2, 5, 21, 3979, 24, 11, 2768, 7195, 3],\n",
              " [2, 7196, 1692, 9, 113, 7197, 8, 1762, 3],\n",
              " [2, 81, 7198, 7199, 4, 7200, 3],\n",
              " [2, 39, 525, 24, 18, 220, 15, 120, 2769, 3],\n",
              " [2, 574, 167, 7201, 9, 385, 7202, 3],\n",
              " [2, 2159, 6, 66, 82, 7203, 3],\n",
              " [2, 17, 1021, 296, 62, 3873, 7204, 3],\n",
              " [2, 1026, 21, 566, 140, 49, 1501, 11, 830, 3],\n",
              " [2, 71, 23, 230, 5, 14, 2770, 604, 2771, 3],\n",
              " [2, 3980, 2701, 8, 2772, 4, 831, 7205, 3],\n",
              " [2, 33, 242, 1027, 884, 4, 75, 9, 7206, 3],\n",
              " [2, 20, 268, 832, 1301, 767, 3],\n",
              " [2, 2670, 38, 526, 4, 884, 12, 3981, 3],\n",
              " [2, 240, 7207, 354, 8, 252, 7208, 3],\n",
              " [2, 43, 112, 500, 833, 5, 2773, 3],\n",
              " [2, 233, 26, 16, 3824, 4, 13, 341, 682, 12, 7209, 3],\n",
              " [2, 253, 7210, 18, 294, 8, 189, 494, 3],\n",
              " [2, 683, 98, 981, 5, 1763, 4, 7211, 3],\n",
              " [2, 10, 36, 7212, 5, 23, 141, 7213, 3],\n",
              " [2, 2160, 54, 2673, 212, 19, 5, 7214, 3],\n",
              " [2, 4, 362, 11, 902, 22, 2161, 7215, 3],\n",
              " [2, 2162, 79, 10, 98, 197, 7216, 3],\n",
              " [2, 511, 6, 2163, 188, 382, 247, 2774, 3],\n",
              " [2, 73, 679, 7217, 233, 21, 2775, 3],\n",
              " [2, 28, 186, 22, 14, 7218, 7219, 7220, 3],\n",
              " [2, 30, 131, 5, 7, 2164, 605, 2776, 3],\n",
              " [2, 78, 346, 3982, 11, 34, 3983, 3],\n",
              " [2, 7221, 2777, 20, 911, 3984, 3],\n",
              " [2, 1116, 12, 7222, 9, 71, 20, 1126, 3],\n",
              " [2, 33, 20, 6, 384, 4, 106, 442, 4, 441, 1149, 3],\n",
              " [2, 7223, 541, 912, 8, 3985, 8, 7224, 3],\n",
              " [2, 174, 190, 209, 109, 3986, 136, 202, 3],\n",
              " [2, 567, 7, 230, 68, 1123, 3987, 3],\n",
              " [2, 4, 635, 569, 5, 29, 10, 422, 606, 3],\n",
              " [2, 5, 118, 307, 21, 108, 5, 7225, 3],\n",
              " [2, 4, 286, 7226, 437, 546, 28, 7227, 3],\n",
              " [2, 24, 254, 37, 1764, 667, 5, 7228, 3],\n",
              " [2, 7229, 35, 7230, 7231, 7232, 279, 3],\n",
              " [2, 32, 300, 133, 5, 64, 127, 7233, 3],\n",
              " [2, 7234, 110, 7235, 7236, 3],\n",
              " [2, 136, 145, 7237, 32, 6, 7238, 7239, 3],\n",
              " [2, 1026, 3988, 12, 7240, 32, 6, 7241, 3],\n",
              " [2, 59, 203, 248, 913, 20, 629, 7242, 3],\n",
              " [2, 146, 7243, 22, 6, 7244, 7245, 3],\n",
              " [2, 1717, 1150, 89, 6, 425, 2778, 4, 13, 7246, 3],\n",
              " [2, 20, 15, 53, 1028, 8, 62, 25, 3989, 7247, 3],\n",
              " [2, 2097, 28, 186, 383, 2165, 28, 23, 7248, 3],\n",
              " [2, 99, 675, 3990, 2166, 83, 3],\n",
              " [2, 5, 67, 2779, 28, 186, 22, 357, 7249, 3],\n",
              " [2, 15, 53, 423, 7250, 462, 8, 6, 607, 3],\n",
              " [2, 10, 111, 7251, 5, 40, 3991, 7252, 3],\n",
              " [2, 4, 834, 23, 1467, 835, 3844, 3],\n",
              " [2, 49, 100, 408, 18, 549, 254, 7253, 3],\n",
              " [2, 30, 26, 16, 443, 28, 439, 7, 65, 13, 7254, 3],\n",
              " [2, 440, 1447, 5, 7255, 4, 5, 2167, 3],\n",
              " [2, 228, 130, 7256, 4, 62, 44, 128, 5, 13, 7257, 3],\n",
              " [2, 164, 121, 8, 184, 7258, 10, 14, 7259, 91, 3],\n",
              " [2, 43, 7260, 387, 215, 5, 2780, 3],\n",
              " [2, 31, 13, 279, 25, 3992, 248, 37, 7261, 3],\n",
              " [2, 7262, 9, 1502, 92, 23, 57, 1765, 3],\n",
              " [2, 5, 17, 7263, 197, 10, 300, 7264, 3],\n",
              " [2, 69, 26, 78, 98, 1007, 2781, 3],\n",
              " [2, 401, 10, 307, 226, 67, 11, 914, 3],\n",
              " [2, 118, 13, 3993, 154, 127, 7265, 3],\n",
              " [2, 5, 1766, 347, 156, 3994, 398, 7266, 3],\n",
              " [2, 7267, 7268, 29, 7269, 8, 7270, 3],\n",
              " [2, 192, 27, 45, 3995, 1029, 81, 7271, 3],\n",
              " [2, 19, 9, 145, 2782, 5, 127, 2783, 18, 7272, 3],\n",
              " [2, 461, 21, 115, 5, 290, 3996, 2784, 3],\n",
              " [2, 5, 15, 177, 2785, 4, 52, 31, 32, 3997, 3],\n",
              " [2, 7273, 7274, 32, 1274, 7275, 3],\n",
              " [2, 174, 162, 45, 1503, 32, 6, 2786, 3],\n",
              " [2, 4, 52, 16, 143, 2675, 672, 1151, 3],\n",
              " [2, 4, 127, 233, 26, 149, 110, 329, 2787, 3],\n",
              " [2, 1030, 5, 13, 162, 4, 26, 35, 597, 486, 3],\n",
              " [2, 7276, 31, 32, 188, 1260, 2788, 3],\n",
              " [2, 22, 307, 19, 5, 9, 836, 20, 1504, 3],\n",
              " [2, 708, 67, 7277, 6, 1303, 7278, 3],\n",
              " [2, 210, 16, 12, 143, 36, 658, 7, 3998, 3],\n",
              " [2, 4, 109, 640, 156, 29, 5, 1479, 447, 3999, 3],\n",
              " [2, 30, 26, 8, 315, 2040, 4000, 9, 7279, 3],\n",
              " [2, 33, 29, 62, 726, 5, 17, 156, 168, 7280, 3],\n",
              " [2, 2063, 2168, 5, 44, 36, 5, 7281, 3],\n",
              " [2, 30, 26, 8, 315, 2789, 1505, 4, 20, 4001, 3],\n",
              " [2, 684, 7282, 37, 7283, 3],\n",
              " [2, 80, 37, 2790, 94, 915, 7284, 7285, 3],\n",
              " [2, 366, 2728, 28, 597, 685, 14, 2130, 3],\n",
              " [2, 10, 5, 13, 209, 1506, 27, 7286, 3],\n",
              " [2, 393, 7287, 2791, 20, 15, 120, 7288, 3],\n",
              " [2, 174, 727, 52, 20, 14, 641, 16, 7289, 3],\n",
              " [2, 7290, 13, 686, 4, 109, 7291, 7292, 3],\n",
              " [2, 2792, 566, 5, 119, 97, 7293, 3],\n",
              " [2, 1767, 41, 28, 95, 415, 7294, 3],\n",
              " [2, 1304, 9, 21, 5, 38, 527, 7295, 3],\n",
              " [2, 51, 1027, 333, 38, 72, 7296, 3],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "vgFtCA9wVIfe"
      },
      "source": [
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\", split=' ', lower=False, oov_token='<UNK>')\n",
        "target_tokenizer.fit_on_texts(target_text_prepr)\n",
        "\n",
        "target_text_lines_enc = target_tokenizer.texts_to_sequences(target_text_prepr)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "gradient": {},
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "mIKa_oc8VIfe"
      },
      "source": [
        "target_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "qu_z0ozzVIff"
      },
      "source": [
        "input_vocab_size = len(input_tokenizer.word_index)\n",
        "target_vocab_size = len(target_tokenizer.word_index)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "p-w27LhpY1db",
        "outputId": "85578da2-8a7f-409b-c5ca-d9d445b120d0"
      },
      "source": [
        "print(\"Input vocab size: {}\".format(input_vocab_size))\n",
        "print(\"Target vocab size: {}\".format(target_vocab_size))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input vocab size: 20750\n",
            "Target vocab size: 4191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4bfzvcNvT-y"
      },
      "source": [
        "Padding is required in order to have a non-ragged tensor to feed to the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "MBOh9LQeY1dg"
      },
      "source": [
        "def pad(x):\n",
        "    return tf.keras.preprocessing.sequence.pad_sequences(x, padding=\"post\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "9zV0xz48Y1dh"
      },
      "source": [
        "input_text = pad(input_text_lines_enc)\n",
        "target_text = pad(target_text_lines_enc)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP1Ob62DmCGD",
        "outputId": "3567b6cc-b788-456d-f681-dfbe8dcd0e53"
      },
      "source": [
        "input_text"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   2,  796,  229, ...,    0,    0,    0],\n",
              "       [   2,   16, 6277, ...,    0,    0,    0],\n",
              "       [   2,   59,    6, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   2,   33,   43, ...,    0,    0,    0],\n",
              "       [   2,   17,   24, ...,    0,    0,    0],\n",
              "       [   2,  623,    5, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GVc41zvvdR9"
      },
      "source": [
        "## 2. The Transformer model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "FE_LiRvcVIfi"
      },
      "source": [
        "input_text_ = []\n",
        "target_text_ = []\n",
        "\n",
        "for line_number in range(0, len(input_text) - 4):\n",
        "    \n",
        "    input_verses = []\n",
        "    target_verses = []\n",
        "    \n",
        "    for i in range(4):\n",
        "        input_verses += list(input_text[line_number + i])\n",
        "        target_verses += list(target_text[line_number + i])\n",
        "    \n",
        "    input_text_.append(input_verses)\n",
        "    target_text_.append(target_verses)\n",
        "    \n",
        "input_text_ = np.array(input_text_)\n",
        "target_text_ = np.array(target_text_)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bII0gWDRVIfi",
        "outputId": "795ecd79-1987-4f16-d58a-eb81fbe545dd"
      },
      "source": [
        "input_text_.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14229, 72)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "7xGxZmlPY1dk"
      },
      "source": [
        "input_train, input_test, target_train, target_test = train_test_split(\n",
        "    input_text_, target_text_\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IN8x175vimK"
      },
      "source": [
        "The dataset is created by grouping the lines in batches and by shuffling them.\n",
        "\n",
        "Each input's line is in correspondence with its target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "tZWLq7g3Y1dl"
      },
      "source": [
        "BUFFER_SIZE = len(input_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
        "\n",
        "input_vocab_size = (\n",
        "    len(input_tokenizer.word_index) + 1\n",
        ")  # the +1 is added to take into account the id 0 of the padding\n",
        "\n",
        "target_vocab_size = (\n",
        "    len(target_tokenizer.word_index) + 1\n",
        ")\n",
        "\n",
        "max_length_targ, max_length_inp = target_text.shape[1], input_text.shape[1]\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(\n",
        "    BUFFER_SIZE\n",
        ")\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RHNAazT5Rs_"
      },
      "source": [
        "We define the positional encoding to add to the embedding.\n",
        "\n",
        "This allows to take into account the order of the characters in the input sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "f200V0QnkBBS"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "OvnGjGhvkD9R"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
        "    )\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "500eU4tu6n-g"
      },
      "source": [
        "We define two masks: \n",
        "\n",
        "one is used to mask the padding added to the sequences in the preprocessing step; \n",
        "\n",
        "the other one is used to mask the positions following the current one and not predicted yet;\n",
        "\n",
        "The first mask is used from both the encoder and the decoder, while the last mask is used only in the self-attention of the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "OVwx6Y4Tku1V"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "3p1-yIYimnvB"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "R-Q4J7EzfuLH"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxzWROrTM9ib"
      },
      "source": [
        "The *scaled_dot_product_attention* gets the attention weights by applying the softmax to the rescaled dot product between the query matrix and the key matrix, while the output is obtained by multiplying the value matrix for those attention weights.\n",
        "\n",
        "The query, key and value matrices are built by multiplying the embedding matrix with the query, key and value weight matrices, which initially are randomly initialized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "RoFZK1S3mtI5"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"\n",
        "    Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "      q: query shape == (..., seq_len_q, depth)\n",
        "      k: key shape == (..., seq_len_k, depth)\n",
        "      v: value shape == (..., seq_len_v, depth_v)\n",
        "      mask: Float tensor with shape broadcastable\n",
        "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "      output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += mask * -1e9\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
        "    attention_weights = tf.nn.softmax(\n",
        "        scaled_attention_logits, axis=-1\n",
        "    )  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlA3inNYQO89"
      },
      "source": [
        "The multi-headed attention allows to improve the performance of the attention mechanism by working with multiple sets of query, key and value weight matrices.\n",
        "\n",
        "These heads work in parallel and process at the same time all the lines of each batch.\n",
        "\n",
        "At the end, the results of all the attention heads are concatenated and multiplied by an additional weight matrix, to adjust the dimension before passing through the final *point_wise_feed_forward_network*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "_UpdBWkVnK02"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"\n",
        "        Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask\n",
        "        )\n",
        "\n",
        "        scaled_attention = tf.transpose(\n",
        "            scaled_attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(\n",
        "            scaled_attention, (batch_size, -1, self.d_model)\n",
        "        )  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "LkMP7DDAok4y"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Dense(dff, activation=\"relu\"),  # (batch_size, seq_len, dff)\n",
        "            tf.keras.layers.Dense(d_model),  # (batch_size, seq_len, d_model)\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO6yyZPWUON7"
      },
      "source": [
        "Each encoder is constituted by a multi-headed self-attention layer and by a final feed forward layer. \n",
        "\n",
        "Both sub-layers have a residual connection around them and are followed by a layer-normalization step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "Dat64C18otwC"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(\n",
        "            out1 + ffn_output\n",
        "        )  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GZslNuSZOKp"
      },
      "source": [
        "The decoder equals the encoder, a part from the fact that it contains a slightly different self-attention layer and an additional attention layer.\n",
        "\n",
        "Indeed, the decoder is characterized by a self-attention layer which focuses only on earlier positions in its input sequence, not looking at the positions which have not been predicted yet.\n",
        "\n",
        "What's more the decoder is also characterized by an attention layer which obtains its key and value matrices from the output of the encoder, while the query matrix is obtained from the output of the previous self-attention in the decoder.\n",
        "\n",
        "The encoder-decoder attention helps the decoder to focus on appropriate positions in the input sequence of the encoder during the translation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "7Vp44lQepI_P"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(\n",
        "            x, x, x, look_ahead_mask\n",
        "        )  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask\n",
        "        )  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(\n",
        "            ffn_output + out2\n",
        "        )  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_DyJiybrOr"
      },
      "source": [
        "The encoding component is a stack of encoders and the decoding component is a stack of decoders of the same number.\n",
        "\n",
        "At the beginning, in the encoding, each input character is turned into a vector using an embedding algorithm and adding the positional encoding to it.\n",
        "\n",
        "This happens only in the bottom-most encoder, while the following encoders take the output of the encoder which is directly below.\n",
        "\n",
        "The same for the decoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "awl9kiESpWBh"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        input_vocab_size,\n",
        "        maximum_position_encoding,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "47tQAEMwpnUj"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        target_vocab_size,\n",
        "        maximum_position_encoding,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [\n",
        "            DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
        "        ]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](\n",
        "                x, enc_output, training, look_ahead_mask, padding_mask\n",
        "            )\n",
        "\n",
        "            attention_weights[f\"decoder_layer{i+1}_block1\"] = block1\n",
        "            attention_weights[f\"decoder_layer{i+1}_block2\"] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TosN_TpKk1eN"
      },
      "source": [
        "In the transformer, the output of the encoding is passed to the stack of decoders and the output of the decoding is projected by a feed forward network into a vector of logits of dimension equal to the one of the target's vocabulary.\n",
        "\n",
        "Obviously this is done for each character of each line of each batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "qCNKKsQ-p99k"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        input_vocab_size,\n",
        "        target_vocab_size,\n",
        "        pe_input,\n",
        "        pe_target,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "            num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate\n",
        "        )\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(\n",
        "        self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask\n",
        "    ):\n",
        "\n",
        "        enc_output = self.encoder(\n",
        "            inp, training, enc_padding_mask\n",
        "        )  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask\n",
        "        )\n",
        "\n",
        "        final_output = self.final_layer(\n",
        "            dec_output\n",
        "        )  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLTOETK4_m6"
      },
      "source": [
        "## 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "LrdL396xqOL4"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 256\n",
        "dff = 1024\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "JFCVQIDjqQHv"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "1R9MlFs0qc5U"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcmLAk1Ut8vG"
      },
      "source": [
        "The loss is calculated using Sparse Categorical Crossentropy and the loss of the padding is masked.\n",
        "\n",
        "The same is done for the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "TBAaRBPsqkuo"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
        ")\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "31R26t9wqlLD"
      },
      "source": [
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.cast(tf.argmax(pred, axis=2), dtype=tf.int32))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "SkVkWvL7qoYu"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.Mean(name=\"train_accuracy\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "5UE3cWGVqvnS"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=input_vocab_size,\n",
        "    target_vocab_size=target_vocab_size,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate,\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "nSE2Rh-_qzo7"
      },
      "source": [
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vbeVUzwtoTE",
        "outputId": "33569fcf-b1b4-4592-ede1-efdc6e5ae25a"
      },
      "source": [
        "!tar chvfz checkpoints.tar.gz checkpoints"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints/\n",
            "checkpoints/wordlevel/\n",
            "checkpoints/wordlevel/ckpt-6.index\n",
            "checkpoints/wordlevel/ckpt-6.data-00000-of-00001\n",
            "checkpoints/wordlevel/checkpoint\n",
            "checkpoints/wordlevel/ckpt-3.index\n",
            "checkpoints/wordlevel/ckpt-4.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITVGgP8Su9MH"
      },
      "source": [
        "To train the decoder we use teacher forcing, calculating the loss between the predicted logits and the real id of the character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "n_VPs6ZOva15"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "1ce0FAOivleY",
        "outputId": "0247db71-32e6-44f3-eea6-adc57259bf28"
      },
      "source": [
        "EPOCHS = 30\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}\"\n",
        "            )\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print(f\"Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}\"\n",
        "    )\n",
        "\n",
        "    print(f\"Time taken for 1 epoch: {time.time() - start:.2f} secs\\n\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.3683 Accuracy 0.0003\n",
            "Epoch 1 Batch 50 Loss 8.1798 Accuracy 0.0359\n",
            "Epoch 1 Batch 100 Loss 7.9529 Accuracy 0.0538\n",
            "Epoch 1 Batch 150 Loss 7.7419 Accuracy 0.0598\n",
            "Epoch 1 Loss 7.6726 Accuracy 0.0624\n",
            "Time taken for 1 epoch: 38.20 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 6.8588 Accuracy 0.1244\n",
            "Epoch 2 Batch 50 Loss 6.5432 Accuracy 0.1257\n",
            "Epoch 2 Batch 100 Loss 6.2611 Accuracy 0.1259\n",
            "Epoch 2 Batch 150 Loss 6.0509 Accuracy 0.1297\n",
            "Epoch 2 Loss 6.0011 Accuracy 0.1312\n",
            "Time taken for 1 epoch: 27.55 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 5.5239 Accuracy 0.1491\n",
            "Epoch 3 Batch 50 Loss 5.4268 Accuracy 0.1546\n",
            "Epoch 3 Batch 100 Loss 5.3665 Accuracy 0.1617\n",
            "Epoch 3 Batch 150 Loss 5.3021 Accuracy 0.1684\n",
            "Epoch 3 Loss 5.2811 Accuracy 0.1703\n",
            "Time taken for 1 epoch: 27.86 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 5.0244 Accuracy 0.1885\n",
            "Epoch 4 Batch 50 Loss 4.9548 Accuracy 0.1995\n",
            "Epoch 4 Batch 100 Loss 4.8824 Accuracy 0.2071\n",
            "Epoch 4 Batch 150 Loss 4.8138 Accuracy 0.2138\n",
            "Epoch 4 Loss 4.7942 Accuracy 0.2156\n",
            "Time taken for 1 epoch: 28.29 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 4.5378 Accuracy 0.2393\n",
            "Epoch 5 Batch 50 Loss 4.4863 Accuracy 0.2430\n",
            "Epoch 5 Batch 100 Loss 4.4464 Accuracy 0.2466\n",
            "Epoch 5 Batch 150 Loss 4.3989 Accuracy 0.2508\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/wordlevel/ckpt-1\n",
            "Epoch 5 Loss 4.3838 Accuracy 0.2522\n",
            "Time taken for 1 epoch: 28.86 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 4.1385 Accuracy 0.2724\n",
            "Epoch 6 Batch 50 Loss 4.1498 Accuracy 0.2712\n",
            "Epoch 6 Batch 100 Loss 4.1143 Accuracy 0.2739\n",
            "Epoch 6 Batch 150 Loss 4.0792 Accuracy 0.2765\n",
            "Epoch 6 Loss 4.0683 Accuracy 0.2774\n",
            "Time taken for 1 epoch: 28.27 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 3.9441 Accuracy 0.2963\n",
            "Epoch 7 Batch 50 Loss 3.8775 Accuracy 0.2936\n",
            "Epoch 7 Batch 100 Loss 3.8496 Accuracy 0.2965\n",
            "Epoch 7 Batch 150 Loss 3.8216 Accuracy 0.2995\n",
            "Epoch 7 Loss 3.8109 Accuracy 0.3007\n",
            "Time taken for 1 epoch: 28.44 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 3.6121 Accuracy 0.3255\n",
            "Epoch 8 Batch 50 Loss 3.5767 Accuracy 0.3322\n",
            "Epoch 8 Batch 100 Loss 3.5076 Accuracy 0.3452\n",
            "Epoch 8 Batch 150 Loss 3.4258 Accuracy 0.3619\n",
            "Epoch 8 Loss 3.3984 Accuracy 0.3674\n",
            "Time taken for 1 epoch: 28.28 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 2.9366 Accuracy 0.4451\n",
            "Epoch 9 Batch 50 Loss 2.8809 Accuracy 0.4613\n",
            "Epoch 9 Batch 100 Loss 2.7702 Accuracy 0.4823\n",
            "Epoch 9 Batch 150 Loss 2.6666 Accuracy 0.5014\n",
            "Epoch 9 Loss 2.6348 Accuracy 0.5074\n",
            "Time taken for 1 epoch: 28.32 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 2.1532 Accuracy 0.5921\n",
            "Epoch 10 Batch 50 Loss 2.0765 Accuracy 0.6028\n",
            "Epoch 10 Batch 100 Loss 1.9988 Accuracy 0.6163\n",
            "Epoch 10 Batch 150 Loss 1.9156 Accuracy 0.6306\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/wordlevel/ckpt-2\n",
            "Epoch 10 Loss 1.8909 Accuracy 0.6348\n",
            "Time taken for 1 epoch: 28.97 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.4850 Accuracy 0.7060\n",
            "Epoch 11 Batch 50 Loss 1.4173 Accuracy 0.7165\n",
            "Epoch 11 Batch 100 Loss 1.3660 Accuracy 0.7252\n",
            "Epoch 11 Batch 150 Loss 1.3096 Accuracy 0.7355\n",
            "Epoch 11 Loss 1.2932 Accuracy 0.7385\n",
            "Time taken for 1 epoch: 28.37 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.9433 Accuracy 0.8053\n",
            "Epoch 12 Batch 50 Loss 0.9377 Accuracy 0.8032\n",
            "Epoch 12 Batch 100 Loss 0.9006 Accuracy 0.8099\n",
            "Epoch 12 Batch 150 Loss 0.8625 Accuracy 0.8171\n",
            "Epoch 12 Loss 0.8507 Accuracy 0.8192\n",
            "Time taken for 1 epoch: 28.31 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.6873 Accuracy 0.8562\n",
            "Epoch 13 Batch 50 Loss 0.6068 Accuracy 0.8672\n",
            "Epoch 13 Batch 100 Loss 0.5792 Accuracy 0.8728\n",
            "Epoch 13 Batch 150 Loss 0.5582 Accuracy 0.8771\n",
            "Epoch 13 Loss 0.5508 Accuracy 0.8785\n",
            "Time taken for 1 epoch: 28.45 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.4086 Accuracy 0.9069\n",
            "Epoch 14 Batch 50 Loss 0.3990 Accuracy 0.9107\n",
            "Epoch 14 Batch 100 Loss 0.3880 Accuracy 0.9126\n",
            "Epoch 14 Batch 150 Loss 0.3744 Accuracy 0.9153\n",
            "Epoch 14 Loss 0.3740 Accuracy 0.9153\n",
            "Time taken for 1 epoch: 28.35 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.3202 Accuracy 0.9242\n",
            "Epoch 15 Batch 50 Loss 0.2689 Accuracy 0.9376\n",
            "Epoch 15 Batch 100 Loss 0.2648 Accuracy 0.9385\n",
            "Epoch 15 Batch 150 Loss 0.2642 Accuracy 0.9382\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/wordlevel/ckpt-3\n",
            "Epoch 15 Loss 0.2619 Accuracy 0.9387\n",
            "Time taken for 1 epoch: 28.74 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.2163 Accuracy 0.9441\n",
            "Epoch 16 Batch 50 Loss 0.2020 Accuracy 0.9516\n",
            "Epoch 16 Batch 100 Loss 0.2046 Accuracy 0.9510\n",
            "Epoch 16 Batch 150 Loss 0.2038 Accuracy 0.9510\n",
            "Epoch 16 Loss 0.2019 Accuracy 0.9515\n",
            "Time taken for 1 epoch: 28.36 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.1244 Accuracy 0.9734\n",
            "Epoch 17 Batch 50 Loss 0.1555 Accuracy 0.9625\n",
            "Epoch 17 Batch 100 Loss 0.1604 Accuracy 0.9607\n",
            "Epoch 17 Batch 150 Loss 0.1598 Accuracy 0.9608\n",
            "Epoch 17 Loss 0.1602 Accuracy 0.9606\n",
            "Time taken for 1 epoch: 28.40 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.1456 Accuracy 0.9654\n",
            "Epoch 18 Batch 50 Loss 0.1408 Accuracy 0.9655\n",
            "Epoch 18 Batch 100 Loss 0.1382 Accuracy 0.9659\n",
            "Epoch 18 Batch 150 Loss 0.1375 Accuracy 0.9657\n",
            "Epoch 18 Loss 0.1384 Accuracy 0.9655\n",
            "Time taken for 1 epoch: 28.28 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.1514 Accuracy 0.9620\n",
            "Epoch 19 Batch 50 Loss 0.1183 Accuracy 0.9703\n",
            "Epoch 19 Batch 100 Loss 0.1188 Accuracy 0.9702\n",
            "Epoch 19 Batch 150 Loss 0.1178 Accuracy 0.9703\n",
            "Epoch 19 Loss 0.1176 Accuracy 0.9703\n",
            "Time taken for 1 epoch: 28.26 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.1030 Accuracy 0.9740\n",
            "Epoch 20 Batch 50 Loss 0.1051 Accuracy 0.9736\n",
            "Epoch 20 Batch 100 Loss 0.1032 Accuracy 0.9740\n",
            "Epoch 20 Batch 150 Loss 0.1030 Accuracy 0.9738\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/wordlevel/ckpt-4\n",
            "Epoch 20 Loss 0.1034 Accuracy 0.9736\n",
            "Time taken for 1 epoch: 28.69 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.0848 Accuracy 0.9767\n",
            "Epoch 21 Batch 50 Loss 0.0934 Accuracy 0.9761\n",
            "Epoch 21 Batch 100 Loss 0.0966 Accuracy 0.9755\n",
            "Epoch 21 Batch 150 Loss 0.0986 Accuracy 0.9750\n",
            "Epoch 21 Loss 0.0984 Accuracy 0.9750\n",
            "Time taken for 1 epoch: 28.22 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.1008 Accuracy 0.9767\n",
            "Epoch 22 Batch 50 Loss 0.0851 Accuracy 0.9785\n",
            "Epoch 22 Batch 100 Loss 0.0846 Accuracy 0.9783\n",
            "Epoch 22 Batch 150 Loss 0.0871 Accuracy 0.9776\n",
            "Epoch 22 Loss 0.0878 Accuracy 0.9775\n",
            "Time taken for 1 epoch: 28.29 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.0698 Accuracy 0.9812\n",
            "Epoch 23 Batch 50 Loss 0.0813 Accuracy 0.9798\n",
            "Epoch 23 Batch 100 Loss 0.0829 Accuracy 0.9791\n",
            "Epoch 23 Batch 150 Loss 0.0837 Accuracy 0.9788\n",
            "Epoch 23 Loss 0.0833 Accuracy 0.9790\n",
            "Time taken for 1 epoch: 28.28 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.0580 Accuracy 0.9837\n",
            "Epoch 24 Batch 50 Loss 0.0748 Accuracy 0.9808\n",
            "Epoch 24 Batch 100 Loss 0.0753 Accuracy 0.9806\n",
            "Epoch 24 Batch 150 Loss 0.0753 Accuracy 0.9807\n",
            "Epoch 24 Loss 0.0758 Accuracy 0.9806\n",
            "Time taken for 1 epoch: 28.25 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.0826 Accuracy 0.9780\n",
            "Epoch 25 Batch 50 Loss 0.0741 Accuracy 0.9807\n",
            "Epoch 25 Batch 100 Loss 0.0738 Accuracy 0.9811\n",
            "Epoch 25 Batch 150 Loss 0.0738 Accuracy 0.9812\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/wordlevel/ckpt-5\n",
            "Epoch 25 Loss 0.0739 Accuracy 0.9812\n",
            "Time taken for 1 epoch: 28.66 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.0643 Accuracy 0.9836\n",
            "Epoch 26 Batch 50 Loss 0.0594 Accuracy 0.9850\n",
            "Epoch 26 Batch 100 Loss 0.0625 Accuracy 0.9842\n",
            "Epoch 26 Batch 150 Loss 0.0621 Accuracy 0.9843\n",
            "Epoch 26 Loss 0.0616 Accuracy 0.9844\n",
            "Time taken for 1 epoch: 28.30 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.0433 Accuracy 0.9881\n",
            "Epoch 27 Batch 50 Loss 0.0561 Accuracy 0.9856\n",
            "Epoch 27 Batch 100 Loss 0.0549 Accuracy 0.9860\n",
            "Epoch 27 Batch 150 Loss 0.0549 Accuracy 0.9862\n",
            "Epoch 27 Loss 0.0550 Accuracy 0.9862\n",
            "Time taken for 1 epoch: 28.22 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.0386 Accuracy 0.9877\n",
            "Epoch 28 Batch 50 Loss 0.0515 Accuracy 0.9875\n",
            "Epoch 28 Batch 100 Loss 0.0500 Accuracy 0.9876\n",
            "Epoch 28 Batch 150 Loss 0.0501 Accuracy 0.9876\n",
            "Epoch 28 Loss 0.0499 Accuracy 0.9877\n",
            "Time taken for 1 epoch: 28.27 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.0395 Accuracy 0.9913\n",
            "Epoch 29 Batch 50 Loss 0.0452 Accuracy 0.9887\n",
            "Epoch 29 Batch 100 Loss 0.0444 Accuracy 0.9890\n",
            "Epoch 29 Batch 150 Loss 0.0445 Accuracy 0.9889\n",
            "Epoch 29 Loss 0.0444 Accuracy 0.9889\n",
            "Time taken for 1 epoch: 28.17 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.0350 Accuracy 0.9915\n",
            "Epoch 30 Batch 50 Loss 0.0413 Accuracy 0.9901\n",
            "Epoch 30 Batch 100 Loss 0.0404 Accuracy 0.9902\n",
            "Epoch 30 Batch 150 Loss 0.0415 Accuracy 0.9898\n",
            "Saving checkpoint for epoch 30 at ./checkpoints/wordlevel/ckpt-6\n",
            "Epoch 30 Loss 0.0412 Accuracy 0.9899\n",
            "Time taken for 1 epoch: 28.77 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz4YwsF04YEI"
      },
      "source": [
        "## 4. Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O44l1saVuebS"
      },
      "source": [
        "We define the *evaluate* function to preprocess the sentence in input to the encoder and to get the predicted ids of the translation.\n",
        "\n",
        "The ids of the translation are obtained by applying *argmax* to the predicted logits of the decoder.\n",
        "\n",
        "We begin feeding the decoder with the id of the start symbol and, at each new step, we pass to the decoder the sequence it has just thrown out.\n",
        "\n",
        "The translation stops when the end symbol is reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "BSNaKtSkvxcJ"
      },
      "source": [
        "def evaluate(sentence, max_length=200):\n",
        "\n",
        "    encoder_input = input_tokenizer.texts_to_sequences(sentence)\n",
        "    encoder_input = [x for l in encoder_input for x in l]\n",
        "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        [encoder_input], maxlen=max_length, padding=\"post\"\n",
        "    )\n",
        "    encoder_input = tf.convert_to_tensor(encoder_input)\n",
        "\n",
        "    output = tf.convert_to_tensor([output_tokenizer.word_index[\"^\"]])\n",
        "    output = tf.expand_dims(output, 0)\n",
        "    result = \"\"\n",
        "\n",
        "    for i in range(max_length):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output\n",
        "        )\n",
        "\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask,\n",
        "        )\n",
        "\n",
        "        # select the last character from the seq_len dimension\n",
        "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
        "        output = tf.concat(\n",
        "            [tf.cast(output, dtype=tf.int32), tf.cast(predicted_id, dtype=tf.int32)],\n",
        "            axis=-1,\n",
        "        )\n",
        "        result += output_tokenizer.index_word[predicted_id.numpy()[0][0]] + \" \"\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == output_tokenizer.word_index[\"$\"]:\n",
        "            break\n",
        "\n",
        "    # output.shape (1, tokens)\n",
        "\n",
        "    return result, attention_weights"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "PkCDxGdeyF9f"
      },
      "source": [
        "def print_translation(sentence, result, ground_truth):\n",
        "    print(f'{\"Input:\":15s}: {sentence}')\n",
        "    print(f'{\"Prediction\":15s}: {result}')\n",
        "    print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "B5cULw_54F8w",
        "outputId": "f13542d2-019b-4680-cbeb-3e200b0d5421"
      },
      "source": [
        "sentence = \"^\"\n",
        "ground_truth = \"\"\n",
        "\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ^\n",
            "Prediction     : Mo pa ri tà tor men to pa ren ti $ \n",
            "Ground truth   : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "V33sFY3iyLLE",
        "outputId": "ac404a09-39a2-40d6-8642-1f2a86d0a7b3"
      },
      "source": [
        "sentence = \"^ Buonasera a tutti $\"\n",
        "ground_truth = \"\"\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ^ Buonasera a tutti $\n",
            "Prediction     : Te ba ro um bri o u sci tar e a gra da ro». $ \n",
            "Ground truth   : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPLXjcQVriKf",
        "outputId": "0e50d979-b996-421d-d2a1-2b4c58ad318b"
      },
      "source": [
        "sentence = \"^ Io non so ben ridir com’ i’ v’intrai, $\"\n",
        "ground_truth = \"|Io |non |so |ben |ri|dir |com’ |i’ |v’ in|trai,\"\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ^ Io non so ben ridir com’ i’ v’intrai, $\n",
            "Prediction     : I si o u sci zio o fug gi lio o u sci to, $ \n",
            "Ground truth   : |Io |non |so |ben |ri|dir |com’ |i’ |v’ in|trai,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-psFsRBr5rE"
      },
      "source": [
        "# 5. Autoregressive generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "avrTxm8pr5rF"
      },
      "source": [
        "class TextGenerator:\n",
        "    def __init__(self, encoder, decoder, fc, tokenizer):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.fc = fc\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def generate(self, seed):\n",
        "        encoder_input = [tokenizer.word_index[i] for i in list(map(str, seed))]\n",
        "        encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            [encoder_input], maxlen=65, padding=\"post\"\n",
        "        )\n",
        "        encoder_input = tf.convert_to_tensor(encoder_input)\n",
        "\n",
        "        dec_input = tf.convert_to_tensor([self.tokenizer.word_index[\"^\"]])\n",
        "        dec_input = tf.expand_dims(dec_input, 0)\n",
        "\n",
        "        index_word = self.tokenizer.index_word\n",
        "\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, dec_input\n",
        "        )\n",
        "\n",
        "        end_symbol = \"$\"\n",
        "\n",
        "        result = \"\"\n",
        "\n",
        "        output = \"\"\n",
        "\n",
        "        initial_state = self.encoder(\n",
        "            encoder_input, False, enc_padding_mask\n",
        "        )  # tf.zeros((1, 65, 256)) #tf.random.uniform((1, 65, 256))\n",
        "\n",
        "        while output != end_symbol:\n",
        "\n",
        "            dec_output, attention_weights = self.decoder(\n",
        "                dec_input, initial_state, False, combined_mask, dec_padding_mask\n",
        "            )\n",
        "\n",
        "            logits = self.fc(dec_output)\n",
        "            logits = logits[:, -1, :]\n",
        "            logits = tf.reshape(logits, (1, 82))\n",
        "\n",
        "            output = tf.random.categorical(logits, 1)\n",
        "\n",
        "            output = output.numpy()[0][0]\n",
        "            output = index_word[output]\n",
        "\n",
        "            result += output\n",
        "\n",
        "            result_encoded = [tokenizer.word_index[i] for i in list(map(str, result))]\n",
        "            result_encoded = tf.convert_to_tensor(result_encoded)\n",
        "            result_encoded = tf.expand_dims(result_encoded, 0)\n",
        "\n",
        "            dec_input = result_encoded\n",
        "\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "d0CZpwFC8Ic3"
      },
      "source": [
        "enc = transformer.encoder\n",
        "dec = transformer.decoder\n",
        "fc = transformer.final_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "cxoNus12r5rF"
      },
      "source": [
        "gen = TextGenerator(enc, dec, fc, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "gradient": {},
        "id": "BQy622iU-es0",
        "outputId": "7c2cbe90-5cb3-4d74-f630-5340b07be733"
      },
      "source": [
        "gen.generate(\"^C\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|CCoC|dbbbì|CCCoC|Cib|CCdCCo|Ccbbì|bì,|bib|CcCCoC|bbb,|bbbìbììbì,|bì|bì|bì|bìì|b|bè,$'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "gradient": {},
        "id": "4avXbdgfr5rF",
        "outputId": "f4944fc6-a1cf-4c47-a6bf-9ddd619e190e"
      },
      "source": [
        "gen.generate(\"^Allora ci vediamo domani$\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|lo|lo|ra |ci |ve|dia|mo |do|ma|ni$'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}