{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "54j16swJY1dW"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/wordlevel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "8RuMqNB4ujuT"
   },
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "lsuXc5StY1dY"
   },
   "outputs": [],
   "source": [
    "input_file = \"data/divina_textonly.txt\"\n",
    "target_file = \"data/divina_syll_textonly.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "ACAEUyITY1dY",
    "outputId": "26daf544-3700-428a-c752-b10e0bbd6d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input text: 558637 characters\n",
      "Length of target text: 873431 characters\n"
     ]
    }
   ],
   "source": [
    "input_text_raw = open(input_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
    "target_text_raw = open(target_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
    "print(\"Length of input text: {} characters\".format(len(input_text_raw)))\n",
    "print(\"Length of target text: {} characters\".format(len(target_text_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    For each line in the file, add start symbol \"^\" in the beginning and end symbol \"$\" in the end\n",
    "    \"\"\"\n",
    "    return [\"^ \" + line.strip() + \" $\" for line in text.split(\"\\n\") if line.strip() != \"\"]\n",
    "\n",
    "\n",
    "input_text_prepr = preprocess(input_text_raw)\n",
    "target_text_prepr = preprocess(target_text_raw)\n",
    "target_text_prepr = list(map(lambda x: re.sub('\\|', ' ', x), target_text_prepr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^  Nel  mez zo  del  cam min  di  no stra  vi ta $',\n",
       " '^  mi  ri tro vai  per  u na  sel va o scu ra, $',\n",
       " '^  ché  la  di rit ta  via  e ra  smar ri ta. $',\n",
       " '^  Ahi  quan to a  dir  qual  e ra è  co sa  du ra $',\n",
       " '^  e sta  sel va  sel vag gia e  a spra e  for te $',\n",
       " '^  che  nel  pen sier  ri no va  la  pa u ra! $',\n",
       " '^  Tan t’ è  a ma ra  che  po co è  più  mor te; $',\n",
       " '^  ma  per  trat tar  del  ben  ch’ i’  vi  tro vai, $',\n",
       " '^  di rò  de  l’ al tre  co se  ch’ i’  v’ ho  scor te. $',\n",
       " '^  Io  non  so  ben  ri dir  com’  i’  v’ in trai, $',\n",
       " '^  tan t’ e ra  pien  di  son no  a  quel  pun to $',\n",
       " '^  che  la  ve ra ce  via  ab ban do nai. $',\n",
       " '^  Ma  poi  ch’ i’  fui  al  piè  d’ un  col le  giun to, $',\n",
       " '^  là  do ve  ter mi na va  quel la  val le $',\n",
       " '^  che  m’ a vea  di  pa u ra il  cor  com pun to, $',\n",
       " '^  guar dai  in  al to e  vi di  le  sue  spal le $',\n",
       " '^  ve sti te  già  de’  rag gi  del  pia ne ta $',\n",
       " '^  che  me na  drit to al trui  per  o gne  cal le. $',\n",
       " '^  Al lor  fu  la  pa u ra un  po co  que ta, $',\n",
       " '^  che  nel  la go  del  cor  m’ e ra  du ra ta $',\n",
       " '^  la  not te  ch’ i’  pas sai  con  tan ta  pie ta. $',\n",
       " '^  E  co me  quei  che  con  le na af fan na ta, $',\n",
       " '^  u sci to  fuor  del  pe la go a  la  ri va, $',\n",
       " '^  si  vol ge a  l’ ac qua  pe ri glio sa e  gua ta, $',\n",
       " '^  co sì  l’ a ni mo  mio,  ch’ an cor  fug gi va, $',\n",
       " '^  si  vol se a  re tro a  ri mi rar  lo  pas so $',\n",
       " '^  che  non  la sciò  già  mai  per so na  vi va. $',\n",
       " '^  Poi  ch’ èi  po sa to un  po co il  cor po  las so, $',\n",
       " '^  ri pre si  via  per  la  piag gia  di ser ta, $',\n",
       " '^  sì  che ’l  piè  fer mo  sem pre e ra ’l  più  bas so. $',\n",
       " '^  Ed  ec co,  qua si al  co min ciar  de  l’ er ta, $',\n",
       " '^  u na  lon za  leg ge ra e  pre sta  mol to, $',\n",
       " '^  che  di  pel  ma co la to e ra  co ver ta; $',\n",
       " '^  e  non  mi  si  par tia  di nan zi al  vol to, $',\n",
       " '^  an zi ’m pe di va  tan to il  mio  cam mi no, $',\n",
       " '^  ch’ i’  fui  per  ri tor nar  più  vol te  vòl to. $',\n",
       " '^  Tem p’ e ra  dal  prin ci pio  del  mat ti no, $',\n",
       " '^  e ’l  sol  mon ta va ’n  sù  con  quel le  stel le $',\n",
       " '^  ch’ e ran  con  lui  quan do  l’ a mor  di vi no $',\n",
       " '^  mos se  di  pri ma  quel le  co se  bel le; $',\n",
       " '^  sì  ch’ a  be ne  spe rar  m’ e ra  ca gio ne $',\n",
       " '^  di  quel la  fie ra a  la  ga et ta  pel le $',\n",
       " '^  l’ o ra  del  tem po e  la  dol ce  sta gio ne; $',\n",
       " '^  ma  non  sì  che  pa u ra  non  mi  des se $',\n",
       " '^  la  vi sta  che  m’ ap par ve  d’ un  le o ne. $',\n",
       " '^  Que sti  pa rea  che  con tra  me  ve nis se $',\n",
       " '^  con  la  te st’ al ta e  con  rab bio sa  fa me, $',\n",
       " '^  sì  che  pa rea  che  l’ ae re  ne  tre mes se. $',\n",
       " '^  Ed  u na  lu pa,  che  di  tut te  bra me $',\n",
       " '^  sem bia va  car ca  ne  la  sua  ma grez za, $',\n",
       " '^  e  mol te  gen ti  fé  già  vi ver  gra me, $',\n",
       " '^  que sta  mi  por se  tan to  di  gra vez za $',\n",
       " '^  con  la  pa u ra  ch’ u scia  di  sua  vi sta, $',\n",
       " '^  ch’ io  per dei  la  spe ran za  de  l’ al tez za. $',\n",
       " '^  E  qual  è  quei  che  vo lon tie ri ac qui sta, $',\n",
       " '^  e  giu gne ’l  tem po  che  per der  lo  fa ce, $',\n",
       " '^  che ’n  tut ti  suoi  pen sier  pian ge e  s’ at tri sta; $',\n",
       " '^  tal  mi  fe ce  la  be stia  san za  pa ce, $',\n",
       " '^  che,  ve nen do mi ’n con tro, a  po co a  po co $',\n",
       " '^  mi  ri pi gne va  là  do ve ’l  sol  ta ce. $',\n",
       " '^  Men tre  ch’ i’  ro vi na va in  bas so  lo co, $',\n",
       " '^  di nan zi a  li oc chi  mi  si  fu  of fer to $',\n",
       " '^  chi  per  lun go  si len zio  pa rea  fio co. $',\n",
       " '^  Quan do  vi di  co stui  nel  gran  di ser to, $',\n",
       " '^ «  Mi se re re  di  me»,  gri dai  a  lui, $',\n",
       " '^ «  qual  che  tu  sii,  od  om bra od  o mo  cer to!». $',\n",
       " '^  Ri spuo se mi:«  Non  o mo, o mo  già  fui, $',\n",
       " '^  e  li  pa ren ti  miei  fu ron  lom bar di, $',\n",
       " '^  man to a ni  per  pa trï a am be dui. $',\n",
       " '^  Nac qui  sub  Iu lio, an cor  che  fos se  tar di, $',\n",
       " '^  e  vis si a  Ro ma  sot to ’l  buo no Au gu sto $',\n",
       " '^  nel  tem po  de  li  dèi  fal si e  bu giar di. $',\n",
       " '^  Po e ta  fui,  e  can tai  di  quel  giu sto $',\n",
       " '^  fi gliuol  d’ An chi se  che  ven ne  di  Tro ia, $',\n",
       " '^  poi  che ’l  su per bo I lï ón  fu  com bu sto. $',\n",
       " '^  Ma  tu  per ché  ri tor ni a  tan ta  no ia? $',\n",
       " '^  per ché  non  sa li il  di let to so  mon te $',\n",
       " '^  ch’ è  prin ci pio e  ca gion  di  tut ta  gio ia?». $',\n",
       " '^ «  Or  se’  tu  quel  Vir gi lio e  quel la  fon te $',\n",
       " '^  che  span di  di  par lar  sì  lar go  fiu me?», $',\n",
       " '^  ri spuo s’ io  lui  con  ver go gno sa  fron te. $',\n",
       " '^ «  O  de  li al tri  po e ti o no re e  lu me, $',\n",
       " '^  va glia mi ’l  lun go  stu dio e ’l  gran de a mo re $',\n",
       " '^  che  m’ ha  fat to  cer car  lo  tuo  vo lu me. $',\n",
       " '^  Tu  se’  lo  mio  ma e stro e ’l  mio  au to re, $',\n",
       " '^  tu  se’  so lo  co lui  da  cu’  io  tol si $',\n",
       " '^  lo  bel lo  sti lo  che  m’ ha  fat to o no re. $',\n",
       " '^  Ve di  la  be stia  per  cu’  io  mi  vol si; $',\n",
       " '^  a iu ta mi  da  lei,  fa mo so  sag gio, $',\n",
       " '^  ch’ el la  mi  fa  tre mar  le  ve ne e i  pol si». $',\n",
       " '^ «  A  te  con vien  te ne re al tro  vï ag gio», $',\n",
       " '^  ri spuo se,  poi  che  la gri mar  mi  vi de, $',\n",
       " '^ «  se  vuo’  cam par  d’ e sto  lo co  sel vag gio; $',\n",
       " '^  ché  que sta  be stia,  per  la  qual  tu  gri de, $',\n",
       " '^  non  la scia al trui  pas sar  per  la  sua  via, $',\n",
       " '^  ma  tan to  lo ’m pe di sce  che  l’ uc ci de; $',\n",
       " '^  e  ha  na tu ra  sì  mal va gia e  ria, $',\n",
       " '^  che  mai  non  em pie  la  bra mo sa  vo glia, $',\n",
       " '^  e  do po ’l  pa sto ha  più  fa me  che  pria. $',\n",
       " '^  Mol ti  son  li a ni ma li a  cui  s’ am mo glia, $',\n",
       " '^  e  più  sa ran no an co ra, in fin  che ’l  vel tro $',\n",
       " '^  ver rà,  che  la  fa rà  mo rir  con  do glia. $',\n",
       " '^  Que sti  non  ci be rà  ter ra  né  pel tro, $',\n",
       " '^  ma  sa pï en za, a mo re  e  vir tu te, $',\n",
       " '^  e  sua  na zion  sa rà  tra  fel tro e  fel tro. $',\n",
       " '^  Di  quel la u mi le I ta lia  fia  sa lu te $',\n",
       " '^  per  cui  mo rì  la  ver gi ne  Cam mil la, $',\n",
       " '^  Eu ria lo e  Tur no e  Ni so  di  fe ru te. $',\n",
       " '^  Que sti  la  cac ce rà  per  o gne  vil la, $',\n",
       " '^  fin  che  l’ av rà  ri mes sa  ne  lo ’n fer no, $',\n",
       " '^  là  on de ’n vi dia  pri ma  di par til la. $',\n",
       " '^  On d’ io  per  lo  tuo  me’  pen so e  di scer no $',\n",
       " '^  che  tu  mi  se gui, e  io  sa rò  tua  gui da, $',\n",
       " '^  e  trar rot ti  di  qui  per  lo co et ter no; $',\n",
       " '^  o ve u di rai  le  di spe ra te  stri da, $',\n",
       " '^  ve drai  li an ti chi  spi ri ti  do len ti, $',\n",
       " '^  ch’ a  la  se con da  mor te  cia scun  gri da; $',\n",
       " '^  e  ve de rai  co lor  che  son  con ten ti $',\n",
       " '^  nel  fo co,  per ché  spe ran  di  ve ni re $',\n",
       " '^  quan do  che  sia  a  le  be a te  gen ti. $',\n",
       " '^  A  le  quai  poi  se  tu  vor rai  sa li re, $',\n",
       " '^  a ni ma  fia  a  ciò  più  di  me  de gna: $',\n",
       " '^  con  lei  ti  la sce rò  nel  mio  par ti re; $',\n",
       " '^  ché  quel lo im pe ra dor  che  là  sù  re gna, $',\n",
       " '^  per ch’ i’  fu’  ri bel lan te a  la  sua  leg ge, $',\n",
       " '^  non  vuol  che ’n  sua  cit tà  per  me  si  ve gna. $',\n",
       " '^  In  tut te  par ti im pe ra e  qui vi  reg ge; $',\n",
       " '^  qui vi è  la  sua  cit tà  e  l’ al to  seg gio: $',\n",
       " '^  oh  fe li ce  co lui  cu’  i vi e leg ge!». $',\n",
       " '^  E  io  a  lui:«  Po e ta, io  ti  ri cheg gio $',\n",
       " '^  per  quel lo  Dio  che  tu  non  co no sce sti, $',\n",
       " '^  ac ciò  ch’ io  fug ga  que sto  ma le e  peg gio, $',\n",
       " '^  che  tu  mi  me ni  là  do v’ or  di ce sti, $',\n",
       " '^  sì  ch’ io  veg gia  la  por ta  di  san  Pie tro $',\n",
       " '^  e  co lor  cui  tu  fai  co tan to  me sti». $',\n",
       " '^  Al lor  si  mos se, e  io  li  ten ni  die tro. $',\n",
       " '^  Lo  gior no  se  n’ an da va, e  l’ ae re  bru no $',\n",
       " '^  to glie va  li a ni mai  che  so no in  ter ra $',\n",
       " '^  da  le  fa ti che  lo ro; e  io  sol  u no $',\n",
       " '^  m’ ap pa rec chia va a  so ste ner  la  guer ra $',\n",
       " '^  sì  del  cam mi no e  sì  de  la  pie ta te, $',\n",
       " '^  che  ri trar rà  la  men te  che  non  er ra. $',\n",
       " '^  O  mu se, o  al to in ge gno, or  m’ a iu ta te; $',\n",
       " '^  o  men te  che  scri ve sti  ciò  ch’ io  vi di, $',\n",
       " '^  qui  si  par rà  la  tua  no bi li ta te. $',\n",
       " '^  Io  co min ciai:«  Po e ta  che  mi  gui di, $',\n",
       " '^  guar da  la  mia  vir tù  s’ el l’ è  pos sen te, $',\n",
       " '^  pri ma  ch’ a  l’ al to  pas so  tu  mi  fi di. $',\n",
       " '^  Tu  di ci  che  di  Sil vï o il  pa ren te, $',\n",
       " '^  cor rut ti bi le an co ra, ad  im mor ta le $',\n",
       " '^  se co lo an dò,  e  fu  sen si bil men te. $',\n",
       " '^  Pe rò,  se  l’ av ver sa rio  d’ o gne  ma le $',\n",
       " '^  cor te se i  fu,  pen san do  l’ al to ef fet to $',\n",
       " '^  ch’ u scir  do vea  di  lui,  e ’l  chi  e ’l  qua le $',\n",
       " '^  non  pa re in de gno ad  o mo  d’ in tel let to; $',\n",
       " '^  ch’ e’  fu  de  l’ al ma  Ro ma e  di  suo im pe ro $',\n",
       " '^  ne  l’ em pi rë o  ciel  per  pa dre e let to: $',\n",
       " '^  la  qua le e ’l  qua le, a  vo ler  dir  lo  ve ro, $',\n",
       " '^  fu  sta bi li ta  per  lo  lo co  san to $',\n",
       " '^  u’  sie de il  suc ces sor  del  mag gior  Pie ro. $',\n",
       " '^  Per  que st’ an da ta on de  li  dai  tu  van to, $',\n",
       " '^  in te se  co se  che  fu ron  ca gio ne $',\n",
       " '^  di  sua  vit to ria e  del  pa pa le am man to. $',\n",
       " '^  An dov vi  poi  lo  Vas  d’ e le zï o ne, $',\n",
       " '^  per  re car ne  con for to a  quel la  fe de $',\n",
       " '^  ch’ è  prin ci pio a  la  via  di  sal va zio ne. $',\n",
       " '^  Ma  io,  per ché  ve nir vi? o  chi ’l  con ce de? $',\n",
       " '^  Io  non  E në a,  io  non  Pau lo  so no; $',\n",
       " '^  me  de gno a  ciò  né  io  né  al tri ’l  cre de. $',\n",
       " '^  Per  che,  se  del  ve ni re io  m’ ab ban do no, $',\n",
       " '^  te mo  che  la  ve nu ta  non  sia  fol le. $',\n",
       " '^  Se’  sa vio; in ten di  me’  ch’ i’  non  ra gio no». $',\n",
       " '^  E  qual  è  quei  che  di svuol  ciò  che  vol le $',\n",
       " '^  e  per  no vi  pen sier  can gia  pro po sta, $',\n",
       " '^  sì  che  dal  co min ciar  tut to  si  tol le, $',\n",
       " '^  tal  mi  fe c’ ï o ’n  quel la o scu ra  co sta, $',\n",
       " '^  per ché,  pen san do,  con su mai  la ’m pre sa $',\n",
       " '^  che  fu  nel  co min ciar  co tan to  to sta. $',\n",
       " '^ «  S’ i’  ho  ben  la  pa ro la  tua  in te sa», $',\n",
       " '^  ri spuo se  del  ma gna ni mo  quel l’ om bra, $',\n",
       " '^ «  l’ a ni ma  tua  è  da  vil ta de of fe sa; $',\n",
       " '^  la  qual  mol te  fï a te  l’ o mo in gom bra $',\n",
       " '^  sì  che  d’ on ra ta im pre sa  lo  ri vol ve, $',\n",
       " '^  co me  fal so  ve der  be stia  quan d’ om bra. $',\n",
       " '^  Da  que sta  te ma ac ciò  che  tu  ti  sol ve, $',\n",
       " '^  di rot ti  per ch’ io  ven ni e  quel  ch’ io ’n te si $',\n",
       " '^  nel  pri mo  pun to  che  di  te  mi  dol ve. $',\n",
       " '^  Io  e ra  tra  co lor  che  son  so spe si, $',\n",
       " '^  e  don na  mi  chia mò  be a ta e  bel la, $',\n",
       " '^  tal  che  di  co man da re io  la  ri chie si. $',\n",
       " '^  Lu ce van  li oc chi  suoi  più  che  la  stel la; $',\n",
       " '^  e  co min ciom mi a  dir  so a ve e  pia na, $',\n",
       " '^  con  an ge li ca  vo ce, in  sua  fa vel la: $',\n",
       " '^ “  O  a ni ma  cor te se  man to a na, $',\n",
       " '^  di  cui  la  fa ma an cor  nel  mon do  du ra, $',\n",
       " '^  e  du re rà  quan to ’l  mon do  lon ta na, $',\n",
       " '^  l’ a mi co  mio,  e  non  de  la  ven tu ra, $',\n",
       " '^  ne  la  di ser ta  piag gia è  im pe di to $',\n",
       " '^  sì  nel  cam min,  che  vòl t’ è  per  pa u ra; $',\n",
       " '^  e  te mo  che  non  sia  già  sì  smar ri to, $',\n",
       " '^  ch’ io  mi  sia  tar di al  soc cor so  le va ta, $',\n",
       " '^  per  quel  ch’ i’  ho  di  lui  nel  cie lo u di to. $',\n",
       " '^  Or  mo vi, e  con  la  tua  pa ro la or na ta $',\n",
       " '^  e  con  ciò  c’ ha  me stie ri al  suo  cam pa re, $',\n",
       " '^  l’ a iu ta  sì  ch’ i’  ne  sia  con so la ta. $',\n",
       " '^  I’  son  Bea tri ce  che  ti  fac cio an da re; $',\n",
       " '^  ve gno  del  lo co o ve  tor nar  di sio; $',\n",
       " '^  a mor  mi  mos se,  che  mi  fa  par la re. $',\n",
       " '^  Quan do  sa rò  di nan zi al  se gnor  mio, $',\n",
       " '^  di  te  mi  lo de rò  so ven te a  lui”. $',\n",
       " '^  Ta cet te al lo ra, e  poi  co min cia’  io: $',\n",
       " '^ “  O  don na  di  vir tù  so la  per  cui $',\n",
       " '^  l’ u ma na  spe zie ec ce de o gne  con ten to $',\n",
       " '^  di  quel  ciel  c’ ha  mi nor  li  cer chi  sui, $',\n",
       " '^  tan to  m’ ag gra da il  tuo  co man da men to, $',\n",
       " '^  che  l’ u bi dir,  se  già  fos se,  m’ è  tar di; $',\n",
       " '^  più  non  t’ è  uo’  ch’ a prir mi il  tuo  ta len to. $',\n",
       " '^  Ma  dim mi  la  ca gion  che  non  ti  guar di $',\n",
       " '^  de  lo  scen der  qua  giu so in  que sto  cen tro $',\n",
       " '^  de  l’ am pio  lo co o ve  tor nar  tu  ar di”. $',\n",
       " '^ “  Da  che  tu  vuo’  sa ver  co tan to a  den tro, $',\n",
       " '^  di rot ti  brie ve men te”,  mi  ri spuo se, $',\n",
       " '^ “  per ch’ i’  non  te mo  di  ve nir  qua  en tro. $',\n",
       " '^  Te mer  si  dee  di  so le  quel le  co se $',\n",
       " '^  c’ han no  po ten za  di  fa re al trui  ma le; $',\n",
       " '^  de  l’ al tre  no,  ché  non  son  pa u ro se. $',\n",
       " '^  I’  son  fat ta  da  Dio,  sua  mer cé,  ta le, $',\n",
       " '^  che  la  vo stra  mi se ria  non  mi  tan ge, $',\n",
       " '^  né  fiam ma  d’ e sto ’n cen dio  non  m’ as sa le. $',\n",
       " '^  Don na è  gen til  nel  ciel  che  si  com pian ge $',\n",
       " '^  di  que sto ’m pe di men to o v’ io  ti  man do, $',\n",
       " '^  sì  che  du ro  giu di cio  là  sù  fran ge. $',\n",
       " '^  Que sta  chie se  Lu cia  in  suo  di man do $',\n",
       " '^  e  dis se:— Or  ha  bi so gno il  tuo  fe de le $',\n",
       " '^  di  te,  e  io  a  te  lo  rac co man do—. $',\n",
       " '^  Lu cia,  ni mi ca  di  cia scun  cru de le, $',\n",
       " '^  si  mos se, e  ven ne al  lo co  do v’ i’  e ra, $',\n",
       " '^  che  mi  se dea  con  l’ an ti ca  Ra che le. $',\n",
       " '^  Dis se:—  Bea tri ce,  lo da  di  Dio  ve ra, $',\n",
       " '^  ché  non  soc cor ri  quei  che  t’ a mò  tan to, $',\n",
       " '^  ch’ u scì  per  te  de  la  vol ga re  schie ra? $',\n",
       " '^  Non  o di  tu  la  pie ta  del  suo  pian to, $',\n",
       " '^  non  ve di  tu  la  mor te  che ’l  com bat te $',\n",
       " '^  su  la  fiu ma na o ve ’l  mar  non  ha  van to?-. $',\n",
       " '^  Al  mon do  non  fur  mai  per so ne  rat te $',\n",
       " '^  a  far  lor  pro  o  a  fug gir  lor  dan no, $',\n",
       " '^  com’  io,  do po  co tai  pa ro le  fat te, $',\n",
       " '^  ven ni  qua  giù  del  mio  be a to  scan no, $',\n",
       " '^  fi dan do mi  del  tuo  par la re o ne sto, $',\n",
       " '^  ch’ o no ra  te  e  quei  ch’ u di to  l’ han no”. $',\n",
       " '^  Po scia  che  m’ eb be  ra gio na to  que sto, $',\n",
       " '^  li oc chi  lu cen ti  la gri man do  vol se, $',\n",
       " '^  per  che  mi  fe ce  del  ve nir  più  pre sto. $',\n",
       " '^  E  ven ni a  te  co sì  com’  el la  vol se: $',\n",
       " '^  d’ i nan zi a  quel la  fie ra  ti  le vai $',\n",
       " '^  che  del  bel  mon te il  cor to an dar  ti  tol se. $',\n",
       " '^  Dun que:  che  è?  per ché,  per ché  re stai, $',\n",
       " '^  per ché  tan ta  vil tà  nel  co re al let te, $',\n",
       " '^  per ché  ar di re e  fran chez za  non  hai, $',\n",
       " '^  po scia  che  tai  tre  don ne  be ne det te $',\n",
       " '^  cu ran  di  te  ne  la  cor te  del  cie lo, $',\n",
       " '^  e ’l  mio  par lar  tan to  ben  ti  pro met te?». $',\n",
       " '^  Qua li  fio ret ti  dal  not tur no  ge lo $',\n",
       " '^  chi na ti e  chiu si,  poi  che ’l  sol  li ’m bian ca, $',\n",
       " '^  si  driz zan  tut ti a per ti in  lo ro  ste lo, $',\n",
       " '^  tal  mi  fe c’ io  di  mia  vir tu de  stan ca, $',\n",
       " '^  e  tan to  buo no ar di re al  cor  mi  cor se, $',\n",
       " '^  ch’ i’  co min ciai  co me  per so na  fran ca: $',\n",
       " '^ «  Oh  pie to sa  co lei  che  mi  soc cor se! $',\n",
       " '^  e  te  cor te se  ch’ u bi di sti  to sto $',\n",
       " '^  a  le  ve re  pa ro le  che  ti  por se! $',\n",
       " '^  Tu  m’ hai  con  di si de rio il  cor  di spo sto $',\n",
       " '^  sì  al  ve nir  con  le  pa ro le  tue, $',\n",
       " '^  ch’ i’  son  tor na to  nel  pri mo  pro po sto. $',\n",
       " '^  Or  va,  ch’ un  sol  vo le re è  d’ am be due: $',\n",
       " '^  tu  du ca,  tu  se gno re e  tu  ma e stro». $',\n",
       " '^  Co sì  li  dis si; e  poi  che  mos so  fue, $',\n",
       " '^  in trai  per  lo  cam mi no al to e  sil ve stro. $',\n",
       " '^ “  Per  me  si  va  ne  la  cit tà  do len te, $',\n",
       " '^  per  me  si  va  ne  l’ et ter no  do lo re, $',\n",
       " '^  per  me  si  va  tra  la  per du ta  gen te. $',\n",
       " '^  Giu sti zia  mos se il  mio  al to  fat to re; $',\n",
       " '^  fe ce mi  la  di vi na  po de sta te, $',\n",
       " '^  la  som ma  sa pï en za e ’l  pri mo a mo re. $',\n",
       " '^  Di nan zi a  me  non  fuor  co se  cre a te $',\n",
       " '^  se  non  et ter ne, e  io  et ter no  du ro. $',\n",
       " '^  La scia te o gne  spe ran za,  voi  ch’ in tra te”. $',\n",
       " '^  Que ste  pa ro le  di  co lo re o scu ro $',\n",
       " '^  vi d’ ï o  scrit te al  som mo  d’ u na  por ta; $',\n",
       " '^  per  ch’ io:«  Ma e stro, il  sen so  lor  m’ è  du ro». $',\n",
       " '^  Ed  el li a  me,  co me  per so na ac cor ta: $',\n",
       " '^ «  Qui  si  con vien  la scia re o gne  so spet to; $',\n",
       " '^  o gne  vil tà  con vien  che  qui  sia  mor ta. $',\n",
       " '^  Noi  siam  ve nu ti al  lo co o v’ i’  t’ ho  det to $',\n",
       " '^  che  tu  ve drai  le  gen ti  do lo ro se $',\n",
       " '^  c’ han no  per du to il  ben  de  l’ in tel let to». $',\n",
       " '^  E  poi  che  la  sua  ma no a  la  mia  puo se $',\n",
       " '^  con  lie to  vol to, on d’ io  mi  con for tai, $',\n",
       " '^  mi  mi se  den tro a  le  se gre te  co se. $',\n",
       " '^  Qui vi  so spi ri,  pian ti e  al ti  guai $',\n",
       " '^  ri so na van  per  l’ ae re  san za  stel le, $',\n",
       " '^  per  ch’ io  al  co min ciar  ne  la gri mai. $',\n",
       " '^  Di ver se  lin gue, or ri bi li  fa vel le, $',\n",
       " '^  pa ro le  di  do lo re, ac cen ti  d’ i ra, $',\n",
       " '^  vo ci al te e  fio che, e  suon  di  man  con  el le $',\n",
       " '^  fa ce va no un  tu mul to, il  qual  s’ ag gi ra $',\n",
       " '^  sem pre in  quel l’ au ra  san za  tem po  tin ta, $',\n",
       " '^  co me  la  re na  quan do  tur bo  spi ra. $',\n",
       " '^  E  io  ch’ a vea  d’ er ror  la  te sta  cin ta, $',\n",
       " '^  dis si:«  Ma e stro,  che  è  quel  ch’ i’  o do? $',\n",
       " '^  e  che  gen t’ è  che  par  nel  duol  sì  vin ta?». $',\n",
       " '^  Ed  el li a  me:«  Que sto  mi se ro  mo do $',\n",
       " '^  te gnon  l’ a ni me  tri ste  di  co lo ro $',\n",
       " '^  che  vis ser  san za ’n fa mia e  san za  lo do. $',\n",
       " '^  Mi schia te  so no a  quel  cat ti vo  co ro $',\n",
       " '^  de  li an ge li  che  non  fu ron  ri bel li $',\n",
       " '^  né  fur  fe de li a  Dio,  ma  per  sé  fuo ro. $',\n",
       " '^  Cac cian li i  ciel  per  non  es ser  men  bel li, $',\n",
       " '^  né  lo  pro fon do in fer no  li  ri ce ve, $',\n",
       " '^  ch’ al cu na  glo ria i  rei  av reb ber  d’ el li». $',\n",
       " '^  E  io:«  Ma e stro,  che  è  tan to  gre ve $',\n",
       " '^  a  lor  che  la men tar  li  fa  sì  for te?». $',\n",
       " '^  Ri spuo se:«  Di ce rol ti  mol to  bre ve. $',\n",
       " '^  Que sti  non  han no  spe ran za  di  mor te, $',\n",
       " '^  e  la  lor  cie ca  vi ta è  tan to  bas sa, $',\n",
       " '^  che ’n vi dï o si  son  d’ o gne al tra  sor te. $',\n",
       " '^  Fa ma  di  lo ro il  mon do es ser  non  las sa; $',\n",
       " '^  mi se ri cor dia e  giu sti zia  li  sde gna: $',\n",
       " '^  non  ra gio niam  di  lor,  ma  guar da e  pas sa». $',\n",
       " '^  E  io,  che  ri guar dai,  vi di u na ’n se gna $',\n",
       " '^  che  gi ran do  cor re va  tan to  rat ta, $',\n",
       " '^  che  d’ o gne  po sa  mi  pa rea  in de gna; $',\n",
       " '^  e  die tro  le  ve nìa  sì  lun ga  trat ta $',\n",
       " '^  di  gen te,  ch’ i’  non  a ve rei  cre du to $',\n",
       " '^  che  mor te  tan ta  n’ a ves se  di sfat ta. $',\n",
       " '^  Po scia  ch’ io  v’ eb bi al cun  ri co no sciu to, $',\n",
       " '^  vi di e  co nob bi  l’ om bra  di  co lui $',\n",
       " '^  che  fe ce  per  vil ta de il  gran  ri fiu to. $',\n",
       " '^  In con ta nen te in te si e  cer to  fui $',\n",
       " '^  che  que sta e ra  la  set ta  d’ i  cat ti vi, $',\n",
       " '^  a  Dio  spia cen ti e  a’  ne mi ci  sui. $',\n",
       " '^  Que sti  sciau ra ti,  che  mai  non  fur  vi vi, $',\n",
       " '^  e ra no i gnu di e  sti mo la ti  mol to $',\n",
       " '^  da  mo sco ni e  da  ve spe  ch’ e ran  i vi. $',\n",
       " '^  El le  ri ga van  lor  di  san gue il  vol to, $',\n",
       " '^  che,  mi schia to  di  la gri me, a’  lor  pie di $',\n",
       " '^  da  fa sti dio si  ver mi e ra  ri col to. $',\n",
       " '^  E  poi  ch’ a  ri guar dar  ol tre  mi  die di, $',\n",
       " '^  vi di  gen ti a  la  ri va  d’ un  gran  fiu me; $',\n",
       " '^  per  ch’ io  dis si:«  Ma e stro, or  mi  con ce di $',\n",
       " '^  ch’ i’  sap pia  qua li  so no, e  qual  co stu me $',\n",
       " '^  le  fa  di  tra pas sar  pa rer  sì  pron te, $',\n",
       " '^  com’  i’  di scer no  per  lo  fio co  lu me». $',\n",
       " '^  Ed  el li a  me:«  Le  co se  ti  fier  con te $',\n",
       " '^  quan do  noi  fer me rem  li  no stri  pas si $',\n",
       " '^  su  la  tri sta  ri vie ra  d’ A che ron te». $',\n",
       " '^  Al lor  con  li oc chi  ver go gno si e  bas si, $',\n",
       " '^  te men do  no ’l  mio  dir  li  fos se  gra ve, $',\n",
       " '^  in fi no al  fiu me  del  par lar  mi  tras si. $',\n",
       " '^  Ed  ec co  ver so  noi  ve nir  per  na ve $',\n",
       " '^  un  vec chio,  bian co  per  an ti co  pe lo, $',\n",
       " '^  gri dan do:«  Guai  a  voi,  a ni me  pra ve! $',\n",
       " '^  Non  i spe ra te  mai  ve der  lo  cie lo: $',\n",
       " '^  i’  ve gno  per  me nar vi a  l’ al tra  ri va $',\n",
       " '^  ne  le  te ne bre et ter ne, in  cal do e ’n  ge lo. $',\n",
       " '^  E  tu  che  se’  co stì,  a ni ma  vi va, $',\n",
       " '^  pàr ti ti  da  co te sti  che  son  mor ti». $',\n",
       " '^  Ma  poi  che  vi de  ch’ io  non  mi  par ti va, $',\n",
       " '^  dis se:«  Per  al tra  via,  per  al tri  por ti $',\n",
       " '^  ver rai  a  piag gia,  non  qui,  per  pas sa re: $',\n",
       " '^  più  lie ve  le gno  con vien  che  ti  por ti». $',\n",
       " '^  E ’l  du ca  lui:«  Ca ron,  non  ti  cruc cia re: $',\n",
       " '^  vuol si  co sì  co là  do ve  si  puo te $',\n",
       " '^  ciò  che  si  vuo le, e  più  non  di man da re». $',\n",
       " '^  Quin ci  fuor  que te  le  la no se  go te $',\n",
       " '^  al  noc chier  de  la  li vi da  pa lu de, $',\n",
       " '^  che ’n tor no a  li oc chi a vea  di  fiam me  ro te. $',\n",
       " '^  Ma  quel l’ a ni me,  ch’ e ran  las se e  nu de, $',\n",
       " '^  can giar  co lo re e  di bat te ro i  den ti, $',\n",
       " '^  rat to  che ’n te ser  le  pa ro le  cru de. $',\n",
       " '^  Be stem mia va no  Dio  e  lor  pa ren ti, $',\n",
       " '^  l’ u ma na  spe zie e ’l  lo co e ’l  tem po e ’l  se me $',\n",
       " '^  di  lor  se men za e  di  lor  na sci men ti. $',\n",
       " '^  Poi  si  ri tras ser  tut te  quan te in sie me, $',\n",
       " '^  for te  pian gen do, a  la  ri va  mal va gia $',\n",
       " '^  ch’ at ten de  cia scun  uom  che  Dio  non  te me. $',\n",
       " '^  Ca ron  di mo nio,  con  oc chi  di  bra gia $',\n",
       " '^  lo ro ac cen nan do,  tut te  le  rac co glie; $',\n",
       " '^  bat te  col  re mo  qua lun que  s’ a da gia. $',\n",
       " '^  Co me  d’ au tun no  si  le van  le  fo glie $',\n",
       " '^  l’ u na ap pres so  de  l’ al tra,  fin  che ’l  ra mo $',\n",
       " '^  ve de a  la  ter ra  tut te  le  sue  spo glie, $',\n",
       " '^  si mi le men te il  mal  se me  d’ A da mo $',\n",
       " '^  git tan si  di  quel  li to ad  u na ad  u na, $',\n",
       " '^  per  cen ni  co me au gel  per  suo  ri chia mo. $',\n",
       " '^  Co sì  sen  van no  su  per  l’ on da  bru na, $',\n",
       " '^  e  a van ti  che  sien  di  là  di sce se, $',\n",
       " '^  an che  di  qua  nuo va  schie ra  s’ a u na. $',\n",
       " '^ «  Fi gliuol  mio»,  dis se ’l  ma e stro  cor te se, $',\n",
       " '^ «  quel li  che  muo ion  ne  l’ i ra  di  Dio $',\n",
       " '^  tut ti  con ve gnon  qui  d’ o gne  pa e se; $',\n",
       " '^  e  pron ti  so no a  tra pas sar  lo  rio, $',\n",
       " '^  ché  la  di vi na  giu sti zia  li  spro na, $',\n",
       " '^  sì  che  la  te ma  si  vol ve in  di sio. $',\n",
       " '^  Quin ci  non  pas sa  mai  a ni ma  buo na; $',\n",
       " '^  e  pe rò,  se  Ca ron  di  te  si  la gna, $',\n",
       " '^  ben  puoi  sa pe re o mai  che ’l  suo  dir  suo na». $',\n",
       " '^  Fi ni to  que sto,  la  bu ia  cam pa gna $',\n",
       " '^  tre mò  sì  for te,  che  de  lo  spa ven to $',\n",
       " '^  la  men te  di  su do re an cor  mi  ba gna. $',\n",
       " '^  La  ter ra  la gri mo sa  die de  ven to, $',\n",
       " '^  che  ba le nò  u na  lu ce  ver mi glia $',\n",
       " '^  la  qual  mi  vin se  cia scun  sen ti men to; $',\n",
       " '^  e  cad di  co me  l’ uom  cui  son no  pi glia. $',\n",
       " '^  Rup pe mi  l’ al to  son no  ne  la  te sta $',\n",
       " '^  un  gre ve  truo no,  sì  ch’ io  mi  ri scos si $',\n",
       " '^  co me  per so na  ch’ è  per  for za  de sta; $',\n",
       " '^  e  l’ oc chio  ri po sa to in tor no  mos si, $',\n",
       " '^  drit to  le va to, e  fi so  ri guar dai $',\n",
       " '^  per  co no scer  lo  lo co  do v’ io  fos si. $',\n",
       " '^  Ve ro è  che ’n  su  la  pro da  mi  tro vai $',\n",
       " '^  de  la  val le  d’ a bis so  do lo ro sa $',\n",
       " '^  che ’n tro no ac co glie  d’ in fi ni ti  guai. $',\n",
       " '^  O scu ra e  pro fon da e ra e  ne bu lo sa $',\n",
       " '^  tan to  che,  per  fic car  lo  vi so a  fon do, $',\n",
       " '^  io  non  vi  di scer nea  al cu na  co sa. $',\n",
       " '^ «  Or  di scen diam  qua  giù  nel  cie co  mon do», $',\n",
       " '^  co min ciò  il  po e ta  tut to  smor to. $',\n",
       " '^ «  Io  sa rò  pri mo, e  tu  sa rai  se con do». $',\n",
       " '^  E  io,  che  del  co lor  mi  fui  ac cor to, $',\n",
       " '^  dis si:«  Co me  ver rò,  se  tu  pa ven ti $',\n",
       " '^  che  suo li al  mio  dub bia re es ser  con for to?». $',\n",
       " '^  Ed  el li a  me:«  L’ an go scia  de  le  gen ti $',\n",
       " '^  che  son  qua  giù,  nel  vi so  mi  di pi gne $',\n",
       " '^  quel la  pie tà  che  tu  per  te ma  sen ti. $',\n",
       " '^  An diam,  ché  la  via  lun ga  ne  so spi gne». $',\n",
       " '^  Co sì  si  mi se e  co sì  mi  fé in tra re $',\n",
       " '^  nel  pri mo  cer chio  che  l’ a bis so  ci gne. $',\n",
       " '^  Qui vi,  se con do  che  per  a scol ta re, $',\n",
       " '^  non  a vea  pian to  mai  che  di  so spi ri $',\n",
       " '^  che  l’ au ra et ter na  fa ce van  tre ma re; $',\n",
       " '^  ciò  av ve nia  di  duol  san za  mar tì ri, $',\n",
       " '^  ch’ a vean  le  tur be,  ch’ e ran  mol te e  gran di, $',\n",
       " '^  d’ in fan ti  e  di  fem mi ne e  di  vi ri. $',\n",
       " '^  Lo  buon  ma e stro a  me:«  Tu  non  di man di $',\n",
       " '^  che  spi ri ti  son  que sti  che  tu  ve di? $',\n",
       " '^  Or  vo’  che  sap pi, in nan zi  che  più  an di, $',\n",
       " '^  ch’ ei  non  pec ca ro; e  s’ el li han no  mer ce di, $',\n",
       " '^  non  ba sta,  per ché  non  eb ber  bat te smo, $',\n",
       " '^  ch’ è  por ta  de  la  fe de  che  tu  cre di; $',\n",
       " '^  e  s’ e’  fu ron  di nan zi al  cri stia ne smo, $',\n",
       " '^  non  a do rar  de bi ta men te a  Dio: $',\n",
       " '^  e  di  que sti  co tai  son  io  me de smo. $',\n",
       " '^  Per  tai  di fet ti,  non  per  al tro  rio, $',\n",
       " '^  se mo  per du ti, e  sol  di  tan to of fe si $',\n",
       " '^  che  san za  spe me  vi ve mo in  di sio». $',\n",
       " '^  Gran  duol  mi  pre se al  cor  quan do  lo ’n te si, $',\n",
       " '^  pe rò  che  gen te  di  mol to  va lo re $',\n",
       " '^  co nob bi  che ’n  quel  lim bo e ran  so spe si. $',\n",
       " '^ «  Dim mi,  ma e stro  mio,  dim mi,  se gno re», $',\n",
       " '^  co min cia’  io  per  vo ler  es ser  cer to $',\n",
       " '^  di  quel la  fe de  che  vin ce o gne er ro re: $',\n",
       " '^ «  u scic ci  mai  al cu no, o  per  suo  mer to $',\n",
       " '^  o  per  al trui,  che  poi  fos se  be a to?». $',\n",
       " '^  E  quei  che ’n te se il  mio  par lar  co ver to, $',\n",
       " '^  ri spuo se:« Io  e ra  nuo vo in  que sto  sta to, $',\n",
       " '^  quan do  ci  vi di  ve ni re un  pos sen te, $',\n",
       " '^  con  se gno  di  vit to ria  co ro na to. $',\n",
       " '^  Tras se ci  l’ om bra  del  pri mo  pa ren te, $',\n",
       " '^  d’ A bèl  suo  fi glio e  quel la  di  No è, $',\n",
       " '^  di  Mo ï sè  le gi sta e  u bi den te; $',\n",
       " '^  A bra àm  pa trï ar ca e  Da vìd  re, $',\n",
       " '^  I sra èl  con  lo  pa dre e  co’  suoi  na ti $',\n",
       " '^  e  con  Ra che le,  per  cui  tan to  fé, $',\n",
       " '^  e  al tri  mol ti, e  fe ce li  be a ti. $',\n",
       " '^  E  vo’  che  sap pi  che,  di nan zi ad  es si, $',\n",
       " '^  spi ri ti u ma ni  non  e ran  sal va ti». $',\n",
       " '^  Non  la scia vam  l’ an dar  per ch’ ei  di ces si, $',\n",
       " '^  ma  pas sa vam  la  sel va  tut ta via, $',\n",
       " '^  la  sel va,  di co,  di  spi ri ti  spes si. $',\n",
       " '^  Non  e ra  lun ga an cor  la  no stra  via $',\n",
       " '^  di  qua  dal  son no,  quan d’ io  vi di un  fo co $',\n",
       " '^  ch’ e mi spe rio  di  te ne bre  vin cia. $',\n",
       " '^  Di  lun gi  n’ e ra va mo an co ra un  po co, $',\n",
       " '^  ma  non  sì  ch’ io  non  di scer nes si in  par te $',\n",
       " '^  ch’ or re vol  gen te  pos se dea  quel  lo co. $',\n",
       " '^ «  O  tu  ch’ o no ri  scï en zï a e  ar te, $',\n",
       " '^  que sti  chi  son  c’ han no  co tan ta on ran za, $',\n",
       " '^  che  dal  mo do  de  li al tri  li  di par te?». $',\n",
       " '^  E  quel li a  me:«  L’ on ra ta  no mi nan za $',\n",
       " '^  che  di  lor  suo na  sù  ne  la  tua  vi ta, $',\n",
       " '^  gra zï a ac qui sta in  ciel  che  sì  li a van za». $',\n",
       " '^  In tan to  vo ce  fu  per  me  u di ta: $',\n",
       " '^ «  O no ra te  l’ al tis si mo  po e ta; $',\n",
       " '^  l’ om bra  sua  tor na,  ch’ e ra  di par ti ta». $',\n",
       " '^  Poi  che  la  vo ce  fu  re sta ta e  que ta, $',\n",
       " '^  vi di  quat tro  gran d’ om bre a  noi  ve ni re: $',\n",
       " '^  sem bian z’ a ve van  né  tri sta  né  lie ta. $',\n",
       " '^  Lo  buon  ma e stro  co min ciò  a  di re: $',\n",
       " '^ «  Mi ra  co lui  con  quel la  spa da in  ma no, $',\n",
       " '^  che  vien  di nan zi ai  tre  sì  co me  si re: $',\n",
       " '^  quel li è  O me ro  po e ta  sov ra no; $',\n",
       " '^  l’ al tro è  O ra zio  sa ti ro  che  ve ne; $',\n",
       " '^  O vi dio è ’l  ter zo, e  l’ ul ti mo  Lu ca no. $',\n",
       " '^  Pe rò  che  cia scun  me co  si  con ve ne $',\n",
       " '^  nel  no me  che  so nò  la  vo ce  so la, $',\n",
       " '^  fan no mi o no re, e  di  ciò  fan no  be ne». $',\n",
       " '^  Co sì  vi d’ i’ a du nar  la  bel la  sco la $',\n",
       " '^  di  quel  se gnor  de  l’ al tis si mo  can to $',\n",
       " '^  che  so vra  li al tri  com’  a qui la  vo la. $',\n",
       " '^  Da  ch’ eb ber  ra gio na to in sie me al quan to, $',\n",
       " '^  vol ser si a  me  con  sa lu te vol  cen no, $',\n",
       " '^  e ’l  mio  ma e stro  sor ri se  di  tan to; $',\n",
       " '^  e  più  d’ o no re an co ra as sai  mi  fen no, $',\n",
       " '^  ch’ e’  sì  mi  fe cer  de  la  lo ro  schie ra, $',\n",
       " '^  sì  ch’ io  fui  se sto  tra  co tan to  sen no. $',\n",
       " '^  Co sì  an dam mo in fi no a  la  lu me ra, $',\n",
       " '^  par lan do  co se  che ’l  ta ce re è  bel lo, $',\n",
       " '^  sì  com’  e ra ’l  par lar  co là  do v’ e ra. $',\n",
       " '^  Ve nim mo al  piè  d’ un  no bi le  ca stel lo, $',\n",
       " '^  set te  vol te  cer chia to  d’ al te  mu ra, $',\n",
       " '^  di fe so in tor no  d’ un  bel  fiu mi cel lo. $',\n",
       " '^  Que sto  pas sam mo  co me  ter ra  du ra; $',\n",
       " '^  per  set te  por te in trai  con  que sti  sa vi: $',\n",
       " '^  giu gnem mo in  pra to  di  fre sca  ver du ra. $',\n",
       " '^  Gen ti  v’ e ran  con  oc chi  tar di e  gra vi, $',\n",
       " '^  di  gran de au to ri tà  ne’  lor  sem bian ti: $',\n",
       " '^  par la van  ra do,  con  vo ci  so a vi. $',\n",
       " '^  Tra em mo ci  co sì  da  l’ un  de’  can ti, $',\n",
       " '^  in  lo co a per to,  lu mi no so e  al to, $',\n",
       " '^  sì  che  ve der  si  po tien  tut ti  quan ti. $',\n",
       " '^  Co là  di rit to,  so vra ’l  ver de  smal to, $',\n",
       " '^  mi  fuor  mo stra ti  li  spi ri ti  ma gni, $',\n",
       " '^  che  del  ve de re in  me  stes so  m’ es sal to. $',\n",
       " '^  I’  vi di E le tra  con  mol ti  com pa gni, $',\n",
       " '^  tra ’  quai  co nob bi  Et tòr  ed  E nea, $',\n",
       " '^  Ce sa re ar ma to  con  li oc chi  gri fa gni. $',\n",
       " '^  Vi di  Cam mil la e  la  Pan ta si lea; $',\n",
       " '^  da  l’ al tra  par te  vi di ’l  re  La ti no $',\n",
       " '^  che  con  La vi na  sua  fi glia  se dea. $',\n",
       " '^  Vi di  quel  Bru to  che  cac ciò  Tar qui no, $',\n",
       " '^  Lu cre zia,  Iu lia,  Mar zï a e  Cor ni glia; $',\n",
       " '^  e  so lo, in  par te,  vi di ’l  Sa la di no. $',\n",
       " '^  Poi  ch’ in nal zai  un  po co  più  le  ci glia, $',\n",
       " '^  vi di ’l  ma e stro  di  co lor  che  san no $',\n",
       " '^  se der  tra  fi lo so fi ca  fa mi glia. $',\n",
       " '^  Tut ti  lo  mi ran,  tut ti o nor  li  fan no: $',\n",
       " '^  qui vi  vi d’ ï o  So cra te e  Pla to ne, $',\n",
       " '^  che ’n nan zi a  li al tri  più  pres so  li  stan no; $',\n",
       " '^  De mo cri to  che ’l  mon do a  ca so  po ne, $',\n",
       " '^  Dï o ge nès,  A nas sa go ra e  Ta le, $',\n",
       " '^  Em pe do clès,  E ra cli to e  Ze no ne; $',\n",
       " '^  e  vi di il  buo no ac co gli tor  del  qua le, $',\n",
       " '^  Dï a sco ri de  di co; e  vi di Or feo, $',\n",
       " '^  Tu lï o e  Li no e  Se ne ca  mo ra le; $',\n",
       " '^  E u cli de  geo mè tra e  To lo meo, $',\n",
       " '^  I po crà te, A vi cen na e  Ga lï e no, $',\n",
       " '^  A ve ro ìs,  che ’l  gran  co men to  feo. $',\n",
       " '^  Io  non  pos so  ri trar  di  tut ti a  pie no, $',\n",
       " '^  pe rò  che  sì  mi  cac cia il  lun go  te ma, $',\n",
       " '^  che  mol te  vol te al  fat to il  dir  vien  me no. $',\n",
       " '^  La  se sta  com pa gnia  in  due  si  sce ma: $',\n",
       " '^  per  al tra  via  mi  me na il  sa vio  du ca, $',\n",
       " '^  fuor  de  la  que ta,  ne  l’ au ra  che  tre ma. $',\n",
       " '^  E  ve gno in  par te o ve  non  è  che  lu ca. $',\n",
       " '^  Co sì  di sce si  del  cer chio  pri ma io $',\n",
       " '^  giù  nel  se con do,  che  men  lo co  cin ghia $',\n",
       " '^  e  tan to  più  do lor,  che  pun ge a  gua io. $',\n",
       " '^  Stav vi  Mi nòs  or ri bil men te, e  rin ghia: $',\n",
       " '^  es sa mi na  le  col pe  ne  l’ in tra ta; $',\n",
       " '^  giu di ca e  man da  se con do  ch’ av vin ghia. $',\n",
       " '^  Di co  che  quan do  l’ a ni ma  mal  na ta $',\n",
       " '^  li  vien  di nan zi,  tut ta  si  con fes sa; $',\n",
       " '^  e  quel  co no sci tor  de  le  pec ca ta $',\n",
       " '^  ve de  qual  lo co  d’ in fer no è  da  es sa; $',\n",
       " '^  ci gne si  con  la  co da  tan te  vol te $',\n",
       " '^  quan tun que  gra di  vuol  che  giù  sia  mes sa. $',\n",
       " '^  Sem pre  di nan zi a  lui  ne  stan no  mol te: $',\n",
       " '^  van no a  vi cen da  cia scu na al  giu di zio, $',\n",
       " '^  di co no e  o do no e  poi  son  giù  vol te. $',\n",
       " '^ «  O  tu  che  vie ni al  do lo ro so o spi zio», $',\n",
       " '^  dis se  Mi nòs  a  me  quan do  mi  vi de, $',\n",
       " '^  la scian do  l’ at to  di  co tan to of fi zio, $',\n",
       " '^ «  guar da  com’  en tri e  di  cui  tu  ti  fi de; $',\n",
       " '^  non  t’ in gan ni  l’ am piez za  de  l’ in tra re!». $',\n",
       " '^  E ’l  du ca  mio  a  lui:«  Per ché  pur  gri de? $',\n",
       " '^  Non  im pe dir  lo  suo  fa ta le an da re: $',\n",
       " '^  vuol si  co sì  co là  do ve  si  puo te $',\n",
       " '^  ciò  che  si  vuo le, e  più  non  di man da re». $',\n",
       " '^  Or  in co min cian  le  do len ti  no te $',\n",
       " '^  a  far mi si  sen ti re; or  son  ve nu to $',\n",
       " '^  là  do ve  mol to  pian to  mi  per cuo te. $',\n",
       " '^  Io  ven ni in  lo co  d’ o gne  lu ce  mu to, $',\n",
       " '^  che  mug ghia  co me  fa  mar  per  tem pe sta, $',\n",
       " '^  se  da  con tra ri  ven ti è  com bat tu to. $',\n",
       " '^  La  bu fe ra in fer nal,  che  mai  non  re sta, $',\n",
       " '^  me na  li  spir ti  con  la  sua  ra pi na; $',\n",
       " '^  vol tan do e  per co ten do  li  mo le sta. $',\n",
       " '^  Quan do  giun gon  da van ti a  la  ru i na, $',\n",
       " '^  qui vi  le  stri da, il  com pian to, il  la men to; $',\n",
       " '^  be stem mian  qui vi  la  vir tù  di vi na. $',\n",
       " '^  In te si  ch’ a  co sì  fat to  tor men to $',\n",
       " '^  en no  dan na ti i  pec ca tor  car na li, $',\n",
       " '^  che  la  ra gion  som met to no al  ta len to. $',\n",
       " '^  E  co me  li  stor nei  ne  por tan  l’ a li $',\n",
       " '^  nel  fred do  tem po, a  schie ra  lar ga e  pie na, $',\n",
       " '^  co sì  quel  fia to  li  spi ri ti  ma li $',\n",
       " '^  di  qua,  di  là,  di  giù,  di  sù  li  me na; $',\n",
       " '^  nul la  spe ran za  li  con for ta  mai, $',\n",
       " '^  non  che  di  po sa,  ma  di  mi nor  pe na. $',\n",
       " '^  E  co me i  gru  van  can tan do  lor  lai, $',\n",
       " '^  fac cen do in  ae re  di  sé  lun ga  ri ga, $',\n",
       " '^  co sì  vi d’ io  ve nir,  tra en do  guai, $',\n",
       " '^  om bre  por ta te  da  la  det ta  bri ga; $',\n",
       " '^  per  ch’ i’  dis si:«  Ma e stro,  chi  son  quel le $',\n",
       " '^  gen ti  che  l’ au ra  ne ra  sì  ga sti ga?». $',\n",
       " '^ «  La  pri ma  di  co lor  di  cui  no vel le $',\n",
       " '^  tu  vuo’  sa per»,  mi  dis se  quel li al lot ta, $',\n",
       " '^ «  fu im pe ra dri ce  di  mol te  fa vel le. $',\n",
       " '^  A  vi zio  di  lus su ria  fu  sì  rot ta, $',\n",
       " '^  che  li bi to  fé  li ci to in  sua  leg ge, $',\n",
       " '^  per  tòr re il  bia smo in  che  e ra  con dot ta. $',\n",
       " '^  El l’ è  Se mi ra mìs,  di  cui  si  leg ge $',\n",
       " '^  che  suc ce det te a  Ni no e  fu  sua  spo sa: $',\n",
       " '^  ten ne  la  ter ra  che ’l  Sol dan  cor reg ge. $',\n",
       " '^  L’ al tra è  co lei  che  s’ an ci se a mo ro sa, $',\n",
       " '^  e  rup pe  fe de al  ce ner  di  Si cheo; $',\n",
       " '^  poi  è  Cle o pa tràs  lus su rï o sa. $',\n",
       " '^  E le na  ve di,  per  cui  tan to  reo $',\n",
       " '^  tem po  si  vol se, e  ve di ’l  gran de A chil le, $',\n",
       " '^  che  con  a mo re al  fi ne  com bat teo. $',\n",
       " '^  Ve di  Pa rìs,  Tri sta no»; e  più  di  mil le $',\n",
       " '^  om bre  mo strom mi e  no mi nom mi a  di to, $',\n",
       " '^  ch’ a mor  di  no stra  vi ta  di par til le. $',\n",
       " '^  Po scia  ch’ io  eb bi ’l  mio  dot to re u di to $',\n",
       " '^  no mar  le  don ne an ti che e ’  ca va lie ri, $',\n",
       " '^  pie tà  mi  giun se, e  fui  qua si  smar ri to. $',\n",
       " '^  I’  co min ciai:«  Po e ta,  vo lon tie ri $',\n",
       " '^  par le rei  a  quei  due  che ’n sie me  van no, $',\n",
       " '^  e  pai on  sì  al  ven to es ser  leg ge ri». $',\n",
       " '^  Ed  el li a  me:«  Ve drai  quan do  sa ran no $',\n",
       " '^  più  pres so a  noi;  e  tu  al lor  li  prie ga $',\n",
       " '^  per  quel lo a mor  che i  me na, ed  ei  ver ran no». $',\n",
       " '^  Sì  to sto  co me il  ven to a  noi  li  pie ga, $',\n",
       " '^  mos si  la  vo ce:« O  a ni me af fan na te, $',\n",
       " '^  ve ni te a  noi  par lar,  s’ al tri  nol  nie ga!». $',\n",
       " '^  Qua li  co lom be  dal  di sio  chia ma te $',\n",
       " '^  con  l’ a li al za te e  fer me al  dol ce  ni do $',\n",
       " '^  ve gnon  per  l’ ae re,  dal  vo ler  por ta te; $',\n",
       " '^  co ta li u scir  de  la  schie ra o v’ è  Di do, $',\n",
       " '^  a  noi  ve nen do  per  l’ ae re  ma li gno, $',\n",
       " '^  sì  for te  fu  l’ af fet tü o so  gri do. $',\n",
       " '^ «  O  a ni mal  gra zï o so e  be ni gno $',\n",
       " '^  che  vi si tan do  vai  per  l’ ae re  per so $',\n",
       " '^  noi  che  ti gnem mo il  mon do  di  san gui gno, $',\n",
       " '^  se  fos se a mi co il  re  de  l’ u ni ver so, $',\n",
       " '^  noi  pre ghe rem mo  lui  de  la  tua  pa ce, $',\n",
       " '^  poi  c’ hai  pie tà  del  no stro  mal  per ver so. $',\n",
       " '^  Di  quel  che u di re e  che  par lar  vi  pia ce, $',\n",
       " '^  noi  u di re mo e  par le re mo a  voi, $',\n",
       " '^  men tre  che ’l  ven to,  co me  fa,  ci  ta ce. $',\n",
       " '^  Sie de  la  ter ra  do ve  na ta  fui $',\n",
       " '^  su  la  ma ri na  do ve ’l  Po  di scen de $',\n",
       " '^  per  a ver  pa ce  co’  se gua ci  sui. $',\n",
       " '^  A mor,  ch’ al  cor  gen til  rat to  s’ ap pren de, $',\n",
       " '^  pre se  co stui  de  la  bel la  per so na $',\n",
       " '^  che  mi  fu  tol ta; e ’l  mo do an cor  m’ of fen de. $',\n",
       " '^  A mor,  ch’ a  nul lo a ma to a mar  per do na, $',\n",
       " '^  mi  pre se  del  co stui  pia cer  sì  for te, $',\n",
       " '^  che,  co me  ve di, an cor  non  m’ ab ban do na. $',\n",
       " '^  A mor  con dus se  noi  ad  u na  mor te. $',\n",
       " '^  Ca i na at ten de  chi a  vi ta  ci  spen se». $',\n",
       " '^  Que ste  pa ro le  da  lor  ci  fuor  por te. $',\n",
       " '^  Quan d’ io  in te si  quel l’ a ni me of fen se, $',\n",
       " '^  chi na’  il  vi so, e  tan to il  ten ni  bas so, $',\n",
       " '^  fin  che ’l  po e ta  mi  dis se:«  Che  pen se?». $',\n",
       " '^  Quan do  ri spuo si,  co min ciai:«  Oh  las so, $',\n",
       " '^  quan ti  dol ci  pen sier,  quan to  di sio $',\n",
       " '^  me nò  co sto ro al  do lo ro so  pas so!». $',\n",
       " '^  Poi  mi  ri vol si a  lo ro e  par la’  io, $',\n",
       " '^  e  co min ciai:«  Fran ce sca, i  tuoi  mar tì ri $',\n",
       " '^  a  la gri mar  mi  fan no  tri sto e  pio. $',\n",
       " '^  Ma  dim mi: al  tem po  d’ i  dol ci  so spi ri, $',\n",
       " '^  a  che  e  co me  con ce det te a mo re $',\n",
       " '^  che  co no sce ste i  dub bio si  di si ri?». $',\n",
       " '^  E  quel la a  me:«  Nes sun  mag gior  do lo re $',\n",
       " '^  che  ri cor dar si  del  tem po  fe li ce $',\n",
       " '^  ne  la  mi se ria; e  ciò  sa ’l  tuo  dot to re. $',\n",
       " '^  Ma  s’ a  co no scer  la  pri ma  ra di ce $',\n",
       " '^  del  no stro a mor  tu  hai  co tan to af fet to, $',\n",
       " '^  di rò  co me  co lui  che  pian ge e  di ce. $',\n",
       " '^  Noi  leg gia va mo un  gior no  per  di let to $',\n",
       " '^  di  Lan cia lot to  co me a mor  lo  strin se; $',\n",
       " '^  so li e ra va mo e  san za al cun  so spet to. $',\n",
       " '^  Per  più  fï a te  li oc chi  ci  so spin se $',\n",
       " '^  quel la  let tu ra, e  sco lo roc ci il  vi so; $',\n",
       " '^  ma  so lo un  pun to  fu  quel  che  ci  vin se. $',\n",
       " '^  Quan do  leg gem mo il  di sï a to  ri so $',\n",
       " '^  es ser  ba scia to  da  co tan to a man te, $',\n",
       " '^  que sti,  che  mai  da  me  non  fia  di vi so, $',\n",
       " '^  la  boc ca  mi  ba sciò  tut to  tre man te. $',\n",
       " '^  Ga le ot to  fu ’l  li bro e  chi  lo  scris se: $',\n",
       " '^  quel  gior no  più  non  vi  leg gem mo a van te». $',\n",
       " '^  Men tre  che  l’ u no  spir to  que sto  dis se, $',\n",
       " '^  l’ al tro  pian gë a;  sì  che  di  pie ta de $',\n",
       " '^  io  ven ni  men  co sì  com’  io  mo ris se. $',\n",
       " '^  E  cad di  co me  cor po  mor to  ca de. $',\n",
       " '^  Al  tor nar  de  la  men te,  che  si  chiu se $',\n",
       " '^  di nan zi a  la  pie tà  d’ i  due  co gna ti, $',\n",
       " '^  che  di  tre sti zia  tut to  mi  con fu se, $',\n",
       " '^  no vi  tor men ti e  no vi  tor men ta ti $',\n",
       " '^  mi  veg gio in tor no,  co me  ch’ io  mi  mo va $',\n",
       " '^  e  ch’ io  mi  vol ga, e  co me  che  io  gua ti. $',\n",
       " '^  Io  so no al  ter zo  cer chio,  de  la  pio va $',\n",
       " '^  et ter na,  ma la det ta,  fred da e  gre ve; $',\n",
       " '^  re go la e  qua li tà  mai  non  l’ è  no va. $',\n",
       " '^  Gran di ne  gros sa,  ac qua  tin ta e  ne ve $',\n",
       " '^  per  l’ ae re  te ne bro so  si  ri ver sa; $',\n",
       " '^  pu te  la  ter ra  che  que sto  ri ce ve. $',\n",
       " '^  Cer be ro,  fie ra  cru de le e  di ver sa, $',\n",
       " '^  con  tre  go le  ca ni na men te  la tra $',\n",
       " '^  so vra  la  gen te  che  qui vi è  som mer sa. $',\n",
       " '^  Li oc chi ha  ver mi gli,  la  bar ba un ta e  a tra, $',\n",
       " '^  e ’l  ven tre  lar go, e  un ghia te  le  ma ni; $',\n",
       " '^  graf fia  li  spir ti ed  i sco ia ed  i squa tra. $',\n",
       " '^  Ur lar  li  fa  la  piog gia  co me  ca ni; $',\n",
       " '^  de  l’ un  de’  la ti  fan no a  l’ al tro  scher mo; $',\n",
       " '^  vol gon si  spes so i  mi se ri  pro fa ni. $',\n",
       " '^  Quan do  ci  scor se  Cer be ro, il  gran  ver mo, $',\n",
       " '^  le  boc che a per se e  mo stroc ci  le  san ne; $',\n",
       " '^  non  a vea  mem bro  che  te nes se  fer mo. $',\n",
       " '^  E ’l  du ca  mio  di ste se  le  sue  span ne, $',\n",
       " '^  pre se  la  ter ra, e  con  pie ne  le  pu gna $',\n",
       " '^  la  git tò  den tro a  le  bra mo se  can ne. $',\n",
       " '^  Qual  è  quel  ca ne  ch’ ab ba ian do a go gna, $',\n",
       " '^  e  si  rac que ta  poi  che ’l  pa sto  mor de, $',\n",
       " '^  ché  so lo a  di vo rar lo in ten de e  pu gna, $',\n",
       " '^  co tai  si  fe cer  quel le  fac ce  lor de $',\n",
       " '^  de  lo  de mo nio  Cer be ro,  che ’n tro na $',\n",
       " '^  l’ a ni me  sì,  ch’ es ser  vor reb ber  sor de. $',\n",
       " '^  Noi  pas sa vam  su  per  l’ om bre  che a do na $',\n",
       " '^  la  gre ve  piog gia, e  po na vam  le  pian te $',\n",
       " '^  so vra  lor  va ni tà  che  par  per so na. $',\n",
       " '^  El le  gia cean  per  ter ra  tut te  quan te, $',\n",
       " '^  fuor  d’ u na  ch’ a  se der  si  le vò,  rat to $',\n",
       " '^  ch’ el la  ci  vi de  pas sar si  da van te. $',\n",
       " '^ «  O  tu  che  se’  per  que sto ’n fer no  trat to», $',\n",
       " '^  mi  dis se,«  ri co no sci mi,  se  sai: $',\n",
       " '^  tu  fo sti,  pri ma  ch’ io  di sfat to,  fat to». $',\n",
       " '^  E  io  a  lui:«  L’ an go scia  che  tu  hai $',\n",
       " '^  for se  ti  ti ra  fuor  de  la  mia  men te, $',\n",
       " '^  sì  che  non  par  ch’ i’  ti  ve des si  mai. $',\n",
       " '^  Ma  dim mi  chi  tu  se’  che ’n  sì  do len te $',\n",
       " '^  lo co  se’  mes so, e  hai  sì  fat ta  pe na, $',\n",
       " '^  che,  s’ al tra è  mag gio,  nul la è  sì  spia cen te». $',\n",
       " '^  Ed  el li a  me:«  La  tua  cit tà,  ch’ è  pie na $',\n",
       " '^  d’ in vi dia  sì  che  già  tra boc ca il  sac co, $',\n",
       " '^  se co  mi  ten ne in  la  vi ta  se re na. $',\n",
       " '^  Voi  cit ta di ni  mi  chia ma ste  Ciac co: $',\n",
       " '^  per  la  dan no sa  col pa  de  la  go la, $',\n",
       " '^  co me  tu  ve di, a  la  piog gia  mi  fiac co. $',\n",
       " '^  E  io  a ni ma  tri sta  non  son  so la, $',\n",
       " '^  ché  tut te  que ste a  si mil  pe na  stan no $',\n",
       " '^  per  si mil  col pa». E  più  non  fé  pa ro la. $',\n",
       " '^  Io  li  ri spuo si:«  Ciac co, il  tuo  af fan no $',\n",
       " '^  mi  pe sa  sì,  ch’ a  la gri mar  mi ’n vi ta; $',\n",
       " '^  ma  dim mi,  se  tu  sai,  a  che  ver ran no $',\n",
       " '^  li  cit ta din  de  la  cit tà  par ti ta; $',\n",
       " '^  s’ al cun  v’ è  giu sto; e  dim mi  la  ca gio ne $',\n",
       " '^  per  che  l’ ha  tan ta  di scor dia as sa li ta». $',\n",
       " '^  E  quel li a  me:«  Do po  lun ga  ten cio ne $',\n",
       " '^  ver ran no al  san gue, e  la  par te  sel vag gia $',\n",
       " '^  cac ce rà  l’ al tra  con  mol ta of fen sio ne. $',\n",
       " '^  Poi  ap pres so  con vien  che  que sta  cag gia $',\n",
       " '^  in fra  tre  so li, e  che  l’ al tra  sor mon ti $',\n",
       " '^  con  la  for za  di  tal  che  te sté  piag gia. $',\n",
       " '^  Al te  ter rà  lun go  tem po  le  fron ti, $',\n",
       " '^  te nen do  l’ al tra  sot to  gra vi  pe si, $',\n",
       " '^  co me  che  di  ciò  pian ga o  che  n’ a on ti. $',\n",
       " '^  Giu sti  son  due,  e  non  vi  so no in te si; $',\n",
       " '^  su per bia, in vi dia e  a va ri zia  so no $',\n",
       " '^  le  tre  fa vil le  c’ han no i  cuo ri ac ce si». $',\n",
       " '^  Qui  puo se  fi ne al  la gri ma bil  suo no. $',\n",
       " '^  E  io  a  lui:«  An cor  vo’  che  mi ’n se gni $',\n",
       " '^  e  che  di  più  par lar  mi  fac ci  do no. $',\n",
       " '^  Fa ri na ta e ’l  Teg ghiaio,  che  fuor  sì  de gni, $',\n",
       " '^  Ia co po  Ru sti cuc ci, Ar ri go e ’l  Mo sca $',\n",
       " '^  e  li al tri  ch’ a  ben  far  puo ser  li ’n ge gni, $',\n",
       " '^  dim mi o ve  so no e  fa  ch’ io  li  co no sca; $',\n",
       " '^  ché  gran  di sio  mi  strin ge  di  sa ve re $',\n",
       " '^  se ’l  ciel  li ad dol cia o  lo ’n fer no  li at to sca». $',\n",
       " '^  E  quel li:« Ei  son  tra  l’ a ni me  più  ne re; $',\n",
       " '^  di ver se  col pe  giù  li  gra va al  fon do: $',\n",
       " '^  se  tan to  scen di,  là i  po trai  ve de re. $',\n",
       " '^  Ma  quan do  tu  sa rai  nel  dol ce  mon do, $',\n",
       " '^  prie go ti  ch’ a  la  men te al trui  mi  re chi: $',\n",
       " '^  più  non  ti  di co e  più  non  ti  ri spon do». $',\n",
       " '^  Li  di rit ti oc chi  tor se al lo ra in  bie chi; $',\n",
       " '^  guar dom mi un  po co e  poi  chi nò  la  te sta: $',\n",
       " '^  cad de  con  es sa a  par  de  li al tri  cie chi. $',\n",
       " '^  E ’l  du ca  dis se a  me:«  Più  non  si  de sta $',\n",
       " '^  di  qua  dal  suon  de  l’ an ge li ca  trom ba, $',\n",
       " '^  quan do  ver rà  la  ni mi ca  po de sta: $',\n",
       " '^  cia scun  ri ve de rà  la  tri sta  tom ba, $',\n",
       " '^  ri pi glie rà  sua  car ne e  sua  fi gu ra, $',\n",
       " '^  u di rà  quel  ch’ in  et ter no  rim bom ba». $',\n",
       " '^  Sì  tra pas sam mo  per  soz za  mi stu ra $',\n",
       " '^  de  l’ om bre e  de  la  piog gia, a  pas si  len ti, $',\n",
       " '^  toc can do un  po co  la  vi ta  fu tu ra; $',\n",
       " '^  per  ch’ io  dis si:«  Ma e stro, e sti  tor men ti $',\n",
       " '^  cre sce ran n’ ei  do po  la  gran  sen ten za, $',\n",
       " '^  o  fier  mi no ri, o  sa ran  sì  co cen ti?». $',\n",
       " '^  Ed  el li a  me:«  Ri tor na a  tua  scï en za, $',\n",
       " '^  che  vuol,  quan to  la  co sa è  più  per fet ta, $',\n",
       " '^  più  sen ta il  be ne, e  co sì  la  do glien za. $',\n",
       " '^  Tut to  che  que sta  gen te  ma la det ta $',\n",
       " '^  in  ve ra  per fe zion  già  mai  non  va da, $',\n",
       " '^  di  là  più  che  di  qua  es se re a spet ta». $',\n",
       " '^  Noi  ag gi ram mo a  ton do  quel la  stra da, $',\n",
       " '^  par lan do  più  as sai  ch’ i’  non  ri di co; $',\n",
       " '^  ve nim mo al  pun to  do ve  si  di gra da: $',\n",
       " '^  qui vi  tro vam mo  Plu to, il  gran  ne mi co. $',\n",
       " '^ «  Pa pe  Sa tàn,  pa pe  Sa tàn  a lep pe!», $',\n",
       " '^  co min ciò  Plu to  con  la  vo ce  chioc cia; $',\n",
       " '^  e  quel  sa vio  gen til,  che  tut to  sep pe, $',\n",
       " '^  dis se  per  con for tar mi:«  Non  ti  noc cia $',\n",
       " '^  la  tua  pa u ra;  ché,  po der  ch’ el li ab bia, $',\n",
       " '^  non  ci  tor rà  lo  scen der  que sta  roc cia». $',\n",
       " '^  Poi  si  ri vol se a  quel la ’n fia ta  lab bia, $',\n",
       " '^  e  dis se:«  Ta ci,  ma la det to  lu po! $',\n",
       " '^  con su ma  den tro  te  con  la  tua  rab bia. $',\n",
       " '^  Non  è  san za  ca gion  l’ an da re al  cu po: $',\n",
       " '^  vuol si  ne  l’ al to,  là  do ve  Mi che le $',\n",
       " '^  fé  la  ven det ta  del  su per bo  stru po». $',\n",
       " '^  Qua li  dal  ven to  le  gon fia te  ve le $',\n",
       " '^  cag gio no av vol te,  poi  che  l’ al ber  fiac ca, $',\n",
       " '^  tal  cad de a  ter ra  la  fie ra  cru de le. $',\n",
       " '^  Co sì  scen dem mo  ne  la  quar ta  lac ca, $',\n",
       " '^  pi glian do  più  de  la  do len te  ri pa $',\n",
       " '^  che ’l  mal  de  l’ u ni ver so  tut to in sac ca. $',\n",
       " '^  Ahi  giu sti zia  di  Dio!  tan te  chi  sti pa $',\n",
       " '^  no ve  tra va glie e  pe ne  quan t’ io  vid di? $',\n",
       " '^  e  per ché  no stra  col pa  sì  ne  sci pa? $',\n",
       " '^  Co me  fa  l’ on da  là  so vra  Ca rid di, $',\n",
       " '^  che  si  fran ge  con  quel la in  cui  s’ in top pa, $',\n",
       " '^  co sì  con vien  che  qui  la  gen te  rid di. $',\n",
       " '^  Qui  vi d’ i’  gen te  più  ch’ al tro ve  trop pa, $',\n",
       " '^  e  d’ u na  par te e  d’ al tra,  con  gran d’ ur li, $',\n",
       " '^  vol tan do  pe si  per  for za  di  pop pa. $',\n",
       " '^  Per co të an si ’n con tro; e  po scia  pur  lì $',\n",
       " '^  si  ri vol gea  cia scun,  vol tan do a  re tro, $',\n",
       " '^  gri dan do:«  Per ché  tie ni?» e«  Per ché  bur li?». $',\n",
       " '^  Co sì  tor na van  per  lo  cer chio  te tro $',\n",
       " '^  da  o gne  ma no a  l’ op po si to  pun to, $',\n",
       " '^  gri dan do si an che  lo ro on to so  me tro; $',\n",
       " '^  poi  si  vol gea  cia scun,  quan d’ e ra  giun to, $',\n",
       " '^  per  lo  suo  mez zo  cer chio a  l’ al tra  gio stra. $',\n",
       " '^  E  io,  ch’ a vea  lo  cor  qua si  com pun to, $',\n",
       " '^  dis si:«  Ma e stro  mio,  or  mi  di mo stra $',\n",
       " '^  che  gen te è  que sta, e  se  tut ti  fuor  cher ci $',\n",
       " '^  que sti  cher cu ti a  la  si ni stra  no stra». $',\n",
       " '^  Ed  el li a  me:«  Tut ti  quan ti  fuor  guer ci $',\n",
       " '^  sì  de  la  men te in  la  vi ta  pri ma ia, $',\n",
       " '^  che  con  mi su ra  nul lo  spen dio  fer ci. $',\n",
       " '^  As sai  la  vo ce  lor  chia ro  l’ ab ba ia, $',\n",
       " '^  quan do  ve gno no a’  due  pun ti  del  cer chio $',\n",
       " '^  do ve  col pa  con tra ria  li  di spa ia. $',\n",
       " '^  Que sti  fuor  cher ci,  che  non  han  co per chio $',\n",
       " '^  pi lo so al  ca po, e  pa pi e  car di na li, $',\n",
       " '^  in  cui  u sa a va ri zia il  suo  so per chio». $',\n",
       " '^  E  io:«  Ma e stro,  tra  que sti  co ta li $',\n",
       " '^  dov re’  io  ben  ri co no sce re al cu ni $',\n",
       " '^  che  fu ro im mon di  di  co te sti  ma li». $',\n",
       " '^  Ed  el li a  me:«  Va no  pen sie ro a du ni: $',\n",
       " '^  la  sco no scen te  vi ta  che i  fé  soz zi, $',\n",
       " '^  ad  o gne  co no scen za or  li  fa  bru ni. $',\n",
       " '^  In  et ter no  ver ran no a  li  due  coz zi: $',\n",
       " '^  que sti  re sur ge ran no  del  se pul cro $',\n",
       " '^  col  pu gno  chiu so, e  que sti  coi  crin  moz zi. $',\n",
       " '^  Mal  da re e  mal  te ner  lo  mon do  pul cro $',\n",
       " '^  ha  tol to  lo ro, e  po sti a  que sta  zuf fa: $',\n",
       " '^  qual  el la  sia,  pa ro le  non  ci ap pul cro. $',\n",
       " '^  Or  puoi,  fi gliuol,  ve der  la  cor ta  buf fa $',\n",
       " '^  d’ i  ben  che  son  com mes si a  la  for tu na, $',\n",
       " '^  per  che  l’ u ma na  gen te  si  rab buf fa; $',\n",
       " '^  ché  tut to  l’ o ro  ch’ è  sot to  la  lu na $',\n",
       " '^  e  che  già  fu,  di  que st’ a ni me  stan che $',\n",
       " '^  non  po te reb be  far ne  po sa re u na». $',\n",
       " '^ «  Ma e stro  mio»,  dis s’ io,«  or  mi  dì  an che: $',\n",
       " '^  que sta  for tu na  di  che  tu  mi  toc che, $',\n",
       " '^  che  è,  che i  ben  del  mon do ha  sì  tra  bran che?». $',\n",
       " '^  E  quel li a  me:«  Oh  cre a tu re  scioc che, $',\n",
       " '^  quan ta i gno ran za è  quel la  che  v’ of fen de! $',\n",
       " '^  Or  vo’  che  tu  mia  sen ten za  ne ’m boc che. $',\n",
       " '^  Co lui  lo  cui  sa ver  tut to  tra scen de, $',\n",
       " '^  fe ce  li  cie li e  diè  lor  chi  con du ce $',\n",
       " '^  sì,  ch’ o gne  par te ad  o gne  par te  splen de, $',\n",
       " '^  di stri bu en do i gual men te  la  lu ce. $',\n",
       " '^  Si mi le men te a  li  splen dor  mon da ni $',\n",
       " '^  or di nò  ge ne ral  mi ni stra e  du ce $',\n",
       " '^  che  per mu tas se a  tem po  li  ben  va ni $',\n",
       " '^  di  gen te in  gen te e  d’ u no in  al tro  san gue, $',\n",
       " '^  ol tre  la  di fen sion  d’ i  sen ni u ma ni; $',\n",
       " '^  per  ch’ u na  gen te im pe ra e  l’ al tra  lan gue, $',\n",
       " '^  se guen do  lo  giu di cio  di  co stei, $',\n",
       " '^  che  è  oc cul to  co me in  er ba  l’ an gue. $',\n",
       " '^  Vo stro  sa ver  non  ha  con ta sto a  lei: $',\n",
       " '^  que sta  pro ve de,  giu di ca, e  per se gue $',\n",
       " '^  suo  re gno  co me il  lo ro  li al tri  dèi. $',\n",
       " '^  Le  sue  per mu ta zion  non  han no  trie gue: $',\n",
       " '^  ne ces si tà  la  fa  es ser  ve lo ce; $',\n",
       " '^  sì  spes so  vien  chi  vi cen da  con se gue. $',\n",
       " '^  Que st’ è  co lei  ch’ è  tan to  po sta in  cro ce $',\n",
       " '^  pur  da  co lor  che  le  do vrien  dar  lo de, $',\n",
       " '^  dan do le  bia smo a  tor to e  ma la  vo ce; $',\n",
       " '^  ma  el la  s’ è  be a ta e  ciò  non  o de: $',\n",
       " '^  con  l’ al tre  pri me  cre a tu re  lie ta $',\n",
       " '^  vol ve  sua  spe ra e  be a ta  si  go de. $',\n",
       " '^  Or  di scen dia mo o mai  a  mag gior  pie ta; $',\n",
       " '^  già  o gne  stel la  ca de  che  sa li va $',\n",
       " '^  quan d’ io  mi  mos si, e ’l  trop po  star  si  vie ta». $',\n",
       " '^  Noi  ri ci dem mo il  cer chio a  l’ al tra  ri va $',\n",
       " '^  sov r’ u na  fon te  che  bol le e  ri ver sa $',\n",
       " '^  per  un  fos sa to  che  da  lei  de ri va. $',\n",
       " '^  L’ ac qua e ra  bu ia  as sai  più  che  per sa; $',\n",
       " '^  e  noi,  in  com pa gnia  de  l’ on de  bi ge, $',\n",
       " '^  in tram mo  giù  per  u na  via  di ver sa. $',\n",
       " '^  In  la  pa lu de  va  c’ ha  no me  Sti ge $',\n",
       " '^  que sto  tri sto  ru scel,  quan d’ è  di sce so $',\n",
       " '^  al  piè  de  le  ma li gne  piag ge  gri ge. $',\n",
       " '^  E  io,  che  di  mi ra re  sta va in te so, $',\n",
       " '^  vi di  gen ti  fan go se in  quel  pan ta no, $',\n",
       " '^  i gnu de  tut te,  con  sem bian te of fe so. $',\n",
       " '^  Que ste  si  per co tean  non  pur  con  ma no, $',\n",
       " '^  ma  con  la  te sta e  col  pet to e  coi  pie di, $',\n",
       " '^  tron can do si  co’  den ti a  bra no a  bra no. $',\n",
       " '^  Lo  buon  ma e stro  dis se:«  Fi glio, or  ve di $',\n",
       " '^  l’ a ni me  di  co lor  cui  vin se  l’ i ra; $',\n",
       " '^  e  an che  vo’  che  tu  per  cer to  cre di $',\n",
       " '^  che  sot to  l’ ac qua è  gen te  che  so spi ra, $',\n",
       " '^  e  fan no  pul lu lar  que st’ ac qua al  sum mo, $',\n",
       " '^  co me  l’ oc chio  ti  di ce, u’  che  s’ ag gi ra. $',\n",
       " '^  Fit ti  nel  li mo  di con:“  Tri sti  fum mo $',\n",
       " '^  ne  l’ ae re  dol ce  che  dal  sol  s’ al le gra, $',\n",
       " '^  por tan do  den tro ac ci dï o so  fum mo: $',\n",
       " '^  or  ci at tri stiam  ne  la  bel let ta  ne gra”. $',\n",
       " '^  Que st’ in no  si  gor go glian  ne  la  stroz za, $',\n",
       " '^  ché  dir  nol  pos son  con  pa ro la in te gra». $',\n",
       " '^  Co sì  gi ram mo  de  la  lor da  poz za $',\n",
       " '^  gran d’ ar co  tra  la  ri pa  sec ca e ’l  méz zo, $',\n",
       " '^  con  li oc chi  vòl ti a  chi  del  fan go in goz za. $',\n",
       " '^  Ve nim mo al  piè  d’ u na  tor re al  da  sez zo. $',\n",
       " '^  Io  di co,  se gui tan do,  ch’ as sai  pri ma $',\n",
       " '^  che  noi  fos si mo al  piè  de  l’ al ta  tor re, $',\n",
       " '^  li oc chi  no stri  n’ an dar  su so a  la  ci ma $',\n",
       " '^  per  due  fiam met te  che i  ve dem mo  por re, $',\n",
       " '^  e  u n’ al tra  da  lun gi  ren der  cen no, $',\n",
       " '^  tan to  ch’ a  pe na il  po tea  l’ oc chio  tòr re. $',\n",
       " '^  E  io  mi  vol si al  mar  di  tut to ’l  sen no; $',\n",
       " '^  dis si:«  Que sto  che  di ce? e  che  ri spon de $',\n",
       " '^  quel l’ al tro  fo co? e  chi  son  quei  che ’l  fen no?». $',\n",
       " '^  Ed  el li a  me:«  Su  per  le  su ci de on de $',\n",
       " '^  già  scor ge re  puoi  quel lo  che  s’ a spet ta, $',\n",
       " '^  se ’l  fum mo  del  pan tan  nol  ti  na scon de». $',\n",
       " '^  Cor da  non  pin se  mai  da  sé  sa et ta $',\n",
       " '^  che  sì  cor res se  via  per  l’ ae re  snel la, $',\n",
       " '^  com’  io  vi di u na  na ve  pic cio let ta $',\n",
       " '^  ve nir  per  l’ ac qua  ver so  noi  in  quel la, $',\n",
       " '^  sot to ’l  go ver no  d’ un  sol  ga le o to, $',\n",
       " '^  che  gri da va:« Or  se’  giun ta, a ni ma  fel la!». $',\n",
       " '^ «  Fle gï às,  Fle gï às,  tu  gri di a  vò to», $',\n",
       " '^  dis se  lo  mio  se gno re,« a  que sta  vol ta: $',\n",
       " '^  più  non  ci av rai  che  sol  pas san do il  lo to». $',\n",
       " '^  Qual  è  co lui  che  gran de in gan no a scol ta $',\n",
       " '^  che  li  sia  fat to, e  poi  se  ne  ram mar ca, $',\n",
       " '^  fe ce si  Fle gï às  ne  l’ i ra ac col ta. $',\n",
       " '^  Lo  du ca  mio  di sce se  ne  la  bar ca, $',\n",
       " '^  e  poi  mi  fe ce in tra re ap pres so  lui; $',\n",
       " '^  e  sol  quan d’ io  fui  den tro  par ve  car ca. $',\n",
       " '^  To sto  che ’l  du ca e  io  nel  le gno  fui, $',\n",
       " '^  se gan do  se  ne  va  l’ an ti ca  pro ra $',\n",
       " '^  de  l’ ac qua  più  che  non  suol  con  al trui. $',\n",
       " '^  Men tre  noi  cor ra vam  la  mor ta  go ra, $',\n",
       " '^  di nan zi  mi  si  fe ce un  pien  di  fan go, $',\n",
       " '^  e  dis se:«  Chi  se’  tu  che  vie ni an zi o ra?». $',\n",
       " '^  E  io  a  lui:«  S’ i’  ve gno,  non  ri man go; $',\n",
       " '^  ma  tu  chi  se’,  che  sì  se’  fat to  brut to?». $',\n",
       " '^  Ri spuo se:«  Ve di  che  son  un  che  pian go». $',\n",
       " '^  E  io  a  lui:«  Con  pian ge re e  con  lut to, $',\n",
       " '^  spi ri to  ma la det to,  ti  ri ma ni; $',\n",
       " '^  ch’ i’  ti  co no sco, an cor  sie  lor do  tut to». $',\n",
       " '^  Al lor  di ste se al  le gno am bo  le  ma ni; $',\n",
       " '^  per  che ’l  ma e stro ac cor to  lo  so spin se, $',\n",
       " '^  di cen do:«  Via  co stà  con  li al tri  ca ni!». $',\n",
       " '^  Lo  col lo  poi  con  le  brac cia  mi  cin se; $',\n",
       " '^  ba sciom mi ’l  vol to e  dis se:« Al ma  sde gno sa, $',\n",
       " '^  be ne det ta  co lei  che ’n  te  s’ in cin se! $',\n",
       " '^  Quei  fu  al  mon do  per so na or go glio sa; $',\n",
       " '^  bon tà  non  è  che  sua  me mo ria  fre gi: $',\n",
       " '^  co sì  s’ è  l’ om bra  sua  qui  fu rï o sa. $',\n",
       " ...]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text_prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\", lower=False, oov_token='<UNK>')\n",
    "input_tokenizer.fit_on_texts(input_text_prepr)\n",
    "\n",
    "input_text_lines_enc = input_tokenizer.texts_to_sequences(input_text_prepr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\", split=' ', lower=False, oov_token='<UNK>')\n",
    "output_tokenizer.fit_on_texts(target_text_prepr)\n",
    "\n",
    "target_text_lines_enc = output_tokenizer.texts_to_sequences(target_text_prepr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 1,\n",
       " '^': 2,\n",
       " '$': 3,\n",
       " 'e': 4,\n",
       " 'di': 5,\n",
       " 'che': 6,\n",
       " 'a': 7,\n",
       " 'la': 8,\n",
       " 'to': 9,\n",
       " 'co': 10,\n",
       " 'te': 11,\n",
       " 'si': 12,\n",
       " 'per': 13,\n",
       " 'se': 14,\n",
       " 'in': 15,\n",
       " 'l’': 16,\n",
       " 'le': 17,\n",
       " 'do': 18,\n",
       " 'al': 19,\n",
       " 'de': 20,\n",
       " 'ta': 21,\n",
       " 'ra': 22,\n",
       " 'ma': 23,\n",
       " 'ti': 24,\n",
       " 'mi': 25,\n",
       " 'no': 26,\n",
       " 'li': 27,\n",
       " 'me': 28,\n",
       " 've': 29,\n",
       " 'so': 30,\n",
       " 'non': 31,\n",
       " 'ri': 32,\n",
       " 'con': 33,\n",
       " 'vi': 34,\n",
       " 're': 35,\n",
       " 'lo': 36,\n",
       " 'ne': 37,\n",
       " 'na': 38,\n",
       " 'da': 39,\n",
       " 'ch’': 40,\n",
       " 'sì': 41,\n",
       " 'mo': 42,\n",
       " 'o': 43,\n",
       " '’l': 44,\n",
       " 'sa': 45,\n",
       " 'po': 46,\n",
       " 'io': 47,\n",
       " 'ce': 48,\n",
       " 'va': 49,\n",
       " 'ro': 50,\n",
       " 'quel': 51,\n",
       " 'd’': 52,\n",
       " 'è': 53,\n",
       " 'pa': 54,\n",
       " 'ca': 55,\n",
       " 'u': 56,\n",
       " 'tu': 57,\n",
       " 'il': 58,\n",
       " 'più': 59,\n",
       " 'ni': 60,\n",
       " 'tro': 61,\n",
       " 'an': 62,\n",
       " 'que': 63,\n",
       " 'vo': 64,\n",
       " 'del': 65,\n",
       " 'men': 66,\n",
       " 'i': 67,\n",
       " 'par': 68,\n",
       " 'tra': 69,\n",
       " 's’': 70,\n",
       " 'ci': 71,\n",
       " 'cor': 72,\n",
       " 'quan': 73,\n",
       " 'sta': 74,\n",
       " 'fa': 75,\n",
       " 'chi': 76,\n",
       " 'ver': 77,\n",
       " 'un': 78,\n",
       " 'za': 79,\n",
       " 'sto': 80,\n",
       " 'to,': 81,\n",
       " 'tan': 82,\n",
       " 'pe': 83,\n",
       " 'E': 84,\n",
       " 'tut': 85,\n",
       " 'vol': 86,\n",
       " 'ché': 87,\n",
       " 'te,': 88,\n",
       " 'be': 89,\n",
       " 'fu': 90,\n",
       " 'ter': 91,\n",
       " 'ser': 92,\n",
       " 'es': 93,\n",
       " 'san': 94,\n",
       " 'gi': 95,\n",
       " '«': 96,\n",
       " 'lu': 97,\n",
       " 'fe': 98,\n",
       " 'lor': 99,\n",
       " 'fi': 100,\n",
       " 'suo': 101,\n",
       " 'ar': 102,\n",
       " 'el': 103,\n",
       " 'tor': 104,\n",
       " 'dis': 105,\n",
       " 'pre': 106,\n",
       " 'nel': 107,\n",
       " 'sti': 108,\n",
       " 'ac': 109,\n",
       " 'su': 110,\n",
       " 'pri': 111,\n",
       " 'ta,': 112,\n",
       " 'qua': 113,\n",
       " 'tri': 114,\n",
       " 'go': 115,\n",
       " 'on': 116,\n",
       " 'du': 117,\n",
       " 'sua': 118,\n",
       " 'm’': 119,\n",
       " 'oc': 120,\n",
       " 'ge': 121,\n",
       " 'ven': 122,\n",
       " 'cia': 123,\n",
       " 'qui': 124,\n",
       " 'son': 125,\n",
       " 'mon': 126,\n",
       " 'for': 127,\n",
       " 'gio': 128,\n",
       " 'sen': 129,\n",
       " 'mor': 130,\n",
       " 'là': 131,\n",
       " 'gen': 132,\n",
       " 'lui': 133,\n",
       " 'der': 134,\n",
       " 'ten': 135,\n",
       " 'col': 136,\n",
       " 'tre': 137,\n",
       " '’n': 138,\n",
       " 'man': 139,\n",
       " 'stra': 140,\n",
       " 'do,': 141,\n",
       " 'se,': 142,\n",
       " 'cre': 143,\n",
       " 'cer': 144,\n",
       " 'già': 145,\n",
       " 'bi': 146,\n",
       " 'mio': 147,\n",
       " 'Ma': 148,\n",
       " 'den': 149,\n",
       " 'pro': 150,\n",
       " 'ra,': 151,\n",
       " 'ran': 152,\n",
       " 'gra': 153,\n",
       " 'ciò': 154,\n",
       " 'cu': 155,\n",
       " 'rò': 156,\n",
       " 'fo': 157,\n",
       " 'ti,': 158,\n",
       " 'no,': 159,\n",
       " 'poi': 160,\n",
       " 'gne': 161,\n",
       " 'cen': 162,\n",
       " 'van': 163,\n",
       " 'so,': 164,\n",
       " 'ga': 165,\n",
       " 'pen': 166,\n",
       " 'stro': 167,\n",
       " 'ad': 168,\n",
       " 'tal': 169,\n",
       " 'or': 170,\n",
       " 'ap': 171,\n",
       " 'i’': 172,\n",
       " 'Co': 173,\n",
       " 'sé': 174,\n",
       " 't’': 175,\n",
       " 'mia': 176,\n",
       " 'qual': 177,\n",
       " 'por': 178,\n",
       " 'O': 179,\n",
       " 'pie': 180,\n",
       " 'mai': 181,\n",
       " 'giu': 182,\n",
       " 'can': 183,\n",
       " 'ben': 184,\n",
       " 'dal': 185,\n",
       " 'to.': 186,\n",
       " 'min': 187,\n",
       " 'pi': 188,\n",
       " 'fos': 189,\n",
       " 'ha': 190,\n",
       " 'pur': 191,\n",
       " 'ba': 192,\n",
       " 'gno': 193,\n",
       " 'gia': 194,\n",
       " 'fer': 195,\n",
       " 'fat': 196,\n",
       " 'nan': 197,\n",
       " 'A': 198,\n",
       " 'chia': 199,\n",
       " 'noi': 200,\n",
       " 'scia': 201,\n",
       " 'glia': 202,\n",
       " 'cui': 203,\n",
       " 'na,': 204,\n",
       " 'com’': 205,\n",
       " 'pas': 206,\n",
       " 'gna': 207,\n",
       " 're,': 208,\n",
       " 'de,': 209,\n",
       " 'né': 210,\n",
       " 'gran': 211,\n",
       " 'gri': 212,\n",
       " 'Io': 213,\n",
       " 'sem': 214,\n",
       " 'guar': 215,\n",
       " 'te.': 216,\n",
       " 'zi': 217,\n",
       " 'tar': 218,\n",
       " 'let': 219,\n",
       " 'zia': 220,\n",
       " 'at': 221,\n",
       " 'che,': 222,\n",
       " 'giù': 223,\n",
       " 'sù': 224,\n",
       " 'ste': 225,\n",
       " 'as': 226,\n",
       " 'sce': 227,\n",
       " 'chio': 228,\n",
       " 'ta.': 229,\n",
       " 'car': 230,\n",
       " 'tem': 231,\n",
       " 'pia': 232,\n",
       " 'fuor': 233,\n",
       " 'pian': 234,\n",
       " 'vea': 235,\n",
       " 'spe': 236,\n",
       " 'si,': 237,\n",
       " 'v’': 238,\n",
       " 'die': 239,\n",
       " 'La': 240,\n",
       " 'ro,': 241,\n",
       " 'ne,': 242,\n",
       " 'sol': 243,\n",
       " 'dol': 244,\n",
       " 'bel': 245,\n",
       " 'sot': 246,\n",
       " 'rà': 247,\n",
       " 'glio': 248,\n",
       " 'ren': 249,\n",
       " 'vien': 250,\n",
       " 'av': 251,\n",
       " 'dan': 252,\n",
       " 'due': 253,\n",
       " 'bra': 254,\n",
       " 'lar': 255,\n",
       " 'sie': 256,\n",
       " 'det': 257,\n",
       " 'zo': 258,\n",
       " 'co,': 259,\n",
       " 'et': 260,\n",
       " 'la,': 261,\n",
       " 'spi': 262,\n",
       " 'lo,': 263,\n",
       " 'pres': 264,\n",
       " 'va,': 265,\n",
       " 'en': 266,\n",
       " 'ria': 267,\n",
       " 'se:«': 268,\n",
       " 'mar': 269,\n",
       " 'le,': 270,\n",
       " 'com': 271,\n",
       " 'tuo': 272,\n",
       " 'tua': 273,\n",
       " 'n’': 274,\n",
       " 'far': 275,\n",
       " 'me,': 276,\n",
       " 'ce,': 277,\n",
       " 'don': 278,\n",
       " 'dar': 279,\n",
       " 'spet': 280,\n",
       " 'sco': 281,\n",
       " 'om': 282,\n",
       " 'fon': 283,\n",
       " 'Non': 284,\n",
       " 'fan': 285,\n",
       " 'da,': 286,\n",
       " 'te;': 287,\n",
       " 'gui': 288,\n",
       " 'tà': 289,\n",
       " 'spuo': 290,\n",
       " 'to;': 291,\n",
       " 'Se': 292,\n",
       " 'mol': 293,\n",
       " 'nu': 294,\n",
       " 'mal': 295,\n",
       " 'Dio': 296,\n",
       " 'se.': 297,\n",
       " 'lei': 298,\n",
       " 'quin': 299,\n",
       " 'lun': 300,\n",
       " 'sta,': 301,\n",
       " 'am': 302,\n",
       " 'veg': 303,\n",
       " 'dir': 304,\n",
       " 'len': 305,\n",
       " 'bo': 306,\n",
       " 'Per': 307,\n",
       " 'voi': 308,\n",
       " 'af': 309,\n",
       " 'ra.': 310,\n",
       " 'pos': 311,\n",
       " 'scen': 312,\n",
       " 'pren': 313,\n",
       " 'sai': 314,\n",
       " 'vir': 315,\n",
       " 'ciel': 316,\n",
       " 'cie': 317,\n",
       " 'sa,': 318,\n",
       " 'vin': 319,\n",
       " 'pun': 320,\n",
       " 'sia': 321,\n",
       " 'no.': 322,\n",
       " 'scu': 323,\n",
       " 'nar': 324,\n",
       " 'quei': 325,\n",
       " 'mos': 326,\n",
       " 'im': 327,\n",
       " 'mu': 328,\n",
       " 'stan': 329,\n",
       " 'ed': 330,\n",
       " 'di,': 331,\n",
       " 'vel': 332,\n",
       " 'Or': 333,\n",
       " 'giun': 334,\n",
       " 'fé': 335,\n",
       " 'li,': 336,\n",
       " 'pria': 337,\n",
       " 'gu': 338,\n",
       " 'Di': 339,\n",
       " 'reb': 340,\n",
       " 'zio': 341,\n",
       " 'lan': 342,\n",
       " 'Que': 343,\n",
       " 'gior': 344,\n",
       " 'bian': 345,\n",
       " 'spo': 346,\n",
       " 'so.': 347,\n",
       " 'za,': 348,\n",
       " 'fiam': 349,\n",
       " 'ca,': 350,\n",
       " 'a’': 351,\n",
       " 'cam': 352,\n",
       " 'fia': 353,\n",
       " 'rag': 354,\n",
       " 'fui': 355,\n",
       " 'ti.': 356,\n",
       " 'Lo': 357,\n",
       " 'c’': 358,\n",
       " 'Al': 359,\n",
       " 'ta;': 360,\n",
       " 'In': 361,\n",
       " 'cun': 362,\n",
       " 'Poi': 363,\n",
       " 'suoi': 364,\n",
       " 'se’': 365,\n",
       " 'vra': 366,\n",
       " 'ma,': 367,\n",
       " 'fac': 368,\n",
       " 'stel': 369,\n",
       " 'Ve': 370,\n",
       " 'stri': 371,\n",
       " 'Ed': 372,\n",
       " 'ru': 373,\n",
       " 'rï': 374,\n",
       " 'miei': 375,\n",
       " 'fal': 376,\n",
       " 'cin': 377,\n",
       " 'mi,': 378,\n",
       " 'sca': 379,\n",
       " 'ver’': 380,\n",
       " 'ni,': 381,\n",
       " 'sue': 382,\n",
       " 'sor': 383,\n",
       " 'cio': 384,\n",
       " 'ri,': 385,\n",
       " 'Quan': 386,\n",
       " 'scun': 387,\n",
       " 'pra': 388,\n",
       " 'mez': 389,\n",
       " 'de’': 390,\n",
       " 'mo,': 391,\n",
       " 'eb': 392,\n",
       " 'val': 393,\n",
       " 'rar': 394,\n",
       " 'Po': 395,\n",
       " 'tù': 396,\n",
       " 'fet': 397,\n",
       " 'se;': 398,\n",
       " 'cal': 399,\n",
       " 'gua': 400,\n",
       " 'ron': 401,\n",
       " 'fron': 402,\n",
       " 'puo': 403,\n",
       " 'lie': 404,\n",
       " 'me:«': 405,\n",
       " 'gue': 406,\n",
       " 'ne.': 407,\n",
       " 'L’': 408,\n",
       " 'via': 409,\n",
       " 'ab': 410,\n",
       " 'piè': 411,\n",
       " 'er': 412,\n",
       " 'vil': 413,\n",
       " 'buon': 414,\n",
       " 'sì,': 415,\n",
       " 'dre': 416,\n",
       " 'gion': 417,\n",
       " 'fin': 418,\n",
       " 'pin': 419,\n",
       " 'lon': 420,\n",
       " 'zion': 421,\n",
       " 'mag': 422,\n",
       " 'io,': 423,\n",
       " 'nul': 424,\n",
       " 'lì': 425,\n",
       " 'scor': 426,\n",
       " 'no;': 427,\n",
       " 'dor': 428,\n",
       " 'han': 429,\n",
       " 'sto,': 430,\n",
       " 'vie': 431,\n",
       " 'leg': 432,\n",
       " 'of': 433,\n",
       " 'Tu': 434,\n",
       " 'de.': 435,\n",
       " 'ï': 436,\n",
       " 'na.': 437,\n",
       " 'ei': 438,\n",
       " 'pio': 439,\n",
       " 're.': 440,\n",
       " 'uom': 441,\n",
       " 'tol': 442,\n",
       " 'tel': 443,\n",
       " 'chiu': 444,\n",
       " 'Qui': 445,\n",
       " 'spa': 446,\n",
       " 'vam': 447,\n",
       " '’': 448,\n",
       " 'pu': 449,\n",
       " 'mio,': 450,\n",
       " 'sar': 451,\n",
       " 'som': 452,\n",
       " 'ber': 453,\n",
       " 'rea': 454,\n",
       " 'rai': 455,\n",
       " 'glie': 456,\n",
       " 'sal': 457,\n",
       " 'mer': 458,\n",
       " 'le.': 459,\n",
       " 'va.': 460,\n",
       " 'gno,': 461,\n",
       " 'Pe': 462,\n",
       " 'ces': 463,\n",
       " 'lin': 464,\n",
       " 'var': 465,\n",
       " 'buo': 466,\n",
       " 'dea': 467,\n",
       " 'cel': 468,\n",
       " 'fra': 469,\n",
       " 'stre': 470,\n",
       " 'trat': 471,\n",
       " 'mil': 472,\n",
       " 'dia': 473,\n",
       " 'ler': 474,\n",
       " 'hai': 475,\n",
       " 'so;': 476,\n",
       " 'fum': 477,\n",
       " 'fug': 478,\n",
       " 'ra;': 479,\n",
       " 'bat': 480,\n",
       " 'Ca': 481,\n",
       " 'ia': 482,\n",
       " 'ae': 483,\n",
       " 'mes': 484,\n",
       " 'I': 485,\n",
       " 'rio': 486,\n",
       " 've,': 487,\n",
       " 'vi,': 488,\n",
       " 'do.': 489,\n",
       " 'ol': 490,\n",
       " 'stes': 491,\n",
       " 'pet': 492,\n",
       " 'Quel': 493,\n",
       " 'ger': 494,\n",
       " 'bia': 495,\n",
       " 'fio': 496,\n",
       " 'An': 497,\n",
       " 'la.': 498,\n",
       " 'gna,': 499,\n",
       " 'cia,': 500,\n",
       " 'stro,': 501,\n",
       " 'Noi': 502,\n",
       " 'ves': 503,\n",
       " 'Le': 504,\n",
       " 'zia,': 505,\n",
       " 'sio': 506,\n",
       " 'ze': 507,\n",
       " 'Cri': 508,\n",
       " 'stu': 509,\n",
       " 'On': 510,\n",
       " 'bre': 511,\n",
       " 'nol': 512,\n",
       " 'spon': 513,\n",
       " 'sur': 514,\n",
       " 'dì': 515,\n",
       " 'drit': 516,\n",
       " 'Bea': 517,\n",
       " 'spir': 518,\n",
       " 'può': 519,\n",
       " 'cea': 520,\n",
       " 'sof': 521,\n",
       " 'pon': 522,\n",
       " 'San': 523,\n",
       " 'fie': 524,\n",
       " 'ce.': 525,\n",
       " 'co.': 526,\n",
       " 'scer': 527,\n",
       " 'Da': 528,\n",
       " 'set': 529,\n",
       " 'pec': 530,\n",
       " 'mem': 531,\n",
       " 'tò': 532,\n",
       " 'se,«': 533,\n",
       " 'ci,': 534,\n",
       " 'ti;': 535,\n",
       " 'Ro': 536,\n",
       " 'ag': 537,\n",
       " 'ro.': 538,\n",
       " 'rac': 539,\n",
       " 'glo': 540,\n",
       " 'fen': 541,\n",
       " 'ne’': 542,\n",
       " 'trop': 543,\n",
       " 'splen': 544,\n",
       " 'brac': 545,\n",
       " 'da.': 546,\n",
       " 'ghi': 547,\n",
       " 'sel': 548,\n",
       " 'trui': 549,\n",
       " 'pel': 550,\n",
       " 'ner': 551,\n",
       " 'chie': 552,\n",
       " 'Li': 553,\n",
       " 'gan': 554,\n",
       " 'Sì': 555,\n",
       " 'sci': 556,\n",
       " 'bas': 557,\n",
       " 'tro,': 558,\n",
       " 'tai': 559,\n",
       " 'glia,': 560,\n",
       " 'fol': 561,\n",
       " 'met': 562,\n",
       " 'tras': 563,\n",
       " 'sa.': 564,\n",
       " 'ho': 565,\n",
       " 'not': 566,\n",
       " 'bu': 567,\n",
       " '“': 568,\n",
       " 'driz': 569,\n",
       " 'scol': 570,\n",
       " 'ul': 571,\n",
       " 'des': 572,\n",
       " 'lio': 573,\n",
       " 'ge,': 574,\n",
       " 'cit': 575,\n",
       " 'e’': 576,\n",
       " 'tur': 577,\n",
       " 'to».': 578,\n",
       " 'rei': 579,\n",
       " 'prie': 580,\n",
       " 'gni': 581,\n",
       " 'Vir': 582,\n",
       " 're;': 583,\n",
       " 'bil': 584,\n",
       " 'nir': 585,\n",
       " 'si.': 586,\n",
       " 'El': 587,\n",
       " 'gel': 588,\n",
       " 'sov': 589,\n",
       " 'fes': 590,\n",
       " 'stret': 591,\n",
       " 'fiu': 592,\n",
       " 'sti,': 593,\n",
       " 'I’': 594,\n",
       " 'rin': 595,\n",
       " 'ga,': 596,\n",
       " 'sï': 597,\n",
       " 'glio,': 598,\n",
       " 'tr’': 599,\n",
       " 'bar': 600,\n",
       " 'rot': 601,\n",
       " 'sta.': 602,\n",
       " 'io:«': 603,\n",
       " 'nò': 604,\n",
       " 'gli': 605,\n",
       " 'cro': 606,\n",
       " 'bol': 607,\n",
       " 'scon': 608,\n",
       " 'ec': 609,\n",
       " 'st’': 610,\n",
       " 'lia': 611,\n",
       " 'lui:«': 612,\n",
       " 'ro;': 613,\n",
       " 'tin': 614,\n",
       " 'ai': 615,\n",
       " 'fre': 616,\n",
       " 'co;': 617,\n",
       " 'cuo': 618,\n",
       " 'star': 619,\n",
       " 'rie': 620,\n",
       " 'fis': 621,\n",
       " '’m': 622,\n",
       " 'prin': 623,\n",
       " 'nen': 624,\n",
       " 'Mi': 625,\n",
       " 'lui,': 626,\n",
       " 'Ri': 627,\n",
       " 'si;': 628,\n",
       " 'pol': 629,\n",
       " 'drai': 630,\n",
       " 'S’': 631,\n",
       " 'cru': 632,\n",
       " 'do:«': 633,\n",
       " 'pic': 634,\n",
       " 'ne;': 635,\n",
       " 'gio,': 636,\n",
       " 'na;': 637,\n",
       " 'spen': 638,\n",
       " 'boc': 639,\n",
       " 'din': 640,\n",
       " 'Ben': 641,\n",
       " 'stin': 642,\n",
       " 'cir': 643,\n",
       " 'vòl': 644,\n",
       " 'le;': 645,\n",
       " 'au': 646,\n",
       " 'trar': 647,\n",
       " 'fuo': 648,\n",
       " 'tì': 649,\n",
       " 'ta».': 650,\n",
       " 'dot': 651,\n",
       " 'Ar': 652,\n",
       " 'las': 653,\n",
       " 'giar': 654,\n",
       " 'dio': 655,\n",
       " 'dim': 656,\n",
       " 'rat': 657,\n",
       " 'gia,': 658,\n",
       " 'Fi': 659,\n",
       " 'cri': 660,\n",
       " 'po,': 661,\n",
       " 'sun': 662,\n",
       " 'ni;': 663,\n",
       " 'Qual': 664,\n",
       " 'ton': 665,\n",
       " 'io,«': 666,\n",
       " 'vò': 667,\n",
       " 'spec': 668,\n",
       " 'Già': 669,\n",
       " 'ban': 670,\n",
       " 'me.': 671,\n",
       " 'zï': 672,\n",
       " 'la;': 673,\n",
       " 'Oh': 674,\n",
       " 'sap': 675,\n",
       " 'Si': 676,\n",
       " 'Pa': 677,\n",
       " 'cos': 678,\n",
       " 'stui': 679,\n",
       " 'cac': 680,\n",
       " 'vuol': 681,\n",
       " 'sa;': 682,\n",
       " 'nor': 683,\n",
       " 'lo.': 684,\n",
       " 'spes': 685,\n",
       " 'nes': 686,\n",
       " 'To': 687,\n",
       " 'ca.': 688,\n",
       " 'stor': 689,\n",
       " 'ce;': 690,\n",
       " 'Con': 691,\n",
       " 'dre,': 692,\n",
       " 'mie': 693,\n",
       " 'li.': 694,\n",
       " 'sten': 695,\n",
       " 'trï': 696,\n",
       " 'vï': 697,\n",
       " 'de;': 698,\n",
       " 'ria,': 699,\n",
       " 'em': 700,\n",
       " 'rò,': 701,\n",
       " 'rer': 702,\n",
       " 'Be': 703,\n",
       " 'puoi': 704,\n",
       " 'quat': 705,\n",
       " 'ma.': 706,\n",
       " 'Che': 707,\n",
       " 'roc': 708,\n",
       " 'go,': 709,\n",
       " 'noi,': 710,\n",
       " 'Chi': 711,\n",
       " 'sciol': 712,\n",
       " 'do;': 713,\n",
       " 'nac': 714,\n",
       " 'sier': 715,\n",
       " 'za.': 716,\n",
       " 'iu': 717,\n",
       " 'cet': 718,\n",
       " 'Te': 719,\n",
       " 'Qua': 720,\n",
       " 'do».': 721,\n",
       " 'ri.': 722,\n",
       " 'Mar': 723,\n",
       " 'tuoi': 724,\n",
       " 'ni.': 725,\n",
       " 'va;': 726,\n",
       " 'chi,': 727,\n",
       " 'ciò:«': 728,\n",
       " 'uo': 729,\n",
       " 'stia': 730,\n",
       " 'vuo’': 731,\n",
       " 'fu’': 732,\n",
       " 'bru': 733,\n",
       " 'scri': 734,\n",
       " 'fï': 735,\n",
       " 'schie': 736,\n",
       " 'dï': 737,\n",
       " 'te».': 738,\n",
       " 'muo': 739,\n",
       " 'zo,': 740,\n",
       " 'nim': 741,\n",
       " 'De': 742,\n",
       " 'gon': 743,\n",
       " 'strin': 744,\n",
       " 'coi': 745,\n",
       " 'r’': 746,\n",
       " 'U': 747,\n",
       " 'bal': 748,\n",
       " 'tir': 749,\n",
       " 'tal,': 750,\n",
       " 'sù,': 751,\n",
       " 'spal': 752,\n",
       " 'pa,': 753,\n",
       " 'sta;': 754,\n",
       " 'da;': 755,\n",
       " 'reg': 756,\n",
       " 'to:': 757,\n",
       " 'si:«': 758,\n",
       " 'lor,': 759,\n",
       " 'dem': 760,\n",
       " 'piac': 761,\n",
       " 'tue': 762,\n",
       " 'dun': 763,\n",
       " 'sto.': 764,\n",
       " 'ché,': 765,\n",
       " 'pron': 766,\n",
       " 'z’': 767,\n",
       " 'tien': 768,\n",
       " 'fred': 769,\n",
       " 'bon': 770,\n",
       " 'dò:«': 771,\n",
       " 'gno.': 772,\n",
       " 'sas': 773,\n",
       " 'Gio': 774,\n",
       " 'smu': 775,\n",
       " 'gliar': 776,\n",
       " 'vai': 777,\n",
       " 'tez': 778,\n",
       " 'Men': 779,\n",
       " 'lei,': 780,\n",
       " 'quai': 781,\n",
       " 'gna.': 782,\n",
       " 'Pie': 783,\n",
       " 'fur': 784,\n",
       " 'ro».': 785,\n",
       " 'tra,': 786,\n",
       " 'git': 787,\n",
       " 'dub': 788,\n",
       " 'nia': 789,\n",
       " 'gros': 790,\n",
       " 'toc': 791,\n",
       " 'Gui': 792,\n",
       " 'dò': 793,\n",
       " 'Bë': 794,\n",
       " 'ciar': 795,\n",
       " 'fui,': 796,\n",
       " 'di.': 797,\n",
       " 'glia.': 798,\n",
       " 'til': 799,\n",
       " 'guer': 800,\n",
       " 'Dio,': 801,\n",
       " 'gir': 802,\n",
       " 'Fa': 803,\n",
       " 'sde': 804,\n",
       " 'Quin': 805,\n",
       " 'nuo': 806,\n",
       " 'cad': 807,\n",
       " 'Mo': 808,\n",
       " 'bro': 809,\n",
       " 'ral': 810,\n",
       " 'tea': 811,\n",
       " 'schi': 812,\n",
       " 'spar': 813,\n",
       " 'poi,': 814,\n",
       " 'gian': 815,\n",
       " 'For': 816,\n",
       " 'rel': 817,\n",
       " 'frut': 818,\n",
       " 'gi,': 819,\n",
       " 'dei': 820,\n",
       " 'tie': 821,\n",
       " 'rec': 822,\n",
       " 'ret': 823,\n",
       " 'vuo': 824,\n",
       " 'be,': 825,\n",
       " 'co’': 826,\n",
       " 'Vi': 827,\n",
       " 'Tut': 828,\n",
       " 'zi,': 829,\n",
       " 'là,': 830,\n",
       " 'mai,': 831,\n",
       " 'bri': 832,\n",
       " 'smo': 833,\n",
       " 'tü': 834,\n",
       " 'Do': 835,\n",
       " 'Car': 836,\n",
       " 'scar': 837,\n",
       " 'mia,': 838,\n",
       " 'stra,': 839,\n",
       " 'vria': 840,\n",
       " 'que,': 841,\n",
       " 'pien': 842,\n",
       " 'sag': 843,\n",
       " 'seg': 844,\n",
       " 'ciai:«': 845,\n",
       " 'Lu': 846,\n",
       " 'Ta': 847,\n",
       " 'scrit': 848,\n",
       " 'nob': 849,\n",
       " 'me;': 850,\n",
       " 'ti».': 851,\n",
       " 'Tra': 852,\n",
       " 'Sa': 853,\n",
       " 'So': 854,\n",
       " 'ghe': 855,\n",
       " 'Cer': 856,\n",
       " 'pan': 857,\n",
       " 'sé,': 858,\n",
       " 'bor': 859,\n",
       " 'di’': 860,\n",
       " 'scel': 861,\n",
       " 'vo,': 862,\n",
       " '’ve': 863,\n",
       " 'net': 864,\n",
       " 'Né': 865,\n",
       " 'mi.': 866,\n",
       " 'ti’': 867,\n",
       " 'dai': 868,\n",
       " 'via,': 869,\n",
       " 'mò': 870,\n",
       " 'gnor': 871,\n",
       " 'di;': 872,\n",
       " 'se:': 873,\n",
       " 'zan': 874,\n",
       " 'cian': 875,\n",
       " 'vec': 876,\n",
       " 'chio,': 877,\n",
       " 'noc': 878,\n",
       " 'nea': 879,\n",
       " 'vo’': 880,\n",
       " 'è,': 881,\n",
       " 'ba,': 882,\n",
       " 'tor,': 883,\n",
       " 'stet': 884,\n",
       " 'ra».': 885,\n",
       " 'ce».': 886,\n",
       " 'sper': 887,\n",
       " 'Fio': 888,\n",
       " 'zò': 889,\n",
       " 'tre,': 890,\n",
       " 'strar': 891,\n",
       " 'scal': 892,\n",
       " 'dos': 893,\n",
       " 'lo;': 894,\n",
       " 'li;': 895,\n",
       " 'nï': 896,\n",
       " 'smar': 897,\n",
       " 'Ahi': 898,\n",
       " 'Tan': 899,\n",
       " 'mat': 900,\n",
       " 'rir': 901,\n",
       " 'ef': 902,\n",
       " 'fran': 903,\n",
       " 'ta:': 904,\n",
       " 'suon': 905,\n",
       " 'sciu': 906,\n",
       " 're:': 907,\n",
       " 'tun': 908,\n",
       " 'giù,': 909,\n",
       " 'cia.': 910,\n",
       " 'Ce': 911,\n",
       " 'cia;': 912,\n",
       " 'ci.': 913,\n",
       " 'ros': 914,\n",
       " 'so».': 915,\n",
       " 'ra:': 916,\n",
       " 'lui,«': 917,\n",
       " 'sin': 918,\n",
       " 'ca;': 919,\n",
       " 'spie': 920,\n",
       " 'og': 921,\n",
       " 'da’': 922,\n",
       " 'glior': 923,\n",
       " 'fret': 924,\n",
       " 'ric': 925,\n",
       " 'Pi': 926,\n",
       " 'trag': 927,\n",
       " 'sog': 928,\n",
       " 'Nel': 929,\n",
       " 'rit': 930,\n",
       " 'sciò': 931,\n",
       " 'pï': 932,\n",
       " 'Giu': 933,\n",
       " 'vi.': 934,\n",
       " 'scï': 935,\n",
       " 'qua,': 936,\n",
       " 'tà,': 937,\n",
       " 'Più': 938,\n",
       " 'ram': 939,\n",
       " 'pul': 940,\n",
       " 'bran': 941,\n",
       " 'sion': 942,\n",
       " 'guen': 943,\n",
       " 'tron': 944,\n",
       " 'der,': 945,\n",
       " 'pal': 946,\n",
       " 'ri;': 947,\n",
       " 'ciel,': 948,\n",
       " 'fit': 949,\n",
       " 'Fe': 950,\n",
       " 'e,': 951,\n",
       " 'gam': 952,\n",
       " 'sfa': 953,\n",
       " 'sma': 954,\n",
       " 'os': 955,\n",
       " 'ma;': 956,\n",
       " 'ir': 957,\n",
       " 'dif': 958,\n",
       " 'Chie': 959,\n",
       " 'ful': 960,\n",
       " 'bio': 961,\n",
       " 'gliuol': 962,\n",
       " 'peg': 963,\n",
       " 'scir': 964,\n",
       " 'u’': 965,\n",
       " 'bra,': 966,\n",
       " 've.': 967,\n",
       " 'soc': 968,\n",
       " 'scì': 969,\n",
       " 'gre': 970,\n",
       " 'gue,': 971,\n",
       " 'rem': 972,\n",
       " 'na».': 973,\n",
       " 'vean': 974,\n",
       " 'ti:': 975,\n",
       " 'Ga': 976,\n",
       " 'nie': 977,\n",
       " 'fa,': 978,\n",
       " 'se».': 979,\n",
       " 'Fran': 980,\n",
       " 'gem': 981,\n",
       " 'piog': 982,\n",
       " 'glian': 983,\n",
       " 'op': 984,\n",
       " 'sia,': 985,\n",
       " 'tac': 986,\n",
       " 'cas': 987,\n",
       " 'di».': 988,\n",
       " 'lez': 989,\n",
       " 'sug': 990,\n",
       " 'tran': 991,\n",
       " 'riz': 992,\n",
       " 'fian': 993,\n",
       " 'suo,': 994,\n",
       " 'ster': 995,\n",
       " 'luo': 996,\n",
       " 'Ba': 997,\n",
       " 'sul': 998,\n",
       " 'lò': 999,\n",
       " 'ciol': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_vocab_size = len(input_tokenizer.word_index)\n",
    "target_vocab_size = len(output_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "p-w27LhpY1db",
    "outputId": "d4061a9c-09a0-46c1-b0a0-501d897ab0e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 20750\n",
      "Target vocab size: 4191\n"
     ]
    }
   ],
   "source": [
    "print(\"Input vocab size: {}\".format(input_vocab_size))\n",
    "print(\"Target vocab size: {}\".format(target_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4bfzvcNvT-y"
   },
   "source": [
    "Padding is required in order to have a non-ragged tensor to feed to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "MBOh9LQeY1dg"
   },
   "outputs": [],
   "source": [
    "def pad(x):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(x, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "9zV0xz48Y1dh"
   },
   "outputs": [],
   "source": [
    "input_text = pad(input_text_lines_enc)\n",
    "target_text = pad(target_text_lines_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GVc41zvvdR9"
   },
   "source": [
    "## 2. The Transformer model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_text_ = []\n",
    "target_text_ = []\n",
    "\n",
    "for line_number in range(0, len(input_text) - 4):\n",
    "    \n",
    "    input_verses = []\n",
    "    target_verses = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        input_verses += list(input_text[line_number + i])\n",
    "        target_verses += list(target_text[line_number + i])\n",
    "    \n",
    "    input_text_.append(input_verses)\n",
    "    target_text_.append(target_verses)\n",
    "    \n",
    "input_text_ = np.array(input_text_)\n",
    "target_text_ = np.array(target_text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14229, 72)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "7xGxZmlPY1dk"
   },
   "outputs": [],
   "source": [
    "input_train, input_test, target_train, target_test = train_test_split(\n",
    "    input_text_, target_text_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IN8x175vimK"
   },
   "source": [
    "The dataset is created by grouping the lines in batches and by shuffling them.\n",
    "\n",
    "Each input's line is in correspondence with its target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "tZWLq7g3Y1dl"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
    "\n",
    "vocab_size = (\n",
    "    len(tokenizer.word_index) + 1\n",
    ")  # the +1 is added to take into account the id 0 of the padding\n",
    "\n",
    "max_length_targ, max_length_inp = target_text.shape[1], input_text.shape[1]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(\n",
    "    BUFFER_SIZE\n",
    ")\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RHNAazT5Rs_"
   },
   "source": [
    "We define the positional encoding to add to the embedding.\n",
    "\n",
    "This allows to take into account the order of the characters in the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "f200V0QnkBBS"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "OvnGjGhvkD9R"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "500eU4tu6n-g"
   },
   "source": [
    "We define two masks: \n",
    "\n",
    "one is used to mask the padding added to the sequences in the preprocessing step; \n",
    "\n",
    "the other one is used to mask the positions following the current one and not predicted yet;\n",
    "\n",
    "The first mask is used from both the encoder and the decoder, while the last mask is used only in the self-attention of the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "OVwx6Y4Tku1V"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "3p1-yIYimnvB"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "R-Q4J7EzfuLH"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxzWROrTM9ib"
   },
   "source": [
    "The *scaled_dot_product_attention* gets the attention weights by applying the softmax to the rescaled dot product between the query matrix and the key matrix, while the output is obtained by multiplying the value matrix for those attention weights.\n",
    "\n",
    "The query, key and value matrices are built by multiplying the embedding matrix with the query, key and value weight matrices, which initially are randomly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "RoFZK1S3mtI5"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "      q: query shape == (..., seq_len_q, depth)\n",
    "      k: key shape == (..., seq_len_k, depth)\n",
    "      v: value shape == (..., seq_len_v, depth_v)\n",
    "      mask: Float tensor with shape broadcastable\n",
    "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "      output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += mask * -1e9\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.nn.softmax(\n",
    "        scaled_attention_logits, axis=-1\n",
    "    )  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlA3inNYQO89"
   },
   "source": [
    "The multi-headed attention allows to improve the performance of the attention mechanism by working with multiple sets of query, key and value weight matrices.\n",
    "\n",
    "These heads work in parallel and process at the same time all the lines of each batch.\n",
    "\n",
    "At the end, the results of all the attention heads are concatenated and multiplied by an additional weight matrix, to adjust the dimension before passing through the final *point_wise_feed_forward_network*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "_UpdBWkVnK02"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask\n",
    "        )\n",
    "\n",
    "        scaled_attention = tf.transpose(\n",
    "            scaled_attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(\n",
    "            scaled_attention, (batch_size, -1, self.d_model)\n",
    "        )  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "LkMP7DDAok4y"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(dff, activation=\"relu\"),  # (batch_size, seq_len, dff)\n",
    "            tf.keras.layers.Dense(d_model),  # (batch_size, seq_len, d_model)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO6yyZPWUON7"
   },
   "source": [
    "Each encoder is constituted by a multi-headed self-attention layer and by a final feed forward layer. \n",
    "\n",
    "Both sub-layers have a residual connection around them and are followed by a layer-normalization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "Dat64C18otwC"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(\n",
    "            out1 + ffn_output\n",
    "        )  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GZslNuSZOKp"
   },
   "source": [
    "The decoder equals the encoder, a part from the fact that it contains a slightly different self-attention layer and an additional attention layer.\n",
    "\n",
    "Indeed, the decoder is characterized by a self-attention layer which focuses only on earlier positions in its input sequence, not looking at the positions which have not been predicted yet.\n",
    "\n",
    "What's more the decoder is also characterized by an attention layer which obtains its key and value matrices from the output of the encoder, while the query matrix is obtained from the output of the previous self-attention in the decoder.\n",
    "\n",
    "The encoder-decoder attention helps the decoder to focus on appropriate positions in the input sequence of the encoder during the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "7Vp44lQepI_P"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(\n",
    "            x, x, x, look_ahead_mask\n",
    "        )  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask\n",
    "        )  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(\n",
    "            ffn_output + out2\n",
    "        )  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zx_DyJiybrOr"
   },
   "source": [
    "The encoding component is a stack of encoders and the decoding component is a stack of decoders of the same number.\n",
    "\n",
    "At the beginning, in the encoding, each input character is turned into a vector using an embedding algorithm and adding the positional encoding to it.\n",
    "\n",
    "This happens only in the bottom-most encoder, while the following encoders take the output of the encoder which is directly below.\n",
    "\n",
    "The same for the decoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "awl9kiESpWBh"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        dff,\n",
    "        input_vocab_size,\n",
    "        maximum_position_encoding,\n",
    "        rate=0.1,\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "47tQAEMwpnUj"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        dff,\n",
    "        target_vocab_size,\n",
    "        maximum_position_encoding,\n",
    "        rate=0.1,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
    "        ]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](\n",
    "                x, enc_output, training, look_ahead_mask, padding_mask\n",
    "            )\n",
    "\n",
    "            attention_weights[f\"decoder_layer{i+1}_block1\"] = block1\n",
    "            attention_weights[f\"decoder_layer{i+1}_block2\"] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TosN_TpKk1eN"
   },
   "source": [
    "In the transformer, the output of the encoding is passed to the stack of decoders and the output of the decoding is projected by a feed forward network into a vector of logits of dimension equal to the one of the target's vocabulary.\n",
    "\n",
    "Obviously this is done for each character of each line of each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "qCNKKsQ-p99k"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        dff,\n",
    "        input_vocab_size,\n",
    "        target_vocab_size,\n",
    "        pe_input,\n",
    "        pe_target,\n",
    "        rate=0.1,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate\n",
    "        )\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(\n",
    "        self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask\n",
    "    ):\n",
    "\n",
    "        enc_output = self.encoder(\n",
    "            inp, training, enc_padding_mask\n",
    "        )  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask\n",
    "        )\n",
    "\n",
    "        final_output = self.final_layer(\n",
    "            dec_output\n",
    "        )  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PLTOETK4_m6"
   },
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "LrdL396xqOL4"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 256\n",
    "dff = 1024\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "JFCVQIDjqQHv"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "1R9MlFs0qc5U"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcmLAk1Ut8vG"
   },
   "source": [
    "The loss is calculated using Sparse Categorical Crossentropy and the loss of the padding is masked.\n",
    "\n",
    "The same is done for the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "TBAaRBPsqkuo"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "31R26t9wqlLD"
   },
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.cast(tf.argmax(pred, axis=2), dtype=tf.int32))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "SkVkWvL7qoYu"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.Mean(name=\"train_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "5UE3cWGVqvnS"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=vocab_size,\n",
    "    target_vocab_size=vocab_size,\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "nSE2Rh-_qzo7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Latest checkpoint restored!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITVGgP8Su9MH"
   },
   "source": [
    "To train the decoder we use teacher forcing, calculating the loss between the predicted logits and the real id of the character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "n_VPs6ZOva15"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "1ce0FAOivleY",
    "outputId": "9b69adc7-411a-4d93-a8f2-41a1cc72ca20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.9237 Accuracy 0.2388\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-55c2f9abe7e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}\"\n",
    "            )\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print(f\"Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}\"\n",
    "    )\n",
    "\n",
    "    print(f\"Time taken for 1 epoch: {time.time() - start:.2f} secs\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz4YwsF04YEI"
   },
   "source": [
    "## 4. Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O44l1saVuebS"
   },
   "source": [
    "We define the *evaluate* function to preprocess the sentence in input to the encoder and to get the predicted ids of the translation.\n",
    "\n",
    "The ids of the translation are obtained by applying *argmax* to the predicted logits of the decoder.\n",
    "\n",
    "We begin feeding the decoder with the id of the start symbol and, at each new step, we pass to the decoder the sequence it has just thrown out.\n",
    "\n",
    "The translation stops when the end symbol is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "BSNaKtSkvxcJ"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=200):\n",
    "\n",
    "    encoder_input = tokenizer.texts_to_sequences(sente)\n",
    "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [encoder_input], maxlen=max_length, padding=\"post\"\n",
    "    )\n",
    "    encoder_input = tf.convert_to_tensor(encoder_input)\n",
    "\n",
    "    output = tf.convert_to_tensor([tokenizer.word_index[\"^\"]])\n",
    "    output = tf.expand_dims(output, 0)\n",
    "    result = \"\"\n",
    "\n",
    "    for i in range(max_length):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output\n",
    "        )\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input,\n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask,\n",
    "        )\n",
    "\n",
    "        # select the last character from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
    "        output = tf.concat(\n",
    "            [tf.cast(output, dtype=tf.int32), tf.cast(predicted_id, dtype=tf.int32)],\n",
    "            axis=-1,\n",
    "        )\n",
    "        result += tokenizer.index_word[predicted_id.numpy()[0][0]] + \" \"\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer.word_index[\"$\"]:\n",
    "            break\n",
    "\n",
    "    # output.shape (1, tokens)\n",
    "\n",
    "    return result, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "PkCDxGdeyF9f"
   },
   "outputs": [],
   "source": [
    "def print_translation(sentence, result, ground_truth):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'{\"Prediction\":15s}: {result}')\n",
    "    print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "B5cULw_54F8w",
    "outputId": "c5591588-ffd5-43cb-9627-7398a9a6813c"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-ce262cbafb26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtranslated_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-184-e04e91f3d035>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, max_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-184-e04e91f3d035>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ' '"
     ]
    }
   ],
   "source": [
    "sentence = \"^ E come l’aere, quand’ è ben pïorno, $\"\n",
    "ground_truth = \"|E |co|me |l’ ae|re, |quan|d’ è |ben |pï|or|no,\"\n",
    "\n",
    "\n",
    "translated_text, attention_weights = evaluate(sentence)\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "V33sFY3iyLLE",
    "outputId": "eae3d80e-f5f2-4c4a-875e-1dd098e966ed"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-732188d497fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtranslated_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-184-e04e91f3d035>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, max_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-184-e04e91f3d035>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ' '"
     ]
    }
   ],
   "source": [
    "sentence = \"^ Buonasera a tutti $\"\n",
    "ground_truth = \"\"\n",
    "\n",
    "translated_text, attention_weights = evaluate(sentence)\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-psFsRBr5rE"
   },
   "source": [
    "# 5. Autoregressive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "avrTxm8pr5rF"
   },
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self, encoder, decoder, fc, tokenizer):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.fc = fc\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate(self, seed):\n",
    "        encoder_input = [tokenizer.word_index[i] for i in list(map(str, seed))]\n",
    "        encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            [encoder_input], maxlen=65, padding=\"post\"\n",
    "        )\n",
    "        encoder_input = tf.convert_to_tensor(encoder_input)\n",
    "\n",
    "        dec_input = tf.convert_to_tensor([self.tokenizer.word_index[\"^\"]])\n",
    "        dec_input = tf.expand_dims(dec_input, 0)\n",
    "\n",
    "        index_word = self.tokenizer.index_word\n",
    "\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, dec_input\n",
    "        )\n",
    "\n",
    "        end_symbol = \"$\"\n",
    "\n",
    "        result = \"\"\n",
    "\n",
    "        output = \"\"\n",
    "\n",
    "        initial_state = self.encoder(\n",
    "            encoder_input, False, enc_padding_mask\n",
    "        )  # tf.zeros((1, 65, 256)) #tf.random.uniform((1, 65, 256))\n",
    "\n",
    "        while output != end_symbol:\n",
    "\n",
    "            dec_output, attention_weights = self.decoder(\n",
    "                dec_input, initial_state, False, combined_mask, dec_padding_mask\n",
    "            )\n",
    "\n",
    "            logits = self.fc(dec_output)\n",
    "            logits = logits[:, -1, :]\n",
    "            logits = tf.reshape(logits, (1, 82))\n",
    "\n",
    "            output = tf.random.categorical(logits, 1)\n",
    "\n",
    "            output = output.numpy()[0][0]\n",
    "            output = index_word[output]\n",
    "\n",
    "            result += output\n",
    "\n",
    "            result_encoded = [tokenizer.word_index[i] for i in list(map(str, result))]\n",
    "            result_encoded = tf.convert_to_tensor(result_encoded)\n",
    "            result_encoded = tf.expand_dims(result_encoded, 0)\n",
    "\n",
    "            dec_input = result_encoded\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "d0CZpwFC8Ic3"
   },
   "outputs": [],
   "source": [
    "enc = transformer.encoder\n",
    "dec = transformer.decoder\n",
    "fc = transformer.final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "cxoNus12r5rF"
   },
   "outputs": [],
   "source": [
    "gen = TextGenerator(enc, dec, fc, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "gradient": {},
    "id": "BQy622iU-es0",
    "outputId": "7c2cbe90-5cb3-4d74-f630-5340b07be733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|CCoC|dbbbì|CCCoC|Cib|CCdCCo|Ccbbì|bì,|bib|CcCCoC|bbb,|bbbìbììbì,|bì|bì|bì|bìì|b|bè,$'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate(\"^C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "gradient": {},
    "id": "4avXbdgfr5rF",
    "outputId": "f4944fc6-a1cf-4c47-a6bf-9ddd619e190e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|lo|lo|ra |ci |ve|dia|mo |do|ma|ni$'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate(\"^Allora ci vediamo domani$\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Comedy transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
