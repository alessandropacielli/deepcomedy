{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZFNtyeMfmnp",
    "outputId": "6e9f12ff-da81-4814-acce-3cc52c333438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepcomedy/\n",
      "deepcomedy/utils.py\n",
      "deepcomedy/models/\n",
      "deepcomedy/models/layers.py\n",
      "deepcomedy/models/decoder_only.py\n",
      "deepcomedy/models/transformer.py\n",
      "deepcomedy/models/__pycache__/\n",
      "deepcomedy/models/__pycache__/layers.cpython-37.pyc\n",
      "deepcomedy/models/__pycache__/__init__.cpython-37.pyc\n",
      "deepcomedy/models/__pycache__/transformer.cpython-37.pyc\n",
      "deepcomedy/models/__init__.py\n",
      "deepcomedy/models/.ipynb_checkpoints/\n",
      "deepcomedy/models/.ipynb_checkpoints/transformer-checkpoint.py\n",
      "deepcomedy/preprocessing.py\n",
      "deepcomedy/__pycache__/\n",
      "deepcomedy/__pycache__/utils.cpython-37.pyc\n",
      "deepcomedy/__pycache__/__init__.cpython-37.pyc\n",
      "deepcomedy/__pycache__/preprocessing.cpython-37.pyc\n",
      "deepcomedy/metrics.py\n",
      "deepcomedy/__init__.py\n",
      "deepcomedy/.ipynb_checkpoints/\n",
      "data/\n",
      "data/orlando.txt\n",
      "data/divina_textonly.txt\n",
      "data/divina.txt\n",
      "data/divina_syll_textonly.txt\n",
      "data/orlando-textonly.txt\n",
      "data/divina_syll.txt\n",
      "data/.ipynb_checkpoints/\n",
      "data/.ipynb_checkpoints/orlando-checkpoint.txt\n",
      "data/.ipynb_checkpoints/orlando-textonly-checkpoint.txt\n",
      "data/.ipynb_checkpoints/divina_textonly-checkpoint.txt\n",
      "data/.ipynb_checkpoints/divina_syll-checkpoint.txt\n",
      "data/.ipynb_checkpoints/divina-checkpoint.txt\n",
      "data/.ipynb_checkpoints/divina_syll_textonly-checkpoint.txt\n"
     ]
    }
   ],
   "source": [
    "!tar zxvf deepcomedy.tar.gz\n",
    "!tar zxvf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YcDazsVbL_tS"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {},
    "id": "54j16swJY1dW"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from deepcomedy.models.transformer import *\n",
    "from deepcomedy.preprocessing import *\n",
    "from deepcomedy.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RuMqNB4ujuT",
    "tags": []
   },
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jH7n29oxB0z4"
   },
   "outputs": [],
   "source": [
    "raw_text = open(\"./data/divina_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
    "raw_syll_text = (\n",
    "    open(\"./data/divina_syll_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
    ")\n",
    "syll_text = preprocess_text(raw_syll_text, end_of_tercet='')\n",
    "text = preprocess_text(raw_text, end_of_tercet='', word_level= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ASHyaMBC84V"
   },
   "source": [
    "Split preprocessed text into verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-IF6sE6FC_4J"
   },
   "outputs": [],
   "source": [
    "sep = \"<EOV>\"\n",
    "input_tercets = [x.lstrip() + sep for x in text.split(sep)][:-1]\n",
    "target_tercets = [x.lstrip() + sep for x in syll_text.split(sep)][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdUmYhUKDEuj"
   },
   "source": [
    "Encode with input and target tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-mob1kOzDD4z"
   },
   "outputs": [],
   "source": [
    "input_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=False, filters=\"\", lower=False\n",
    ")\n",
    "input_tokenizer.fit_on_texts(input_tercets)\n",
    "\n",
    "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=False, filters=\"\", lower=False\n",
    ")\n",
    "target_tokenizer.fit_on_texts(target_tercets)\n",
    "\n",
    "enc_input_tercets = input_tokenizer.texts_to_sequences(input_tercets)\n",
    "enc_target_tercets = target_tokenizer.texts_to_sequences(target_tercets)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xDKv92yAL_t8"
   },
   "outputs": [],
   "source": [
    "input_text = []\n",
    "target_text = []\n",
    "target_text_tercet = []\n",
    "\n",
    "for line in range(len(enc_input_tercets) - 2):\n",
    "    input_text.append(list(chain(*enc_input_tercets[line : line + 3])))\n",
    "    target_text_tercet.append(list(chain(*enc_target_tercets[line : line + 3])))\n",
    "    target_text.append(list(chain(*enc_target_tercets[line : line + 4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY44HP5lKz2-"
   },
   "source": [
    "Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Pq34y57yK3wd"
   },
   "outputs": [],
   "source": [
    "padded_input_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    input_text, padding=\"post\"\n",
    ")\n",
    "padded_target_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    target_text, padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LdFUuDTcf0Mr"
   },
   "outputs": [],
   "source": [
    "input_train, input_val, target_train, target_val = train_test_split(padded_input_text, padded_target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYBcAQRsr4zX"
   },
   "source": [
    "## 2. Hyperparameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OnTScmSr7-z",
    "outputId": "1bd59626-9a78-402d-9e1c-f5390280e574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ohxcbbae\n",
      "Sweep URL: https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"word2char-gen-sweep-2\",\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"value\": 32},\n",
    "        \"epochs\": {\"value\": 15},\n",
    "        \"num_layers\": {\"values\": [4, 8, 12]},\n",
    "        \"num_heads\": {\"values\": [4, 8]},\n",
    "        \"d_model\": {\"value\": 256},\n",
    "        \"dff\": {\"values\": [512, 1024]},\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='deepcomedy', entity='deepcomedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "uXhx10XysCwB",
    "outputId": "585399be-6080-407d-de51-c0e73c8b9744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jq37nmvy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">frosty-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/jq37nmvy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/jq37nmvy</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_172205-jq37nmvy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.4572 Accuracy 0.0049\n",
      "Epoch 1 Batch 50 Loss 4.3120 Accuracy 0.1064\n",
      "Epoch 1 Batch 100 Loss 3.7332 Accuracy 0.1581\n",
      "Epoch 1 Batch 150 Loss 3.4701 Accuracy 0.1802\n",
      "Epoch 1 Batch 200 Loss 3.2360 Accuracy 0.2075\n",
      "Epoch 1 Batch 250 Loss 3.0311 Accuracy 0.2345\n",
      "Epoch 1 Batch 300 Loss 2.8734 Accuracy 0.2549\n",
      "Epoch 1 Loss 2.7931 Accuracy 0.2651\n",
      "Time taken for 1 epoch: 49.21 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0052 Accuracy 0.3713\n",
      "Epoch 2 Batch 50 Loss 2.0027 Accuracy 0.3675\n",
      "Epoch 2 Batch 100 Loss 1.9902 Accuracy 0.3687\n",
      "Epoch 2 Batch 150 Loss 1.9772 Accuracy 0.3708\n",
      "Epoch 2 Batch 200 Loss 1.9657 Accuracy 0.3728\n",
      "Epoch 2 Batch 250 Loss 1.9537 Accuracy 0.3758\n",
      "Epoch 2 Batch 300 Loss 1.9396 Accuracy 0.3793\n",
      "Epoch 2 Loss 1.9299 Accuracy 0.3816\n",
      "Time taken for 1 epoch: 40.37 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8242 Accuracy 0.4120\n",
      "Epoch 3 Batch 50 Loss 1.8062 Accuracy 0.4139\n",
      "Epoch 3 Batch 100 Loss 1.7871 Accuracy 0.4194\n",
      "Epoch 3 Batch 150 Loss 1.7680 Accuracy 0.4241\n",
      "Epoch 3 Batch 200 Loss 1.7503 Accuracy 0.4288\n",
      "Epoch 3 Batch 250 Loss 1.7337 Accuracy 0.4336\n",
      "Epoch 3 Batch 300 Loss 1.7193 Accuracy 0.4374\n",
      "Epoch 3 Loss 1.7094 Accuracy 0.4402\n",
      "Time taken for 1 epoch: 40.52 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.5939 Accuracy 0.4776\n",
      "Epoch 4 Batch 50 Loss 1.5966 Accuracy 0.4724\n",
      "Epoch 4 Batch 100 Loss 1.5828 Accuracy 0.4775\n",
      "Epoch 4 Batch 150 Loss 1.5706 Accuracy 0.4816\n",
      "Epoch 4 Batch 200 Loss 1.5607 Accuracy 0.4852\n",
      "Epoch 4 Batch 250 Loss 1.5495 Accuracy 0.4889\n",
      "Epoch 4 Batch 300 Loss 1.5396 Accuracy 0.4918\n",
      "Epoch 4 Loss 1.5331 Accuracy 0.4939\n",
      "Time taken for 1 epoch: 40.39 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4877 Accuracy 0.5117\n",
      "Epoch 5 Batch 50 Loss 1.4484 Accuracy 0.5196\n",
      "Epoch 5 Batch 100 Loss 1.4424 Accuracy 0.5218\n",
      "Epoch 5 Batch 150 Loss 1.4343 Accuracy 0.5245\n",
      "Epoch 5 Batch 200 Loss 1.4265 Accuracy 0.5273\n",
      "Epoch 5 Batch 250 Loss 1.4190 Accuracy 0.5295\n",
      "Epoch 5 Batch 300 Loss 1.4125 Accuracy 0.5315\n",
      "Epoch 5 Batch 0 Validation Loss 1.3150 Validation Accuracy 0.5663\n",
      "Epoch 5 Batch 50 Validation Loss 1.3078 Validation Accuracy 0.5670\n",
      "Epoch 5 Batch 100 Validation Loss 1.3045 Validation Accuracy 0.5664\n",
      "Epoch 5 Loss 1.4077 Accuracy 0.5330\n",
      "Time taken for 1 epoch: 54.24 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.3507 Accuracy 0.5496\n",
      "Epoch 6 Batch 50 Loss 1.3405 Accuracy 0.5543\n",
      "Epoch 6 Batch 100 Loss 1.3373 Accuracy 0.5558\n",
      "Epoch 6 Batch 150 Loss 1.3311 Accuracy 0.5577\n",
      "Epoch 6 Batch 200 Loss 1.3253 Accuracy 0.5595\n",
      "Epoch 6 Batch 250 Loss 1.3193 Accuracy 0.5614\n",
      "Epoch 6 Batch 300 Loss 1.3133 Accuracy 0.5636\n",
      "Epoch 6 Loss 1.3098 Accuracy 0.5649\n",
      "Time taken for 1 epoch: 40.30 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.2588 Accuracy 0.5742\n",
      "Epoch 7 Batch 50 Loss 1.2504 Accuracy 0.5839\n",
      "Epoch 7 Batch 100 Loss 1.2478 Accuracy 0.5841\n",
      "Epoch 7 Batch 150 Loss 1.2436 Accuracy 0.5855\n",
      "Epoch 7 Batch 200 Loss 1.2372 Accuracy 0.5880\n",
      "Epoch 7 Batch 250 Loss 1.2307 Accuracy 0.5904\n",
      "Epoch 7 Batch 300 Loss 1.2248 Accuracy 0.5927\n",
      "Epoch 7 Loss 1.2208 Accuracy 0.5941\n",
      "Time taken for 1 epoch: 40.57 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.1562 Accuracy 0.6197\n",
      "Epoch 8 Batch 50 Loss 1.1512 Accuracy 0.6173\n",
      "Epoch 8 Batch 100 Loss 1.1516 Accuracy 0.6176\n",
      "Epoch 8 Batch 150 Loss 1.1450 Accuracy 0.6199\n",
      "Epoch 8 Batch 200 Loss 1.1388 Accuracy 0.6220\n",
      "Epoch 8 Batch 250 Loss 1.1322 Accuracy 0.6244\n",
      "Epoch 8 Batch 300 Loss 1.1242 Accuracy 0.6274\n",
      "Epoch 8 Loss 1.1186 Accuracy 0.6295\n",
      "Time taken for 1 epoch: 40.27 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.0174 Accuracy 0.6625\n",
      "Epoch 9 Batch 50 Loss 1.0130 Accuracy 0.6655\n",
      "Epoch 9 Batch 100 Loss 0.9942 Accuracy 0.6726\n",
      "Epoch 9 Batch 150 Loss 0.9801 Accuracy 0.6776\n",
      "Epoch 9 Batch 200 Loss 0.9621 Accuracy 0.6841\n",
      "Epoch 9 Batch 250 Loss 0.9450 Accuracy 0.6901\n",
      "Epoch 9 Batch 300 Loss 0.9260 Accuracy 0.6967\n",
      "Epoch 9 Loss 0.9154 Accuracy 0.7004\n",
      "Time taken for 1 epoch: 40.95 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7848 Accuracy 0.7479\n",
      "Epoch 10 Batch 50 Loss 0.7488 Accuracy 0.7569\n",
      "Epoch 10 Batch 100 Loss 0.7395 Accuracy 0.7597\n",
      "Epoch 10 Batch 150 Loss 0.7256 Accuracy 0.7642\n",
      "Epoch 10 Batch 200 Loss 0.7164 Accuracy 0.7672\n",
      "Epoch 10 Batch 250 Loss 0.7060 Accuracy 0.7707\n",
      "Epoch 10 Batch 300 Loss 0.6950 Accuracy 0.7742\n",
      "Epoch 10 Batch 0 Validation Loss 0.5839 Validation Accuracy 0.8116\n",
      "Epoch 10 Batch 50 Validation Loss 0.5734 Validation Accuracy 0.8135\n",
      "Epoch 10 Batch 100 Validation Loss 0.5712 Validation Accuracy 0.8144\n",
      "Epoch 10 Loss 0.6891 Accuracy 0.7760\n",
      "Time taken for 1 epoch: 54.84 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.6031 Accuracy 0.8000\n",
      "Epoch 11 Batch 50 Loss 0.5803 Accuracy 0.8098\n",
      "Epoch 11 Batch 100 Loss 0.5784 Accuracy 0.8108\n",
      "Epoch 11 Batch 150 Loss 0.5721 Accuracy 0.8129\n",
      "Epoch 11 Batch 200 Loss 0.5647 Accuracy 0.8153\n",
      "Epoch 11 Batch 250 Loss 0.5598 Accuracy 0.8170\n",
      "Epoch 11 Batch 300 Loss 0.5557 Accuracy 0.8183\n",
      "Epoch 11 Loss 0.5526 Accuracy 0.8192\n",
      "Time taken for 1 epoch: 40.37 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.4877 Accuracy 0.8418\n",
      "Epoch 12 Batch 50 Loss 0.4804 Accuracy 0.8421\n",
      "Epoch 12 Batch 100 Loss 0.4768 Accuracy 0.8434\n",
      "Epoch 12 Batch 150 Loss 0.4754 Accuracy 0.8438\n",
      "Epoch 12 Batch 200 Loss 0.4740 Accuracy 0.8442\n",
      "Epoch 12 Batch 250 Loss 0.4730 Accuracy 0.8445\n",
      "Epoch 12 Batch 300 Loss 0.4711 Accuracy 0.8452\n",
      "Epoch 12 Loss 0.4701 Accuracy 0.8455\n",
      "Time taken for 1 epoch: 40.38 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.4320 Accuracy 0.8575\n",
      "Epoch 13 Batch 50 Loss 0.4278 Accuracy 0.8597\n",
      "Epoch 13 Batch 100 Loss 0.4258 Accuracy 0.8601\n",
      "Epoch 13 Batch 150 Loss 0.4251 Accuracy 0.8602\n",
      "Epoch 13 Batch 200 Loss 0.4234 Accuracy 0.8606\n",
      "Epoch 13 Batch 250 Loss 0.4212 Accuracy 0.8613\n",
      "Epoch 13 Batch 300 Loss 0.4207 Accuracy 0.8614\n",
      "Epoch 13 Loss 0.4199 Accuracy 0.8617\n",
      "Time taken for 1 epoch: 40.20 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.3972 Accuracy 0.8737\n",
      "Epoch 14 Batch 50 Loss 0.3896 Accuracy 0.8710\n",
      "Epoch 14 Batch 100 Loss 0.3848 Accuracy 0.8728\n",
      "Epoch 14 Batch 150 Loss 0.3848 Accuracy 0.8729\n",
      "Epoch 14 Batch 200 Loss 0.3836 Accuracy 0.8733\n",
      "Epoch 14 Batch 250 Loss 0.3827 Accuracy 0.8737\n",
      "Epoch 14 Batch 300 Loss 0.3815 Accuracy 0.8742\n",
      "Epoch 14 Loss 0.3809 Accuracy 0.8744\n",
      "Time taken for 1 epoch: 40.62 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.3442 Accuracy 0.8853\n",
      "Epoch 15 Batch 50 Loss 0.3553 Accuracy 0.8825\n",
      "Epoch 15 Batch 100 Loss 0.3558 Accuracy 0.8822\n",
      "Epoch 15 Batch 150 Loss 0.3559 Accuracy 0.8822\n",
      "Epoch 15 Batch 200 Loss 0.3571 Accuracy 0.8819\n",
      "Epoch 15 Batch 250 Loss 0.3564 Accuracy 0.8822\n",
      "Epoch 15 Batch 300 Loss 0.3560 Accuracy 0.8823\n",
      "Epoch 15 Batch 0 Validation Loss 0.3339 Validation Accuracy 0.8924\n",
      "Epoch 15 Batch 50 Validation Loss 0.3489 Validation Accuracy 0.8882\n",
      "Epoch 15 Batch 100 Validation Loss 0.3512 Validation Accuracy 0.8876\n",
      "Epoch 15 Loss 0.3559 Accuracy 0.8824\n",
      "Time taken for 1 epoch: 53.91 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3445<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_172205-jq37nmvy/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_172205-jq37nmvy/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.35586</td></tr><tr><td>train_accuracy</td><td>0.88242</td></tr><tr><td>_runtime</td><td>755</td></tr><tr><td>_timestamp</td><td>1622223280</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>0.3506</td></tr><tr><td>val_accuracy</td><td>0.88783</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▆▅▄▄▄▃▃▃▂▂▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▄▄▅▅▆▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">frosty-sweep-1</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/jq37nmvy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/jq37nmvy</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 899qddlr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">genial-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/899qddlr\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/899qddlr</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_173445-899qddlr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.8934 Accuracy 0.0013\n",
      "Epoch 1 Batch 50 Loss 3.8787 Accuracy 0.1401\n",
      "Epoch 1 Batch 100 Loss 3.4961 Accuracy 0.1743\n",
      "Epoch 1 Batch 150 Loss 3.3394 Accuracy 0.1870\n",
      "Epoch 1 Batch 200 Loss 3.2476 Accuracy 0.1951\n",
      "Epoch 1 Batch 250 Loss 3.1041 Accuracy 0.2134\n",
      "Epoch 1 Batch 300 Loss 2.9536 Accuracy 0.2338\n",
      "Epoch 1 Loss 2.8718 Accuracy 0.2451\n",
      "Time taken for 1 epoch: 92.25 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0714 Accuracy 0.3459\n",
      "Epoch 2 Batch 50 Loss 2.0440 Accuracy 0.3602\n",
      "Epoch 2 Batch 100 Loss 2.0221 Accuracy 0.3628\n",
      "Epoch 2 Batch 150 Loss 2.0045 Accuracy 0.3652\n",
      "Epoch 2 Batch 200 Loss 1.9910 Accuracy 0.3675\n",
      "Epoch 2 Batch 250 Loss 1.9791 Accuracy 0.3698\n",
      "Epoch 2 Batch 300 Loss 1.9655 Accuracy 0.3727\n",
      "Epoch 2 Loss 1.9565 Accuracy 0.3749\n",
      "Time taken for 1 epoch: 74.83 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8564 Accuracy 0.4009\n",
      "Epoch 3 Batch 50 Loss 1.8390 Accuracy 0.4019\n",
      "Epoch 3 Batch 100 Loss 1.8201 Accuracy 0.4069\n",
      "Epoch 3 Batch 150 Loss 1.7981 Accuracy 0.4124\n",
      "Epoch 3 Batch 200 Loss 1.7806 Accuracy 0.4171\n",
      "Epoch 3 Batch 250 Loss 1.7647 Accuracy 0.4212\n",
      "Epoch 3 Batch 300 Loss 1.7487 Accuracy 0.4258\n",
      "Epoch 3 Loss 1.7393 Accuracy 0.4285\n",
      "Time taken for 1 epoch: 74.50 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.6236 Accuracy 0.4649\n",
      "Epoch 4 Batch 50 Loss 1.6302 Accuracy 0.4621\n",
      "Epoch 4 Batch 100 Loss 1.6187 Accuracy 0.4655\n",
      "Epoch 4 Batch 150 Loss 1.6072 Accuracy 0.4694\n",
      "Epoch 4 Batch 200 Loss 1.5961 Accuracy 0.4730\n",
      "Epoch 4 Batch 250 Loss 1.5850 Accuracy 0.4766\n",
      "Epoch 4 Batch 300 Loss 1.5747 Accuracy 0.4799\n",
      "Epoch 4 Loss 1.5680 Accuracy 0.4821\n",
      "Time taken for 1 epoch: 75.40 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4879 Accuracy 0.5131\n",
      "Epoch 5 Batch 50 Loss 1.4913 Accuracy 0.5075\n",
      "Epoch 5 Batch 100 Loss 1.4809 Accuracy 0.5099\n",
      "Epoch 5 Batch 150 Loss 1.4737 Accuracy 0.5122\n",
      "Epoch 5 Batch 200 Loss 1.4672 Accuracy 0.5142\n",
      "Epoch 5 Batch 250 Loss 1.4604 Accuracy 0.5162\n",
      "Epoch 5 Batch 300 Loss 1.4535 Accuracy 0.5183\n",
      "Epoch 5 Batch 0 Validation Loss 1.3420 Validation Accuracy 0.5515\n",
      "Epoch 5 Batch 50 Validation Loss 1.3560 Validation Accuracy 0.5490\n",
      "Epoch 5 Batch 100 Validation Loss 1.3539 Validation Accuracy 0.5498\n",
      "Epoch 5 Loss 1.4495 Accuracy 0.5194\n",
      "Time taken for 1 epoch: 102.05 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.4100 Accuracy 0.5342\n",
      "Epoch 6 Batch 50 Loss 1.3925 Accuracy 0.5375\n",
      "Epoch 6 Batch 100 Loss 1.3870 Accuracy 0.5398\n",
      "Epoch 6 Batch 150 Loss 1.3810 Accuracy 0.5415\n",
      "Epoch 6 Batch 200 Loss 1.3749 Accuracy 0.5438\n",
      "Epoch 6 Batch 250 Loss 1.3701 Accuracy 0.5453\n",
      "Epoch 6 Batch 300 Loss 1.3647 Accuracy 0.5471\n",
      "Epoch 6 Loss 1.3615 Accuracy 0.5480\n",
      "Time taken for 1 epoch: 74.63 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.3306 Accuracy 0.5547\n",
      "Epoch 7 Batch 50 Loss 1.3113 Accuracy 0.5647\n",
      "Epoch 7 Batch 100 Loss 1.3047 Accuracy 0.5668\n",
      "Epoch 7 Batch 150 Loss 1.3018 Accuracy 0.5679\n",
      "Epoch 7 Batch 200 Loss 1.2963 Accuracy 0.5691\n",
      "Epoch 7 Batch 250 Loss 1.2917 Accuracy 0.5707\n",
      "Epoch 7 Batch 300 Loss 1.2866 Accuracy 0.5724\n",
      "Epoch 7 Loss 1.2841 Accuracy 0.5733\n",
      "Time taken for 1 epoch: 75.50 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.2541 Accuracy 0.5790\n",
      "Epoch 8 Batch 50 Loss 1.2394 Accuracy 0.5886\n",
      "Epoch 8 Batch 100 Loss 1.2353 Accuracy 0.5894\n",
      "Epoch 8 Batch 150 Loss 1.2305 Accuracy 0.5908\n",
      "Epoch 8 Batch 200 Loss 1.2291 Accuracy 0.5917\n",
      "Epoch 8 Batch 250 Loss 1.2256 Accuracy 0.5926\n",
      "Epoch 8 Batch 300 Loss 1.2221 Accuracy 0.5937\n",
      "Epoch 8 Loss 1.2200 Accuracy 0.5945\n",
      "Time taken for 1 epoch: 75.67 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.2119 Accuracy 0.5874\n",
      "Epoch 9 Batch 50 Loss 1.1850 Accuracy 0.6042\n",
      "Epoch 9 Batch 100 Loss 1.1808 Accuracy 0.6067\n",
      "Epoch 9 Batch 150 Loss 1.1778 Accuracy 0.6078\n",
      "Epoch 9 Batch 200 Loss 1.1751 Accuracy 0.6086\n",
      "Epoch 9 Batch 250 Loss 1.1732 Accuracy 0.6091\n",
      "Epoch 9 Batch 300 Loss 1.1707 Accuracy 0.6099\n",
      "Epoch 9 Loss 1.1694 Accuracy 0.6104\n",
      "Time taken for 1 epoch: 75.66 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.1281 Accuracy 0.6174\n",
      "Epoch 10 Batch 50 Loss 1.1381 Accuracy 0.6210\n",
      "Epoch 10 Batch 100 Loss 1.1354 Accuracy 0.6219\n",
      "Epoch 10 Batch 150 Loss 1.1353 Accuracy 0.6217\n",
      "Epoch 10 Batch 200 Loss 1.1338 Accuracy 0.6219\n",
      "Epoch 10 Batch 250 Loss 1.1324 Accuracy 0.6221\n",
      "Epoch 10 Batch 300 Loss 1.1297 Accuracy 0.6231\n",
      "Epoch 10 Batch 0 Validation Loss 1.1017 Validation Accuracy 0.6363\n",
      "Epoch 10 Batch 50 Validation Loss 1.0841 Validation Accuracy 0.6380\n",
      "Epoch 10 Batch 100 Validation Loss 1.0803 Validation Accuracy 0.6388\n",
      "Epoch 10 Loss 1.1285 Accuracy 0.6235\n",
      "Time taken for 1 epoch: 101.70 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.1223 Accuracy 0.6307\n",
      "Epoch 11 Batch 50 Loss 1.1008 Accuracy 0.6317\n",
      "Epoch 11 Batch 100 Loss 1.1004 Accuracy 0.6320\n",
      "Epoch 11 Batch 150 Loss 1.0977 Accuracy 0.6332\n",
      "Epoch 11 Batch 200 Loss 1.0975 Accuracy 0.6332\n",
      "Epoch 11 Batch 250 Loss 1.0974 Accuracy 0.6330\n",
      "Epoch 11 Batch 300 Loss 1.0958 Accuracy 0.6334\n",
      "Epoch 11 Loss 1.0948 Accuracy 0.6338\n",
      "Time taken for 1 epoch: 74.54 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.0696 Accuracy 0.6411\n",
      "Epoch 12 Batch 50 Loss 1.0702 Accuracy 0.6414\n",
      "Epoch 12 Batch 100 Loss 1.0718 Accuracy 0.6410\n",
      "Epoch 12 Batch 150 Loss 1.0700 Accuracy 0.6415\n",
      "Epoch 12 Batch 200 Loss 1.0708 Accuracy 0.6413\n",
      "Epoch 12 Batch 250 Loss 1.0694 Accuracy 0.6418\n",
      "Epoch 12 Batch 300 Loss 1.0686 Accuracy 0.6422\n",
      "Epoch 12 Loss 1.0685 Accuracy 0.6423\n",
      "Time taken for 1 epoch: 75.24 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.0356 Accuracy 0.6475\n",
      "Epoch 13 Batch 50 Loss 1.0440 Accuracy 0.6497\n",
      "Epoch 13 Batch 100 Loss 1.0425 Accuracy 0.6502\n",
      "Epoch 13 Batch 150 Loss 1.0428 Accuracy 0.6502\n",
      "Epoch 13 Batch 200 Loss 1.0421 Accuracy 0.6504\n",
      "Epoch 13 Batch 250 Loss 1.0420 Accuracy 0.6505\n",
      "Epoch 13 Batch 300 Loss 1.0420 Accuracy 0.6505\n",
      "Epoch 13 Loss 1.0408 Accuracy 0.6508\n",
      "Time taken for 1 epoch: 75.51 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.9954 Accuracy 0.6655\n",
      "Epoch 14 Batch 50 Loss 1.0071 Accuracy 0.6607\n",
      "Epoch 14 Batch 100 Loss 1.0089 Accuracy 0.6601\n",
      "Epoch 14 Batch 150 Loss 1.0098 Accuracy 0.6600\n",
      "Epoch 14 Batch 200 Loss 1.0100 Accuracy 0.6601\n",
      "Epoch 14 Batch 250 Loss 1.0085 Accuracy 0.6606\n",
      "Epoch 14 Batch 300 Loss 1.0076 Accuracy 0.6609\n",
      "Epoch 14 Loss 1.0061 Accuracy 0.6614\n",
      "Time taken for 1 epoch: 75.50 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.9582 Accuracy 0.6788\n",
      "Epoch 15 Batch 50 Loss 0.9791 Accuracy 0.6700\n",
      "Epoch 15 Batch 100 Loss 0.9801 Accuracy 0.6697\n",
      "Epoch 15 Batch 150 Loss 0.9802 Accuracy 0.6696\n",
      "Epoch 15 Batch 200 Loss 0.9787 Accuracy 0.6701\n",
      "Epoch 15 Batch 250 Loss 0.9784 Accuracy 0.6701\n",
      "Epoch 15 Batch 300 Loss 0.9773 Accuracy 0.6704\n",
      "Epoch 15 Batch 0 Validation Loss 0.9392 Validation Accuracy 0.6812\n",
      "Epoch 15 Batch 50 Validation Loss 0.9487 Validation Accuracy 0.6807\n",
      "Epoch 15 Batch 100 Validation Loss 0.9494 Validation Accuracy 0.6800\n",
      "Epoch 15 Loss 0.9763 Accuracy 0.6708\n",
      "Time taken for 1 epoch: 102.02 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3964<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_173445-899qddlr/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_173445-899qddlr/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.97635</td></tr><tr><td>train_accuracy</td><td>0.67084</td></tr><tr><td>_runtime</td><td>1415</td></tr><tr><td>_timestamp</td><td>1622224700</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>0.94839</td></tr><tr><td>val_accuracy</td><td>0.68047</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▆▆▆▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">genial-sweep-2</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/899qddlr\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/899qddlr</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9y61190t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">spring-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/9y61190t\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/9y61190t</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_175824-9y61190t</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.8240 Accuracy 0.0064\n",
      "Epoch 1 Batch 50 Loss 3.7973 Accuracy 0.1406\n",
      "Epoch 1 Batch 100 Loss 3.4437 Accuracy 0.1742\n",
      "Epoch 1 Batch 150 Loss 3.3002 Accuracy 0.1871\n",
      "Epoch 1 Batch 200 Loss 3.2222 Accuracy 0.1945\n",
      "Epoch 1 Batch 250 Loss 3.1727 Accuracy 0.1995\n",
      "Epoch 1 Batch 300 Loss 3.1380 Accuracy 0.2031\n",
      "Epoch 1 Loss 3.1210 Accuracy 0.2049\n",
      "Time taken for 1 epoch: 135.85 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.9557 Accuracy 0.2231\n",
      "Epoch 2 Batch 50 Loss 2.8036 Accuracy 0.2406\n",
      "Epoch 2 Batch 100 Loss 2.5574 Accuracy 0.2769\n",
      "Epoch 2 Batch 150 Loss 2.4301 Accuracy 0.2954\n",
      "Epoch 2 Batch 200 Loss 2.3472 Accuracy 0.3083\n",
      "Epoch 2 Batch 250 Loss 2.2886 Accuracy 0.3178\n",
      "Epoch 2 Batch 300 Loss 2.2430 Accuracy 0.3254\n",
      "Epoch 2 Loss 2.2184 Accuracy 0.3293\n",
      "Time taken for 1 epoch: 108.89 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.0268 Accuracy 0.3621\n",
      "Epoch 3 Batch 50 Loss 1.9632 Accuracy 0.3711\n",
      "Epoch 3 Batch 100 Loss 1.9471 Accuracy 0.3749\n",
      "Epoch 3 Batch 150 Loss 1.9303 Accuracy 0.3785\n",
      "Epoch 3 Batch 200 Loss 1.9204 Accuracy 0.3806\n",
      "Epoch 3 Batch 250 Loss 1.9035 Accuracy 0.3847\n",
      "Epoch 3 Batch 300 Loss 1.8872 Accuracy 0.3888\n",
      "Epoch 3 Loss 1.8780 Accuracy 0.3909\n",
      "Time taken for 1 epoch: 110.17 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.7845 Accuracy 0.3992\n",
      "Epoch 4 Batch 50 Loss 1.7755 Accuracy 0.4167\n",
      "Epoch 4 Batch 100 Loss 1.7616 Accuracy 0.4208\n",
      "Epoch 4 Batch 150 Loss 1.7492 Accuracy 0.4238\n",
      "Epoch 4 Batch 200 Loss 1.7355 Accuracy 0.4281\n",
      "Epoch 4 Batch 250 Loss 1.7239 Accuracy 0.4317\n",
      "Epoch 4 Batch 300 Loss 1.7121 Accuracy 0.4355\n",
      "Epoch 4 Loss 1.7047 Accuracy 0.4377\n",
      "Time taken for 1 epoch: 110.39 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.6304 Accuracy 0.4646\n",
      "Epoch 5 Batch 50 Loss 1.6191 Accuracy 0.4652\n",
      "Epoch 5 Batch 100 Loss 1.6095 Accuracy 0.4676\n",
      "Epoch 5 Batch 150 Loss 1.6021 Accuracy 0.4698\n",
      "Epoch 5 Batch 200 Loss 1.5930 Accuracy 0.4723\n",
      "Epoch 5 Batch 250 Loss 1.5837 Accuracy 0.4751\n",
      "Epoch 5 Batch 300 Loss 1.5765 Accuracy 0.4776\n",
      "Epoch 5 Batch 0 Validation Loss 1.4691 Validation Accuracy 0.5136\n",
      "Epoch 5 Batch 50 Validation Loss 1.4818 Validation Accuracy 0.5066\n",
      "Epoch 5 Batch 100 Validation Loss 1.4834 Validation Accuracy 0.5061\n",
      "Epoch 5 Loss 1.5721 Accuracy 0.4787\n",
      "Time taken for 1 epoch: 151.27 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.5036 Accuracy 0.4994\n",
      "Epoch 6 Batch 50 Loss 1.5107 Accuracy 0.4979\n",
      "Epoch 6 Batch 100 Loss 1.5081 Accuracy 0.4986\n",
      "Epoch 6 Batch 150 Loss 1.5014 Accuracy 0.5012\n",
      "Epoch 6 Batch 200 Loss 1.4965 Accuracy 0.5026\n",
      "Epoch 6 Batch 250 Loss 1.4913 Accuracy 0.5042\n",
      "Epoch 6 Batch 300 Loss 1.4859 Accuracy 0.5060\n",
      "Epoch 6 Loss 1.4827 Accuracy 0.5072\n",
      "Time taken for 1 epoch: 109.14 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.4651 Accuracy 0.5211\n",
      "Epoch 7 Batch 50 Loss 1.4428 Accuracy 0.5212\n",
      "Epoch 7 Batch 100 Loss 1.4373 Accuracy 0.5228\n",
      "Epoch 7 Batch 150 Loss 1.4311 Accuracy 0.5247\n",
      "Epoch 7 Batch 200 Loss 1.4277 Accuracy 0.5257\n",
      "Epoch 7 Batch 250 Loss 1.4224 Accuracy 0.5273\n",
      "Epoch 7 Batch 300 Loss 1.4177 Accuracy 0.5289\n",
      "Epoch 7 Loss 1.4142 Accuracy 0.5301\n",
      "Time taken for 1 epoch: 110.29 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.3822 Accuracy 0.5410\n",
      "Epoch 8 Batch 50 Loss 1.3740 Accuracy 0.5426\n",
      "Epoch 8 Batch 100 Loss 1.3693 Accuracy 0.5443\n",
      "Epoch 8 Batch 150 Loss 1.3661 Accuracy 0.5452\n",
      "Epoch 8 Batch 200 Loss 1.3619 Accuracy 0.5463\n",
      "Epoch 8 Batch 250 Loss 1.3578 Accuracy 0.5479\n",
      "Epoch 8 Batch 300 Loss 1.3538 Accuracy 0.5492\n",
      "Epoch 8 Loss 1.3512 Accuracy 0.5500\n",
      "Time taken for 1 epoch: 110.38 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.2952 Accuracy 0.5707\n",
      "Epoch 9 Batch 50 Loss 1.3143 Accuracy 0.5612\n",
      "Epoch 9 Batch 100 Loss 1.3120 Accuracy 0.5624\n",
      "Epoch 9 Batch 150 Loss 1.3077 Accuracy 0.5639\n",
      "Epoch 9 Batch 200 Loss 1.3033 Accuracy 0.5655\n",
      "Epoch 9 Batch 250 Loss 1.3003 Accuracy 0.5666\n",
      "Epoch 9 Batch 300 Loss 1.2971 Accuracy 0.5677\n",
      "Epoch 9 Loss 1.2949 Accuracy 0.5686\n",
      "Time taken for 1 epoch: 110.56 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.2936 Accuracy 0.5722\n",
      "Epoch 10 Batch 50 Loss 1.2645 Accuracy 0.5785\n",
      "Epoch 10 Batch 100 Loss 1.2608 Accuracy 0.5801\n",
      "Epoch 10 Batch 150 Loss 1.2563 Accuracy 0.5816\n",
      "Epoch 10 Batch 200 Loss 1.2539 Accuracy 0.5824\n",
      "Epoch 10 Batch 250 Loss 1.2500 Accuracy 0.5839\n",
      "Epoch 10 Batch 300 Loss 1.2488 Accuracy 0.5843\n",
      "Epoch 10 Batch 0 Validation Loss 1.1961 Validation Accuracy 0.5978\n",
      "Epoch 10 Batch 50 Validation Loss 1.1845 Validation Accuracy 0.6037\n",
      "Epoch 10 Batch 100 Validation Loss 1.1858 Validation Accuracy 0.6030\n",
      "Epoch 10 Loss 1.2474 Accuracy 0.5847\n",
      "Time taken for 1 epoch: 151.32 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.2232 Accuracy 0.5942\n",
      "Epoch 11 Batch 50 Loss 1.2232 Accuracy 0.5928\n",
      "Epoch 11 Batch 100 Loss 1.2191 Accuracy 0.5943\n",
      "Epoch 11 Batch 150 Loss 1.2166 Accuracy 0.5948\n",
      "Epoch 11 Batch 200 Loss 1.2146 Accuracy 0.5951\n",
      "Epoch 11 Batch 250 Loss 1.2118 Accuracy 0.5960\n",
      "Epoch 11 Batch 300 Loss 1.2103 Accuracy 0.5967\n",
      "Epoch 11 Loss 1.2083 Accuracy 0.5973\n",
      "Time taken for 1 epoch: 108.88 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.1783 Accuracy 0.6078\n",
      "Epoch 12 Batch 50 Loss 1.1829 Accuracy 0.6057\n",
      "Epoch 12 Batch 100 Loss 1.1825 Accuracy 0.6054\n",
      "Epoch 12 Batch 150 Loss 1.1807 Accuracy 0.6061\n",
      "Epoch 12 Batch 200 Loss 1.1780 Accuracy 0.6071\n",
      "Epoch 12 Batch 250 Loss 1.1766 Accuracy 0.6076\n",
      "Epoch 12 Batch 300 Loss 1.1749 Accuracy 0.6083\n",
      "Epoch 12 Loss 1.1744 Accuracy 0.6084\n",
      "Time taken for 1 epoch: 110.29 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.1517 Accuracy 0.6076\n",
      "Epoch 13 Batch 50 Loss 1.1463 Accuracy 0.6168\n",
      "Epoch 13 Batch 100 Loss 1.1485 Accuracy 0.6162\n",
      "Epoch 13 Batch 150 Loss 1.1461 Accuracy 0.6171\n",
      "Epoch 13 Batch 200 Loss 1.1452 Accuracy 0.6176\n",
      "Epoch 13 Batch 250 Loss 1.1438 Accuracy 0.6180\n",
      "Epoch 13 Batch 300 Loss 1.1416 Accuracy 0.6187\n",
      "Epoch 13 Loss 1.1404 Accuracy 0.6190\n",
      "Time taken for 1 epoch: 110.54 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.1514 Accuracy 0.6208\n",
      "Epoch 14 Batch 50 Loss 1.1169 Accuracy 0.6263\n",
      "Epoch 14 Batch 100 Loss 1.1150 Accuracy 0.6268\n",
      "Epoch 14 Batch 150 Loss 1.1120 Accuracy 0.6278\n",
      "Epoch 14 Batch 200 Loss 1.1096 Accuracy 0.6285\n",
      "Epoch 14 Batch 250 Loss 1.1085 Accuracy 0.6291\n",
      "Epoch 14 Batch 300 Loss 1.1075 Accuracy 0.6295\n",
      "Epoch 14 Loss 1.1067 Accuracy 0.6298\n",
      "Time taken for 1 epoch: 110.09 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.1012 Accuracy 0.6295\n",
      "Epoch 15 Batch 50 Loss 1.0725 Accuracy 0.6407\n",
      "Epoch 15 Batch 100 Loss 1.0754 Accuracy 0.6398\n",
      "Epoch 15 Batch 150 Loss 1.0772 Accuracy 0.6392\n",
      "Epoch 15 Batch 200 Loss 1.0771 Accuracy 0.6391\n",
      "Epoch 15 Batch 250 Loss 1.0766 Accuracy 0.6391\n",
      "Epoch 15 Batch 300 Loss 1.0760 Accuracy 0.6392\n",
      "Epoch 15 Batch 0 Validation Loss 1.0418 Validation Accuracy 0.6455\n",
      "Epoch 15 Batch 50 Validation Loss 1.0356 Validation Accuracy 0.6535\n",
      "Epoch 15 Batch 100 Validation Loss 1.0350 Validation Accuracy 0.6527\n",
      "Epoch 15 Loss 1.0757 Accuracy 0.6394\n",
      "Time taken for 1 epoch: 152.65 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5005<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_175824-9y61190t/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_175824-9y61190t/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>1.07572</td></tr><tr><td>train_accuracy</td><td>0.63942</td></tr><tr><td>_runtime</td><td>2097</td></tr><tr><td>_timestamp</td><td>1622226801</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>1.03455</td></tr><tr><td>val_accuracy</td><td>0.65284</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">spring-sweep-3</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/9y61190t\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/9y61190t</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: scogrrrc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wobbly-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/scogrrrc\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/scogrrrc</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_183325-scogrrrc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.8236 Accuracy 0.1393\n",
      "Epoch 1 Batch 50 Loss 4.0263 Accuracy 0.1935\n",
      "Epoch 1 Batch 100 Loss 3.5693 Accuracy 0.2019\n",
      "Epoch 1 Batch 150 Loss 3.3445 Accuracy 0.2113\n",
      "Epoch 1 Batch 200 Loss 3.1240 Accuracy 0.2345\n",
      "Epoch 1 Batch 250 Loss 2.9371 Accuracy 0.2564\n",
      "Epoch 1 Batch 300 Loss 2.7948 Accuracy 0.2733\n",
      "Epoch 1 Loss 2.7214 Accuracy 0.2818\n",
      "Time taken for 1 epoch: 56.05 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0664 Accuracy 0.3558\n",
      "Epoch 2 Batch 50 Loss 1.9984 Accuracy 0.3668\n",
      "Epoch 2 Batch 100 Loss 1.9834 Accuracy 0.3691\n",
      "Epoch 2 Batch 150 Loss 1.9719 Accuracy 0.3712\n",
      "Epoch 2 Batch 200 Loss 1.9624 Accuracy 0.3732\n",
      "Epoch 2 Batch 250 Loss 1.9519 Accuracy 0.3755\n",
      "Epoch 2 Batch 300 Loss 1.9416 Accuracy 0.3779\n",
      "Epoch 2 Loss 1.9347 Accuracy 0.3797\n",
      "Time taken for 1 epoch: 46.42 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8444 Accuracy 0.3991\n",
      "Epoch 3 Batch 50 Loss 1.8391 Accuracy 0.4017\n",
      "Epoch 3 Batch 100 Loss 1.8210 Accuracy 0.4083\n",
      "Epoch 3 Batch 150 Loss 1.8035 Accuracy 0.4127\n",
      "Epoch 3 Batch 200 Loss 1.7856 Accuracy 0.4172\n",
      "Epoch 3 Batch 250 Loss 1.7693 Accuracy 0.4214\n",
      "Epoch 3 Batch 300 Loss 1.7536 Accuracy 0.4258\n",
      "Epoch 3 Loss 1.7435 Accuracy 0.4286\n",
      "Time taken for 1 epoch: 46.65 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.6254 Accuracy 0.4683\n",
      "Epoch 4 Batch 50 Loss 1.6291 Accuracy 0.4633\n",
      "Epoch 4 Batch 100 Loss 1.6156 Accuracy 0.4668\n",
      "Epoch 4 Batch 150 Loss 1.6049 Accuracy 0.4701\n",
      "Epoch 4 Batch 200 Loss 1.5922 Accuracy 0.4740\n",
      "Epoch 4 Batch 250 Loss 1.5806 Accuracy 0.4778\n",
      "Epoch 4 Batch 300 Loss 1.5691 Accuracy 0.4812\n",
      "Epoch 4 Loss 1.5621 Accuracy 0.4835\n",
      "Time taken for 1 epoch: 46.65 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4798 Accuracy 0.5037\n",
      "Epoch 5 Batch 50 Loss 1.4760 Accuracy 0.5091\n",
      "Epoch 5 Batch 100 Loss 1.4650 Accuracy 0.5128\n",
      "Epoch 5 Batch 150 Loss 1.4570 Accuracy 0.5155\n",
      "Epoch 5 Batch 200 Loss 1.4497 Accuracy 0.5181\n",
      "Epoch 5 Batch 250 Loss 1.4417 Accuracy 0.5206\n",
      "Epoch 5 Batch 300 Loss 1.4336 Accuracy 0.5233\n",
      "Epoch 5 Batch 0 Validation Loss 1.3571 Validation Accuracy 0.5437\n",
      "Epoch 5 Batch 50 Validation Loss 1.3341 Validation Accuracy 0.5547\n",
      "Epoch 5 Batch 100 Validation Loss 1.3357 Validation Accuracy 0.5546\n",
      "Epoch 5 Loss 1.4295 Accuracy 0.5246\n",
      "Time taken for 1 epoch: 63.05 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.3833 Accuracy 0.5346\n",
      "Epoch 6 Batch 50 Loss 1.3654 Accuracy 0.5446\n",
      "Epoch 6 Batch 100 Loss 1.3587 Accuracy 0.5467\n",
      "Epoch 6 Batch 150 Loss 1.3531 Accuracy 0.5490\n",
      "Epoch 6 Batch 200 Loss 1.3479 Accuracy 0.5508\n",
      "Epoch 6 Batch 250 Loss 1.3425 Accuracy 0.5525\n",
      "Epoch 6 Batch 300 Loss 1.3365 Accuracy 0.5548\n",
      "Epoch 6 Loss 1.3333 Accuracy 0.5559\n",
      "Time taken for 1 epoch: 46.84 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.2627 Accuracy 0.5811\n",
      "Epoch 7 Batch 50 Loss 1.2781 Accuracy 0.5741\n",
      "Epoch 7 Batch 100 Loss 1.2765 Accuracy 0.5753\n",
      "Epoch 7 Batch 150 Loss 1.2716 Accuracy 0.5768\n",
      "Epoch 7 Batch 200 Loss 1.2665 Accuracy 0.5786\n",
      "Epoch 7 Batch 250 Loss 1.2619 Accuracy 0.5801\n",
      "Epoch 7 Batch 300 Loss 1.2580 Accuracy 0.5813\n",
      "Epoch 7 Loss 1.2552 Accuracy 0.5823\n",
      "Time taken for 1 epoch: 46.97 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.2393 Accuracy 0.5906\n",
      "Epoch 8 Batch 50 Loss 1.2059 Accuracy 0.5982\n",
      "Epoch 8 Batch 100 Loss 1.2030 Accuracy 0.5983\n",
      "Epoch 8 Batch 150 Loss 1.2009 Accuracy 0.5997\n",
      "Epoch 8 Batch 200 Loss 1.1986 Accuracy 0.6003\n",
      "Epoch 8 Batch 250 Loss 1.1961 Accuracy 0.6012\n",
      "Epoch 8 Batch 300 Loss 1.1931 Accuracy 0.6021\n",
      "Epoch 8 Loss 1.1915 Accuracy 0.6027\n",
      "Time taken for 1 epoch: 47.01 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1334 Accuracy 0.6232\n",
      "Epoch 9 Batch 50 Loss 1.1546 Accuracy 0.6146\n",
      "Epoch 9 Batch 100 Loss 1.1517 Accuracy 0.6157\n",
      "Epoch 9 Batch 150 Loss 1.1505 Accuracy 0.6159\n",
      "Epoch 9 Batch 200 Loss 1.1483 Accuracy 0.6167\n",
      "Epoch 9 Batch 250 Loss 1.1453 Accuracy 0.6176\n",
      "Epoch 9 Batch 300 Loss 1.1430 Accuracy 0.6185\n",
      "Epoch 9 Loss 1.1415 Accuracy 0.6189\n",
      "Time taken for 1 epoch: 46.97 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.1321 Accuracy 0.6202\n",
      "Epoch 10 Batch 50 Loss 1.1054 Accuracy 0.6300\n",
      "Epoch 10 Batch 100 Loss 1.1048 Accuracy 0.6302\n",
      "Epoch 10 Batch 150 Loss 1.1029 Accuracy 0.6307\n",
      "Epoch 10 Batch 200 Loss 1.1015 Accuracy 0.6311\n",
      "Epoch 10 Batch 250 Loss 1.1005 Accuracy 0.6316\n",
      "Epoch 10 Batch 300 Loss 1.0990 Accuracy 0.6322\n",
      "Epoch 10 Batch 0 Validation Loss 1.0544 Validation Accuracy 0.6419\n",
      "Epoch 10 Batch 50 Validation Loss 1.0641 Validation Accuracy 0.6459\n",
      "Epoch 10 Batch 100 Validation Loss 1.0629 Validation Accuracy 0.6462\n",
      "Epoch 10 Loss 1.0981 Accuracy 0.6326\n",
      "Time taken for 1 epoch: 63.14 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.0504 Accuracy 0.6490\n",
      "Epoch 11 Batch 50 Loss 1.0648 Accuracy 0.6432\n",
      "Epoch 11 Batch 100 Loss 1.0652 Accuracy 0.6434\n",
      "Epoch 11 Batch 150 Loss 1.0603 Accuracy 0.6449\n",
      "Epoch 11 Batch 200 Loss 1.0558 Accuracy 0.6467\n",
      "Epoch 11 Batch 250 Loss 1.0506 Accuracy 0.6484\n",
      "Epoch 11 Batch 300 Loss 1.0469 Accuracy 0.6497\n",
      "Epoch 11 Loss 1.0443 Accuracy 0.6506\n",
      "Time taken for 1 epoch: 46.78 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.9847 Accuracy 0.6734\n",
      "Epoch 12 Batch 50 Loss 0.9939 Accuracy 0.6671\n",
      "Epoch 12 Batch 100 Loss 0.9952 Accuracy 0.6662\n",
      "Epoch 12 Batch 150 Loss 0.9937 Accuracy 0.6665\n",
      "Epoch 12 Batch 200 Loss 0.9934 Accuracy 0.6669\n",
      "Epoch 12 Batch 250 Loss 0.9933 Accuracy 0.6671\n",
      "Epoch 12 Batch 300 Loss 0.9923 Accuracy 0.6673\n",
      "Epoch 12 Loss 0.9916 Accuracy 0.6676\n",
      "Time taken for 1 epoch: 47.00 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.9532 Accuracy 0.6809\n",
      "Epoch 13 Batch 50 Loss 0.9515 Accuracy 0.6798\n",
      "Epoch 13 Batch 100 Loss 0.9474 Accuracy 0.6816\n",
      "Epoch 13 Batch 150 Loss 0.9431 Accuracy 0.6831\n",
      "Epoch 13 Batch 200 Loss 0.9380 Accuracy 0.6850\n",
      "Epoch 13 Batch 250 Loss 0.9338 Accuracy 0.6865\n",
      "Epoch 13 Batch 300 Loss 0.9294 Accuracy 0.6879\n",
      "Epoch 13 Loss 0.9271 Accuracy 0.6887\n",
      "Time taken for 1 epoch: 47.13 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.8634 Accuracy 0.7096\n",
      "Epoch 14 Batch 50 Loss 0.8632 Accuracy 0.7092\n",
      "Epoch 14 Batch 100 Loss 0.8622 Accuracy 0.7091\n",
      "Epoch 14 Batch 150 Loss 0.8615 Accuracy 0.7094\n",
      "Epoch 14 Batch 200 Loss 0.8606 Accuracy 0.7098\n",
      "Epoch 14 Batch 250 Loss 0.8589 Accuracy 0.7103\n",
      "Epoch 14 Batch 300 Loss 0.8576 Accuracy 0.7108\n",
      "Epoch 14 Loss 0.8564 Accuracy 0.7112\n",
      "Time taken for 1 epoch: 47.22 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.8129 Accuracy 0.7228\n",
      "Epoch 15 Batch 50 Loss 0.8045 Accuracy 0.7264\n",
      "Epoch 15 Batch 100 Loss 0.8053 Accuracy 0.7265\n",
      "Epoch 15 Batch 150 Loss 0.8043 Accuracy 0.7272\n",
      "Epoch 15 Batch 200 Loss 0.8033 Accuracy 0.7277\n",
      "Epoch 15 Batch 250 Loss 0.8027 Accuracy 0.7280\n",
      "Epoch 15 Batch 300 Loss 0.8015 Accuracy 0.7285\n",
      "Epoch 15 Batch 0 Validation Loss 0.7878 Validation Accuracy 0.7404\n",
      "Epoch 15 Batch 50 Validation Loss 0.7932 Validation Accuracy 0.7349\n",
      "Epoch 15 Batch 100 Validation Loss 0.7906 Validation Accuracy 0.7359\n",
      "Epoch 15 Loss 0.8009 Accuracy 0.7286\n",
      "Time taken for 1 epoch: 63.42 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6634<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.34021505376…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_183325-scogrrrc/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_183325-scogrrrc/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.80093</td></tr><tr><td>train_accuracy</td><td>0.72864</td></tr><tr><td>_runtime</td><td>877</td></tr><tr><td>_timestamp</td><td>1622227682</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>0.79055</td></tr><tr><td>val_accuracy</td><td>0.73598</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▃▄▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▄▁</td></tr><tr><td>val_accuracy</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wobbly-sweep-4</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/scogrrrc\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/scogrrrc</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 868jjwul with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fresh-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/868jjwul\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/868jjwul</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_184805-868jjwul</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.2955 Accuracy 0.0010\n",
      "Epoch 1 Batch 50 Loss 4.1029 Accuracy 0.1260\n",
      "Epoch 1 Batch 100 Loss 3.6100 Accuracy 0.1653\n",
      "Epoch 1 Batch 150 Loss 3.4132 Accuracy 0.1806\n",
      "Epoch 1 Batch 200 Loss 3.3070 Accuracy 0.1898\n",
      "Epoch 1 Batch 250 Loss 3.2057 Accuracy 0.2008\n",
      "Epoch 1 Batch 300 Loss 3.0523 Accuracy 0.2217\n",
      "Epoch 1 Loss 2.9633 Accuracy 0.2340\n",
      "Time taken for 1 epoch: 107.47 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0793 Accuracy 0.3529\n",
      "Epoch 2 Batch 50 Loss 2.0530 Accuracy 0.3576\n",
      "Epoch 2 Batch 100 Loss 2.0283 Accuracy 0.3608\n",
      "Epoch 2 Batch 150 Loss 2.0078 Accuracy 0.3642\n",
      "Epoch 2 Batch 200 Loss 1.9910 Accuracy 0.3671\n",
      "Epoch 2 Batch 250 Loss 1.9769 Accuracy 0.3698\n",
      "Epoch 2 Batch 300 Loss 1.9637 Accuracy 0.3726\n",
      "Epoch 2 Loss 1.9553 Accuracy 0.3746\n",
      "Time taken for 1 epoch: 86.81 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8475 Accuracy 0.3975\n",
      "Epoch 3 Batch 50 Loss 1.8550 Accuracy 0.3983\n",
      "Epoch 3 Batch 100 Loss 1.8371 Accuracy 0.4035\n",
      "Epoch 3 Batch 150 Loss 1.8194 Accuracy 0.4083\n",
      "Epoch 3 Batch 200 Loss 1.8022 Accuracy 0.4122\n",
      "Epoch 3 Batch 250 Loss 1.7865 Accuracy 0.4161\n",
      "Epoch 3 Batch 300 Loss 1.7718 Accuracy 0.4195\n",
      "Epoch 3 Loss 1.7630 Accuracy 0.4220\n",
      "Time taken for 1 epoch: 87.01 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.6546 Accuracy 0.4507\n",
      "Epoch 4 Batch 50 Loss 1.6502 Accuracy 0.4534\n",
      "Epoch 4 Batch 100 Loss 1.6405 Accuracy 0.4574\n",
      "Epoch 4 Batch 150 Loss 1.6318 Accuracy 0.4608\n",
      "Epoch 4 Batch 200 Loss 1.6217 Accuracy 0.4643\n",
      "Epoch 4 Batch 250 Loss 1.6121 Accuracy 0.4676\n",
      "Epoch 4 Batch 300 Loss 1.6031 Accuracy 0.4707\n",
      "Epoch 4 Loss 1.5978 Accuracy 0.4724\n",
      "Time taken for 1 epoch: 87.68 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.5480 Accuracy 0.4894\n",
      "Epoch 5 Batch 50 Loss 1.5208 Accuracy 0.4970\n",
      "Epoch 5 Batch 100 Loss 1.5117 Accuracy 0.4996\n",
      "Epoch 5 Batch 150 Loss 1.5035 Accuracy 0.5023\n",
      "Epoch 5 Batch 200 Loss 1.4950 Accuracy 0.5050\n",
      "Epoch 5 Batch 250 Loss 1.4877 Accuracy 0.5075\n",
      "Epoch 5 Batch 300 Loss 1.4802 Accuracy 0.5100\n",
      "Epoch 5 Batch 0 Validation Loss 1.3975 Validation Accuracy 0.5413\n",
      "Epoch 5 Batch 50 Validation Loss 1.3798 Validation Accuracy 0.5408\n",
      "Epoch 5 Batch 100 Validation Loss 1.3808 Validation Accuracy 0.5400\n",
      "Epoch 5 Loss 1.4755 Accuracy 0.5113\n",
      "Time taken for 1 epoch: 117.09 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.4294 Accuracy 0.5216\n",
      "Epoch 6 Batch 50 Loss 1.4088 Accuracy 0.5323\n",
      "Epoch 6 Batch 100 Loss 1.4054 Accuracy 0.5327\n",
      "Epoch 6 Batch 150 Loss 1.4013 Accuracy 0.5340\n",
      "Epoch 6 Batch 200 Loss 1.3960 Accuracy 0.5357\n",
      "Epoch 6 Batch 250 Loss 1.3905 Accuracy 0.5374\n",
      "Epoch 6 Batch 300 Loss 1.3857 Accuracy 0.5391\n",
      "Epoch 6 Loss 1.3817 Accuracy 0.5403\n",
      "Time taken for 1 epoch: 86.91 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.3238 Accuracy 0.5570\n",
      "Epoch 7 Batch 50 Loss 1.3336 Accuracy 0.5565\n",
      "Epoch 7 Batch 100 Loss 1.3293 Accuracy 0.5576\n",
      "Epoch 7 Batch 150 Loss 1.3232 Accuracy 0.5596\n",
      "Epoch 7 Batch 200 Loss 1.3175 Accuracy 0.5617\n",
      "Epoch 7 Batch 250 Loss 1.3124 Accuracy 0.5636\n",
      "Epoch 7 Batch 300 Loss 1.3071 Accuracy 0.5653\n",
      "Epoch 7 Loss 1.3036 Accuracy 0.5663\n",
      "Time taken for 1 epoch: 87.59 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.2730 Accuracy 0.5745\n",
      "Epoch 8 Batch 50 Loss 1.2598 Accuracy 0.5803\n",
      "Epoch 8 Batch 100 Loss 1.2560 Accuracy 0.5824\n",
      "Epoch 8 Batch 150 Loss 1.2521 Accuracy 0.5838\n",
      "Epoch 8 Batch 200 Loss 1.2479 Accuracy 0.5853\n",
      "Epoch 8 Batch 250 Loss 1.2437 Accuracy 0.5865\n",
      "Epoch 8 Batch 300 Loss 1.2396 Accuracy 0.5879\n",
      "Epoch 8 Loss 1.2377 Accuracy 0.5885\n",
      "Time taken for 1 epoch: 87.52 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.2174 Accuracy 0.5913\n",
      "Epoch 9 Batch 50 Loss 1.2032 Accuracy 0.6003\n",
      "Epoch 9 Batch 100 Loss 1.1968 Accuracy 0.6020\n",
      "Epoch 9 Batch 150 Loss 1.1931 Accuracy 0.6031\n",
      "Epoch 9 Batch 200 Loss 1.1911 Accuracy 0.6038\n",
      "Epoch 9 Batch 250 Loss 1.1884 Accuracy 0.6047\n",
      "Epoch 9 Batch 300 Loss 1.1861 Accuracy 0.6052\n",
      "Epoch 9 Loss 1.1845 Accuracy 0.6058\n",
      "Time taken for 1 epoch: 87.56 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.1425 Accuracy 0.6162\n",
      "Epoch 10 Batch 50 Loss 1.1468 Accuracy 0.6176\n",
      "Epoch 10 Batch 100 Loss 1.1511 Accuracy 0.6165\n",
      "Epoch 10 Batch 150 Loss 1.1485 Accuracy 0.6172\n",
      "Epoch 10 Batch 200 Loss 1.1468 Accuracy 0.6176\n",
      "Epoch 10 Batch 250 Loss 1.1450 Accuracy 0.6181\n",
      "Epoch 10 Batch 300 Loss 1.1427 Accuracy 0.6188\n",
      "Epoch 10 Batch 0 Validation Loss 1.1348 Validation Accuracy 0.6211\n",
      "Epoch 10 Batch 50 Validation Loss 1.0950 Validation Accuracy 0.6342\n",
      "Epoch 10 Batch 100 Validation Loss 1.0946 Validation Accuracy 0.6342\n",
      "Epoch 10 Loss 1.1423 Accuracy 0.6189\n",
      "Time taken for 1 epoch: 118.01 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.0912 Accuracy 0.6339\n",
      "Epoch 11 Batch 50 Loss 1.1120 Accuracy 0.6283\n",
      "Epoch 11 Batch 100 Loss 1.1131 Accuracy 0.6280\n",
      "Epoch 11 Batch 150 Loss 1.1119 Accuracy 0.6284\n",
      "Epoch 11 Batch 200 Loss 1.1108 Accuracy 0.6287\n",
      "Epoch 11 Batch 250 Loss 1.1105 Accuracy 0.6291\n",
      "Epoch 11 Batch 300 Loss 1.1094 Accuracy 0.6294\n",
      "Epoch 11 Loss 1.1084 Accuracy 0.6299\n",
      "Time taken for 1 epoch: 87.09 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.0798 Accuracy 0.6392\n",
      "Epoch 12 Batch 50 Loss 1.0859 Accuracy 0.6374\n",
      "Epoch 12 Batch 100 Loss 1.0865 Accuracy 0.6370\n",
      "Epoch 12 Batch 150 Loss 1.0845 Accuracy 0.6374\n",
      "Epoch 12 Batch 200 Loss 1.0849 Accuracy 0.6373\n",
      "Epoch 12 Batch 250 Loss 1.0836 Accuracy 0.6376\n",
      "Epoch 12 Batch 300 Loss 1.0817 Accuracy 0.6382\n",
      "Epoch 12 Loss 1.0808 Accuracy 0.6385\n",
      "Time taken for 1 epoch: 87.02 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.0152 Accuracy 0.6654\n",
      "Epoch 13 Batch 50 Loss 1.0559 Accuracy 0.6468\n",
      "Epoch 13 Batch 100 Loss 1.0564 Accuracy 0.6462\n",
      "Epoch 13 Batch 150 Loss 1.0550 Accuracy 0.6466\n",
      "Epoch 13 Batch 200 Loss 1.0545 Accuracy 0.6468\n",
      "Epoch 13 Batch 250 Loss 1.0531 Accuracy 0.6472\n",
      "Epoch 13 Batch 300 Loss 1.0519 Accuracy 0.6475\n",
      "Epoch 13 Loss 1.0508 Accuracy 0.6478\n",
      "Time taken for 1 epoch: 87.49 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.0273 Accuracy 0.6647\n",
      "Epoch 14 Batch 50 Loss 1.0260 Accuracy 0.6562\n",
      "Epoch 14 Batch 100 Loss 1.0275 Accuracy 0.6552\n",
      "Epoch 14 Batch 150 Loss 1.0257 Accuracy 0.6560\n",
      "Epoch 14 Batch 200 Loss 1.0240 Accuracy 0.6565\n",
      "Epoch 14 Batch 250 Loss 1.0221 Accuracy 0.6569\n",
      "Epoch 14 Batch 300 Loss 1.0215 Accuracy 0.6570\n",
      "Epoch 14 Loss 1.0206 Accuracy 0.6572\n",
      "Time taken for 1 epoch: 87.54 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.9885 Accuracy 0.6643\n",
      "Epoch 15 Batch 50 Loss 0.9980 Accuracy 0.6641\n",
      "Epoch 15 Batch 100 Loss 0.9950 Accuracy 0.6650\n",
      "Epoch 15 Batch 150 Loss 0.9938 Accuracy 0.6652\n",
      "Epoch 15 Batch 200 Loss 0.9938 Accuracy 0.6653\n",
      "Epoch 15 Batch 250 Loss 0.9931 Accuracy 0.6656\n",
      "Epoch 15 Batch 300 Loss 0.9920 Accuracy 0.6660\n",
      "Epoch 15 Batch 0 Validation Loss 0.9567 Validation Accuracy 0.6767\n",
      "Epoch 15 Batch 50 Validation Loss 0.9657 Validation Accuracy 0.6748\n",
      "Epoch 15 Batch 100 Validation Loss 0.9612 Validation Accuracy 0.6765\n",
      "Epoch 15 Loss 0.9914 Accuracy 0.6662\n",
      "Time taken for 1 epoch: 115.85 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7454<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_184805-868jjwul/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_184805-868jjwul/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.99138</td></tr><tr><td>train_accuracy</td><td>0.6662</td></tr><tr><td>_runtime</td><td>1625</td></tr><tr><td>_timestamp</td><td>1622229310</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>0.96191</td></tr><tr><td>val_accuracy</td><td>0.67628</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▄▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fresh-sweep-5</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/868jjwul\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/868jjwul</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kl569k0o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">zesty-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/kl569k0o\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/kl569k0o</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_191515-kl569k0o</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.9896 Accuracy 0.0181\n",
      "Epoch 1 Batch 50 Loss 3.8650 Accuracy 0.1329\n",
      "Epoch 1 Batch 100 Loss 3.4866 Accuracy 0.1696\n",
      "Epoch 1 Batch 150 Loss 3.3307 Accuracy 0.1839\n",
      "Epoch 1 Batch 200 Loss 3.2455 Accuracy 0.1918\n",
      "Epoch 1 Batch 250 Loss 3.1917 Accuracy 0.1971\n",
      "Epoch 1 Batch 300 Loss 3.1547 Accuracy 0.2009\n",
      "Epoch 1 Loss 3.1332 Accuracy 0.2031\n",
      "Time taken for 1 epoch: 156.20 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.8250 Accuracy 0.2410\n",
      "Epoch 2 Batch 50 Loss 2.5240 Accuracy 0.2795\n",
      "Epoch 2 Batch 100 Loss 2.3882 Accuracy 0.3012\n",
      "Epoch 2 Batch 150 Loss 2.3103 Accuracy 0.3127\n",
      "Epoch 2 Batch 200 Loss 2.2567 Accuracy 0.3208\n",
      "Epoch 2 Batch 250 Loss 2.2154 Accuracy 0.3272\n",
      "Epoch 2 Batch 300 Loss 2.1796 Accuracy 0.3331\n",
      "Epoch 2 Loss 2.1599 Accuracy 0.3363\n",
      "Time taken for 1 epoch: 127.30 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.9471 Accuracy 0.3729\n",
      "Epoch 3 Batch 50 Loss 1.9543 Accuracy 0.3720\n",
      "Epoch 3 Batch 100 Loss 1.9430 Accuracy 0.3757\n",
      "Epoch 3 Batch 150 Loss 1.9313 Accuracy 0.3781\n",
      "Epoch 3 Batch 200 Loss 1.9198 Accuracy 0.3808\n",
      "Epoch 3 Batch 250 Loss 1.9073 Accuracy 0.3838\n",
      "Epoch 3 Batch 300 Loss 1.8926 Accuracy 0.3875\n",
      "Epoch 3 Loss 1.8820 Accuracy 0.3901\n",
      "Time taken for 1 epoch: 129.02 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.7985 Accuracy 0.4073\n",
      "Epoch 4 Batch 50 Loss 1.7585 Accuracy 0.4206\n",
      "Epoch 4 Batch 100 Loss 1.7454 Accuracy 0.4243\n",
      "Epoch 4 Batch 150 Loss 1.7333 Accuracy 0.4277\n",
      "Epoch 4 Batch 200 Loss 1.7227 Accuracy 0.4310\n",
      "Epoch 4 Batch 250 Loss 1.7129 Accuracy 0.4339\n",
      "Epoch 4 Batch 300 Loss 1.7034 Accuracy 0.4370\n",
      "Epoch 4 Loss 1.6970 Accuracy 0.4389\n",
      "Time taken for 1 epoch: 128.35 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.5907 Accuracy 0.4680\n",
      "Epoch 5 Batch 50 Loss 1.6200 Accuracy 0.4620\n",
      "Epoch 5 Batch 100 Loss 1.6130 Accuracy 0.4644\n",
      "Epoch 5 Batch 150 Loss 1.6047 Accuracy 0.4672\n",
      "Epoch 5 Batch 200 Loss 1.5965 Accuracy 0.4699\n",
      "Epoch 5 Batch 250 Loss 1.5901 Accuracy 0.4719\n",
      "Epoch 5 Batch 300 Loss 1.5845 Accuracy 0.4739\n",
      "Epoch 5 Batch 0 Validation Loss 1.4855 Validation Accuracy 0.5037\n",
      "Epoch 5 Batch 50 Validation Loss 1.4916 Validation Accuracy 0.5006\n",
      "Epoch 5 Batch 100 Validation Loss 1.4918 Validation Accuracy 0.5012\n",
      "Epoch 5 Loss 1.5800 Accuracy 0.4752\n",
      "Time taken for 1 epoch: 167.50 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.5306 Accuracy 0.4889\n",
      "Epoch 6 Batch 50 Loss 1.5266 Accuracy 0.4928\n",
      "Epoch 6 Batch 100 Loss 1.5219 Accuracy 0.4939\n",
      "Epoch 6 Batch 150 Loss 1.5164 Accuracy 0.4961\n",
      "Epoch 6 Batch 200 Loss 1.5099 Accuracy 0.4981\n",
      "Epoch 6 Batch 250 Loss 1.5047 Accuracy 0.4994\n",
      "Epoch 6 Batch 300 Loss 1.4999 Accuracy 0.5012\n",
      "Epoch 6 Loss 1.4971 Accuracy 0.5021\n",
      "Time taken for 1 epoch: 127.01 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.4385 Accuracy 0.5213\n",
      "Epoch 7 Batch 50 Loss 1.4581 Accuracy 0.5134\n",
      "Epoch 7 Batch 100 Loss 1.4523 Accuracy 0.5159\n",
      "Epoch 7 Batch 150 Loss 1.4481 Accuracy 0.5171\n",
      "Epoch 7 Batch 200 Loss 1.4434 Accuracy 0.5188\n",
      "Epoch 7 Batch 250 Loss 1.4386 Accuracy 0.5205\n",
      "Epoch 7 Batch 300 Loss 1.4352 Accuracy 0.5218\n",
      "Epoch 7 Loss 1.4327 Accuracy 0.5228\n",
      "Time taken for 1 epoch: 127.05 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.3823 Accuracy 0.5375\n",
      "Epoch 8 Batch 50 Loss 1.3939 Accuracy 0.5352\n",
      "Epoch 8 Batch 100 Loss 1.3919 Accuracy 0.5364\n",
      "Epoch 8 Batch 150 Loss 1.3885 Accuracy 0.5375\n",
      "Epoch 8 Batch 200 Loss 1.3859 Accuracy 0.5387\n",
      "Epoch 8 Batch 250 Loss 1.3813 Accuracy 0.5402\n",
      "Epoch 8 Batch 300 Loss 1.3774 Accuracy 0.5416\n",
      "Epoch 8 Loss 1.3747 Accuracy 0.5425\n",
      "Time taken for 1 epoch: 127.40 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.3359 Accuracy 0.5561\n",
      "Epoch 9 Batch 50 Loss 1.3423 Accuracy 0.5522\n",
      "Epoch 9 Batch 100 Loss 1.3366 Accuracy 0.5550\n",
      "Epoch 9 Batch 150 Loss 1.3355 Accuracy 0.5557\n",
      "Epoch 9 Batch 200 Loss 1.3305 Accuracy 0.5573\n",
      "Epoch 9 Batch 250 Loss 1.3258 Accuracy 0.5588\n",
      "Epoch 9 Batch 300 Loss 1.3223 Accuracy 0.5600\n",
      "Epoch 9 Loss 1.3214 Accuracy 0.5605\n",
      "Time taken for 1 epoch: 127.06 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.2864 Accuracy 0.5708\n",
      "Epoch 10 Batch 50 Loss 1.2853 Accuracy 0.5727\n",
      "Epoch 10 Batch 100 Loss 1.2849 Accuracy 0.5733\n",
      "Epoch 10 Batch 150 Loss 1.2812 Accuracy 0.5744\n",
      "Epoch 10 Batch 200 Loss 1.2773 Accuracy 0.5753\n",
      "Epoch 10 Batch 250 Loss 1.2731 Accuracy 0.5768\n",
      "Epoch 10 Batch 300 Loss 1.2699 Accuracy 0.5779\n",
      "Epoch 10 Batch 0 Validation Loss 1.2035 Validation Accuracy 0.5925\n",
      "Epoch 10 Batch 50 Validation Loss 1.2019 Validation Accuracy 0.5999\n",
      "Epoch 10 Batch 100 Validation Loss 1.2029 Validation Accuracy 0.5996\n",
      "Epoch 10 Loss 1.2684 Accuracy 0.5783\n",
      "Time taken for 1 epoch: 167.23 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.2386 Accuracy 0.5927\n",
      "Epoch 11 Batch 50 Loss 1.2394 Accuracy 0.5870\n",
      "Epoch 11 Batch 100 Loss 1.2421 Accuracy 0.5866\n",
      "Epoch 11 Batch 150 Loss 1.2414 Accuracy 0.5875\n",
      "Epoch 11 Batch 200 Loss 1.2362 Accuracy 0.5893\n",
      "Epoch 11 Batch 250 Loss 1.2311 Accuracy 0.5908\n",
      "Epoch 11 Batch 300 Loss 1.2289 Accuracy 0.5916\n",
      "Epoch 11 Loss 1.2275 Accuracy 0.5920\n",
      "Time taken for 1 epoch: 126.88 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.1879 Accuracy 0.6048\n",
      "Epoch 12 Batch 50 Loss 1.2036 Accuracy 0.6013\n",
      "Epoch 12 Batch 100 Loss 1.2030 Accuracy 0.6012\n",
      "Epoch 12 Batch 150 Loss 1.1992 Accuracy 0.6020\n",
      "Epoch 12 Batch 200 Loss 1.1965 Accuracy 0.6027\n",
      "Epoch 12 Batch 250 Loss 1.1960 Accuracy 0.6028\n",
      "Epoch 12 Batch 300 Loss 1.1942 Accuracy 0.6033\n",
      "Epoch 12 Loss 1.1930 Accuracy 0.6036\n",
      "Time taken for 1 epoch: 126.97 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.1914 Accuracy 0.6056\n",
      "Epoch 13 Batch 50 Loss 1.1742 Accuracy 0.6100\n",
      "Epoch 13 Batch 100 Loss 1.1679 Accuracy 0.6113\n",
      "Epoch 13 Batch 150 Loss 1.1652 Accuracy 0.6120\n",
      "Epoch 13 Batch 200 Loss 1.1628 Accuracy 0.6129\n",
      "Epoch 13 Batch 250 Loss 1.1628 Accuracy 0.6128\n",
      "Epoch 13 Batch 300 Loss 1.1600 Accuracy 0.6137\n",
      "Epoch 13 Loss 1.1587 Accuracy 0.6142\n",
      "Time taken for 1 epoch: 127.21 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.1512 Accuracy 0.6161\n",
      "Epoch 14 Batch 50 Loss 1.1257 Accuracy 0.6244\n",
      "Epoch 14 Batch 100 Loss 1.1277 Accuracy 0.6236\n",
      "Epoch 14 Batch 150 Loss 1.1302 Accuracy 0.6227\n",
      "Epoch 14 Batch 200 Loss 1.1291 Accuracy 0.6233\n",
      "Epoch 14 Batch 250 Loss 1.1267 Accuracy 0.6241\n",
      "Epoch 14 Batch 300 Loss 1.1242 Accuracy 0.6249\n",
      "Epoch 14 Loss 1.1229 Accuracy 0.6253\n",
      "Time taken for 1 epoch: 127.21 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.0874 Accuracy 0.6381\n",
      "Epoch 15 Batch 50 Loss 1.0935 Accuracy 0.6347\n",
      "Epoch 15 Batch 100 Loss 1.0944 Accuracy 0.6341\n",
      "Epoch 15 Batch 150 Loss 1.0949 Accuracy 0.6339\n",
      "Epoch 15 Batch 200 Loss 1.0978 Accuracy 0.6333\n",
      "Epoch 15 Batch 250 Loss 1.0958 Accuracy 0.6340\n",
      "Epoch 15 Batch 300 Loss 1.0943 Accuracy 0.6344\n",
      "Epoch 15 Batch 0 Validation Loss 1.0525 Validation Accuracy 0.6528\n",
      "Epoch 15 Batch 50 Validation Loss 1.0469 Validation Accuracy 0.6495\n",
      "Epoch 15 Batch 100 Validation Loss 1.0458 Validation Accuracy 0.6502\n",
      "Epoch 15 Loss 1.0933 Accuracy 0.6347\n",
      "Time taken for 1 epoch: 167.64 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8993<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_191515-kl569k0o/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_191515-kl569k0o/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>1.09334</td></tr><tr><td>train_accuracy</td><td>0.63472</td></tr><tr><td>_runtime</td><td>2365</td></tr><tr><td>_timestamp</td><td>1622231680</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>1.04573</td></tr><tr><td>val_accuracy</td><td>0.65015</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">zesty-sweep-6</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/kl569k0o\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/kl569k0o</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k8y4hckm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">unique-sweep-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/k8y4hckm\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/k8y4hckm</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_195444-k8y4hckm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.5716 Accuracy 0.0022\n",
      "Epoch 1 Batch 50 Loss 4.3405 Accuracy 0.1259\n",
      "Epoch 1 Batch 100 Loss 3.7211 Accuracy 0.1678\n",
      "Epoch 1 Batch 150 Loss 3.4345 Accuracy 0.1913\n",
      "Epoch 1 Batch 200 Loss 3.1682 Accuracy 0.2234\n",
      "Epoch 1 Batch 250 Loss 2.9610 Accuracy 0.2491\n",
      "Epoch 1 Batch 300 Loss 2.8092 Accuracy 0.2677\n",
      "Epoch 1 Loss 2.7322 Accuracy 0.2771\n",
      "Time taken for 1 epoch: 54.06 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.9702 Accuracy 0.3746\n",
      "Epoch 2 Batch 50 Loss 1.9754 Accuracy 0.3707\n",
      "Epoch 2 Batch 100 Loss 1.9656 Accuracy 0.3714\n",
      "Epoch 2 Batch 150 Loss 1.9542 Accuracy 0.3743\n",
      "Epoch 2 Batch 200 Loss 1.9430 Accuracy 0.3770\n",
      "Epoch 2 Batch 250 Loss 1.9312 Accuracy 0.3798\n",
      "Epoch 2 Batch 300 Loss 1.9173 Accuracy 0.3835\n",
      "Epoch 2 Loss 1.9081 Accuracy 0.3860\n",
      "Time taken for 1 epoch: 44.05 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.7919 Accuracy 0.4211\n",
      "Epoch 3 Batch 50 Loss 1.7794 Accuracy 0.4208\n",
      "Epoch 3 Batch 100 Loss 1.7592 Accuracy 0.4262\n",
      "Epoch 3 Batch 150 Loss 1.7383 Accuracy 0.4321\n",
      "Epoch 3 Batch 200 Loss 1.7192 Accuracy 0.4376\n",
      "Epoch 3 Batch 250 Loss 1.7002 Accuracy 0.4432\n",
      "Epoch 3 Batch 300 Loss 1.6823 Accuracy 0.4485\n",
      "Epoch 3 Loss 1.6718 Accuracy 0.4518\n",
      "Time taken for 1 epoch: 44.30 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.5474 Accuracy 0.4869\n",
      "Epoch 4 Batch 50 Loss 1.5398 Accuracy 0.4909\n",
      "Epoch 4 Batch 100 Loss 1.5267 Accuracy 0.4952\n",
      "Epoch 4 Batch 150 Loss 1.5157 Accuracy 0.4985\n",
      "Epoch 4 Batch 200 Loss 1.5057 Accuracy 0.5016\n",
      "Epoch 4 Batch 250 Loss 1.4952 Accuracy 0.5050\n",
      "Epoch 4 Batch 300 Loss 1.4848 Accuracy 0.5082\n",
      "Epoch 4 Loss 1.4779 Accuracy 0.5103\n",
      "Time taken for 1 epoch: 44.22 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4046 Accuracy 0.5258\n",
      "Epoch 5 Batch 50 Loss 1.3931 Accuracy 0.5371\n",
      "Epoch 5 Batch 100 Loss 1.3861 Accuracy 0.5392\n",
      "Epoch 5 Batch 150 Loss 1.3807 Accuracy 0.5413\n",
      "Epoch 5 Batch 200 Loss 1.3741 Accuracy 0.5435\n",
      "Epoch 5 Batch 250 Loss 1.3668 Accuracy 0.5459\n",
      "Epoch 5 Batch 300 Loss 1.3597 Accuracy 0.5482\n",
      "Epoch 5 Batch 0 Validation Loss 1.2433 Validation Accuracy 0.5966\n",
      "Epoch 5 Batch 50 Validation Loss 1.2554 Validation Accuracy 0.5826\n",
      "Epoch 5 Batch 100 Validation Loss 1.2558 Validation Accuracy 0.5825\n",
      "Epoch 5 Loss 1.3556 Accuracy 0.5497\n",
      "Time taken for 1 epoch: 58.94 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.2779 Accuracy 0.5671\n",
      "Epoch 6 Batch 50 Loss 1.2915 Accuracy 0.5713\n",
      "Epoch 6 Batch 100 Loss 1.2846 Accuracy 0.5738\n",
      "Epoch 6 Batch 150 Loss 1.2798 Accuracy 0.5751\n",
      "Epoch 6 Batch 200 Loss 1.2742 Accuracy 0.5772\n",
      "Epoch 6 Batch 250 Loss 1.2700 Accuracy 0.5789\n",
      "Epoch 6 Batch 300 Loss 1.2653 Accuracy 0.5805\n",
      "Epoch 6 Loss 1.2624 Accuracy 0.5815\n",
      "Time taken for 1 epoch: 43.94 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.1862 Accuracy 0.6068\n",
      "Epoch 7 Batch 50 Loss 1.2033 Accuracy 0.5997\n",
      "Epoch 7 Batch 100 Loss 1.2044 Accuracy 0.5995\n",
      "Epoch 7 Batch 150 Loss 1.2008 Accuracy 0.6009\n",
      "Epoch 7 Batch 200 Loss 1.1979 Accuracy 0.6022\n",
      "Epoch 7 Batch 250 Loss 1.1934 Accuracy 0.6036\n",
      "Epoch 7 Batch 300 Loss 1.1906 Accuracy 0.6044\n",
      "Epoch 7 Loss 1.1892 Accuracy 0.6049\n",
      "Time taken for 1 epoch: 44.21 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.1169 Accuracy 0.6250\n",
      "Epoch 8 Batch 50 Loss 1.1432 Accuracy 0.6185\n",
      "Epoch 8 Batch 100 Loss 1.1451 Accuracy 0.6185\n",
      "Epoch 8 Batch 150 Loss 1.1429 Accuracy 0.6196\n",
      "Epoch 8 Batch 200 Loss 1.1408 Accuracy 0.6202\n",
      "Epoch 8 Batch 250 Loss 1.1374 Accuracy 0.6212\n",
      "Epoch 8 Batch 300 Loss 1.1345 Accuracy 0.6221\n",
      "Epoch 8 Loss 1.1331 Accuracy 0.6224\n",
      "Time taken for 1 epoch: 44.07 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1013 Accuracy 0.6241\n",
      "Epoch 9 Batch 50 Loss 1.0897 Accuracy 0.6347\n",
      "Epoch 9 Batch 100 Loss 1.0937 Accuracy 0.6337\n",
      "Epoch 9 Batch 150 Loss 1.0909 Accuracy 0.6348\n",
      "Epoch 9 Batch 200 Loss 1.0896 Accuracy 0.6354\n",
      "Epoch 9 Batch 250 Loss 1.0893 Accuracy 0.6355\n",
      "Epoch 9 Batch 300 Loss 1.0876 Accuracy 0.6362\n",
      "Epoch 9 Loss 1.0863 Accuracy 0.6366\n",
      "Time taken for 1 epoch: 44.00 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.0247 Accuracy 0.6471\n",
      "Epoch 10 Batch 50 Loss 1.0479 Accuracy 0.6484\n",
      "Epoch 10 Batch 100 Loss 1.0490 Accuracy 0.6486\n",
      "Epoch 10 Batch 150 Loss 1.0472 Accuracy 0.6492\n",
      "Epoch 10 Batch 200 Loss 1.0428 Accuracy 0.6510\n",
      "Epoch 10 Batch 250 Loss 1.0376 Accuracy 0.6526\n",
      "Epoch 10 Batch 300 Loss 1.0345 Accuracy 0.6538\n",
      "Epoch 10 Batch 0 Validation Loss 0.9815 Validation Accuracy 0.6725\n",
      "Epoch 10 Batch 50 Validation Loss 0.9858 Validation Accuracy 0.6718\n",
      "Epoch 10 Batch 100 Validation Loss 0.9868 Validation Accuracy 0.6716\n",
      "Epoch 10 Loss 1.0323 Accuracy 0.6546\n",
      "Time taken for 1 epoch: 58.67 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.9498 Accuracy 0.6858\n",
      "Epoch 11 Batch 50 Loss 0.9751 Accuracy 0.6731\n",
      "Epoch 11 Batch 100 Loss 0.9792 Accuracy 0.6719\n",
      "Epoch 11 Batch 150 Loss 0.9779 Accuracy 0.6725\n",
      "Epoch 11 Batch 200 Loss 0.9780 Accuracy 0.6725\n",
      "Epoch 11 Batch 250 Loss 0.9772 Accuracy 0.6726\n",
      "Epoch 11 Batch 300 Loss 0.9743 Accuracy 0.6737\n",
      "Epoch 11 Loss 0.9730 Accuracy 0.6742\n",
      "Time taken for 1 epoch: 44.14 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.9230 Accuracy 0.6901\n",
      "Epoch 12 Batch 50 Loss 0.9159 Accuracy 0.6939\n",
      "Epoch 12 Batch 100 Loss 0.9071 Accuracy 0.6969\n",
      "Epoch 12 Batch 150 Loss 0.8996 Accuracy 0.6994\n",
      "Epoch 12 Batch 200 Loss 0.8922 Accuracy 0.7022\n",
      "Epoch 12 Batch 250 Loss 0.8852 Accuracy 0.7047\n",
      "Epoch 12 Batch 300 Loss 0.8757 Accuracy 0.7082\n",
      "Epoch 12 Loss 0.8699 Accuracy 0.7102\n",
      "Time taken for 1 epoch: 44.02 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.7658 Accuracy 0.7406\n",
      "Epoch 13 Batch 50 Loss 0.7408 Accuracy 0.7552\n",
      "Epoch 13 Batch 100 Loss 0.7261 Accuracy 0.7604\n",
      "Epoch 13 Batch 150 Loss 0.7117 Accuracy 0.7653\n",
      "Epoch 13 Batch 200 Loss 0.7001 Accuracy 0.7696\n",
      "Epoch 13 Batch 250 Loss 0.6884 Accuracy 0.7736\n",
      "Epoch 13 Batch 300 Loss 0.6764 Accuracy 0.7775\n",
      "Epoch 13 Loss 0.6693 Accuracy 0.7799\n",
      "Time taken for 1 epoch: 43.90 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.5521 Accuracy 0.8154\n",
      "Epoch 14 Batch 50 Loss 0.5437 Accuracy 0.8203\n",
      "Epoch 14 Batch 100 Loss 0.5394 Accuracy 0.8221\n",
      "Epoch 14 Batch 150 Loss 0.5354 Accuracy 0.8234\n",
      "Epoch 14 Batch 200 Loss 0.5305 Accuracy 0.8251\n",
      "Epoch 14 Batch 250 Loss 0.5253 Accuracy 0.8268\n",
      "Epoch 14 Batch 300 Loss 0.5204 Accuracy 0.8284\n",
      "Epoch 14 Loss 0.5167 Accuracy 0.8297\n",
      "Time taken for 1 epoch: 44.27 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.4246 Accuracy 0.8588\n",
      "Epoch 15 Batch 50 Loss 0.4401 Accuracy 0.8546\n",
      "Epoch 15 Batch 100 Loss 0.4375 Accuracy 0.8551\n",
      "Epoch 15 Batch 150 Loss 0.4356 Accuracy 0.8557\n",
      "Epoch 15 Batch 200 Loss 0.4337 Accuracy 0.8562\n",
      "Epoch 15 Batch 250 Loss 0.4335 Accuracy 0.8563\n",
      "Epoch 15 Batch 300 Loss 0.4306 Accuracy 0.8572\n",
      "Epoch 15 Batch 0 Validation Loss 0.3955 Validation Accuracy 0.8743\n",
      "Epoch 15 Batch 50 Validation Loss 0.4028 Validation Accuracy 0.8692\n",
      "Epoch 15 Batch 100 Validation Loss 0.4002 Validation Accuracy 0.8698\n",
      "Epoch 15 Loss 0.4292 Accuracy 0.8576\n",
      "Time taken for 1 epoch: 58.57 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11636<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_195444-k8y4hckm/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_195444-k8y4hckm/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.4292</td></tr><tr><td>train_accuracy</td><td>0.85761</td></tr><tr><td>_runtime</td><td>823</td></tr><tr><td>_timestamp</td><td>1622232508</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>0.40048</td></tr><tr><td>val_accuracy</td><td>0.86965</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▅▅▄▄▄▃▃▃▃▃▂▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▄▅▅▅▅▆▆▆▇██</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▁</td></tr><tr><td>val_accuracy</td><td>▁▃█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">unique-sweep-7</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/k8y4hckm\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/k8y4hckm</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l32u04ge with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">breezy-sweep-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/l32u04ge\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/l32u04ge</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_200831-l32u04ge</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.0337 Accuracy 0.0064\n",
      "Epoch 1 Batch 50 Loss 3.8114 Accuracy 0.1463\n",
      "Epoch 1 Batch 100 Loss 3.4434 Accuracy 0.1763\n",
      "Epoch 1 Batch 150 Loss 3.2984 Accuracy 0.1885\n",
      "Epoch 1 Batch 200 Loss 3.2116 Accuracy 0.1967\n",
      "Epoch 1 Batch 250 Loss 3.0679 Accuracy 0.2154\n",
      "Epoch 1 Batch 300 Loss 2.9167 Accuracy 0.2367\n",
      "Epoch 1 Loss 2.8344 Accuracy 0.2482\n",
      "Time taken for 1 epoch: 99.74 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0362 Accuracy 0.3579\n",
      "Epoch 2 Batch 50 Loss 2.0106 Accuracy 0.3635\n",
      "Epoch 2 Batch 100 Loss 1.9942 Accuracy 0.3660\n",
      "Epoch 2 Batch 150 Loss 1.9800 Accuracy 0.3686\n",
      "Epoch 2 Batch 200 Loss 1.9667 Accuracy 0.3712\n",
      "Epoch 2 Batch 250 Loss 1.9523 Accuracy 0.3745\n",
      "Epoch 2 Batch 300 Loss 1.9366 Accuracy 0.3785\n",
      "Epoch 2 Loss 1.9254 Accuracy 0.3814\n",
      "Time taken for 1 epoch: 81.33 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.7737 Accuracy 0.4071\n",
      "Epoch 3 Batch 50 Loss 1.7773 Accuracy 0.4179\n",
      "Epoch 3 Batch 100 Loss 1.7537 Accuracy 0.4240\n",
      "Epoch 3 Batch 150 Loss 1.7367 Accuracy 0.4283\n",
      "Epoch 4 Batch 100 Loss 1.5572 Accuracy 0.4844\n",
      "Epoch 4 Batch 150 Loss 1.5468 Accuracy 0.4876\n",
      "Epoch 4 Batch 200 Loss 1.5364 Accuracy 0.4905\n",
      "Epoch 4 Batch 250 Loss 1.5258 Accuracy 0.4940\n",
      "Epoch 4 Batch 300 Loss 1.5165 Accuracy 0.4971\n",
      "Epoch 4 Loss 1.5105 Accuracy 0.4989\n",
      "Time taken for 1 epoch: 82.62 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4460 Accuracy 0.5079\n",
      "Epoch 5 Batch 50 Loss 1.4377 Accuracy 0.5208\n",
      "Epoch 5 Batch 100 Loss 1.4270 Accuracy 0.5240\n",
      "Epoch 5 Batch 150 Loss 1.4215 Accuracy 0.5264\n",
      "Epoch 5 Batch 200 Loss 1.4122 Accuracy 0.5294\n",
      "Epoch 5 Batch 250 Loss 1.4050 Accuracy 0.5321\n",
      "Epoch 5 Batch 300 Loss 1.3982 Accuracy 0.5344\n",
      "Epoch 5 Batch 0 Validation Loss 1.3077 Validation Accuracy 0.5642\n",
      "Epoch 5 Batch 50 Validation Loss 1.3017 Validation Accuracy 0.5646\n",
      "Epoch 5 Batch 100 Validation Loss 1.3019 Validation Accuracy 0.5649\n",
      "Epoch 5 Loss 1.3936 Accuracy 0.5359\n",
      "Time taken for 1 epoch: 111.47 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.3900 Accuracy 0.5361\n",
      "Epoch 6 Batch 50 Loss 1.3299 Accuracy 0.5571\n",
      "Epoch 6 Batch 100 Loss 1.3236 Accuracy 0.5594\n",
      "Epoch 6 Batch 150 Loss 1.3191 Accuracy 0.5610\n",
      "Epoch 6 Batch 200 Loss 1.3131 Accuracy 0.5631\n",
      "Epoch 6 Batch 250 Loss 1.3062 Accuracy 0.5653\n",
      "Epoch 6 Batch 300 Loss 1.3001 Accuracy 0.5675\n",
      "Epoch 6 Loss 1.2966 Accuracy 0.5686\n",
      "Time taken for 1 epoch: 81.54 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.2124 Accuracy 0.5991\n",
      "Epoch 7 Batch 50 Loss 1.2426 Accuracy 0.5860\n",
      "Epoch 7 Batch 100 Loss 1.2412 Accuracy 0.5871\n",
      "Epoch 7 Batch 150 Loss 1.2350 Accuracy 0.5892\n",
      "Epoch 7 Batch 200 Loss 1.2311 Accuracy 0.5904\n",
      "Epoch 7 Batch 250 Loss 1.2264 Accuracy 0.5920\n",
      "Epoch 7 Batch 300 Loss 1.2222 Accuracy 0.5935\n",
      "Epoch 7 Loss 1.2198 Accuracy 0.5942\n",
      "Time taken for 1 epoch: 82.60 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.1988 Accuracy 0.6029\n",
      "Epoch 8 Batch 50 Loss 1.1727 Accuracy 0.6082\n",
      "Epoch 8 Batch 100 Loss 1.1753 Accuracy 0.6079\n",
      "Epoch 8 Batch 150 Loss 1.1729 Accuracy 0.6090\n",
      "Epoch 8 Batch 200 Loss 1.1689 Accuracy 0.6103\n",
      "Epoch 8 Batch 250 Loss 1.1663 Accuracy 0.6110\n",
      "Epoch 8 Batch 300 Loss 1.1632 Accuracy 0.6121\n",
      "Epoch 8 Loss 1.1615 Accuracy 0.6126\n",
      "Time taken for 1 epoch: 82.97 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1142 Accuracy 0.6317\n",
      "Epoch 9 Batch 50 Loss 1.1256 Accuracy 0.6238\n",
      "Epoch 9 Batch 100 Loss 1.1207 Accuracy 0.6254\n",
      "Epoch 9 Batch 150 Loss 1.1204 Accuracy 0.6254\n",
      "Epoch 9 Batch 200 Loss 1.1186 Accuracy 0.6261\n",
      "Epoch 9 Batch 250 Loss 1.1175 Accuracy 0.6266\n",
      "Epoch 9 Batch 300 Loss 1.1159 Accuracy 0.6270\n",
      "Epoch 9 Loss 1.1144 Accuracy 0.6273\n",
      "Time taken for 1 epoch: 82.50 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.0782 Accuracy 0.6328\n",
      "Epoch 10 Batch 50 Loss 1.0835 Accuracy 0.6370\n",
      "Epoch 10 Batch 100 Loss 1.0822 Accuracy 0.6376\n",
      "Epoch 10 Batch 150 Loss 1.0823 Accuracy 0.6376\n",
      "Epoch 10 Batch 200 Loss 1.0820 Accuracy 0.6377\n",
      "Epoch 10 Batch 250 Loss 1.0800 Accuracy 0.6383\n",
      "Epoch 10 Batch 300 Loss 1.0781 Accuracy 0.6388\n",
      "Epoch 10 Batch 0 Validation Loss 1.0580 Validation Accuracy 0.6446\n",
      "Epoch 10 Batch 50 Validation Loss 1.0397 Validation Accuracy 0.6515\n",
      "Epoch 10 Batch 100 Validation Loss 1.0406 Validation Accuracy 0.6519\n",
      "Epoch 10 Loss 1.0776 Accuracy 0.6390\n",
      "Time taken for 1 epoch: 112.08 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.0440 Accuracy 0.6494\n",
      "Epoch 11 Batch 50 Loss 1.0523 Accuracy 0.6467\n",
      "Epoch 11 Batch 100 Loss 1.0522 Accuracy 0.6465\n",
      "Epoch 11 Batch 150 Loss 1.0491 Accuracy 0.6476\n",
      "Epoch 11 Batch 200 Loss 1.0495 Accuracy 0.6476\n",
      "Epoch 11 Batch 250 Loss 1.0491 Accuracy 0.6479\n",
      "Epoch 11 Batch 300 Loss 1.0480 Accuracy 0.6481\n",
      "Epoch 11 Loss 1.0473 Accuracy 0.6484\n",
      "Time taken for 1 epoch: 81.79 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.0065 Accuracy 0.6581\n",
      "Epoch 12 Batch 50 Loss 1.0215 Accuracy 0.6565\n",
      "Epoch 12 Batch 100 Loss 1.0241 Accuracy 0.6553\n",
      "Epoch 12 Batch 150 Loss 1.0249 Accuracy 0.6549\n",
      "Epoch 12 Batch 200 Loss 1.0234 Accuracy 0.6554\n",
      "Epoch 12 Batch 250 Loss 1.0221 Accuracy 0.6559\n",
      "Epoch 12 Batch 300 Loss 1.0222 Accuracy 0.6558\n",
      "Epoch 12 Loss 1.0222 Accuracy 0.6560\n",
      "Time taken for 1 epoch: 82.57 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.9851 Accuracy 0.6670\n",
      "Epoch 13 Batch 50 Loss 0.9959 Accuracy 0.6633\n",
      "Epoch 13 Batch 100 Loss 0.9960 Accuracy 0.6639\n",
      "Epoch 13 Batch 150 Loss 0.9967 Accuracy 0.6639\n",
      "Epoch 13 Batch 200 Loss 0.9967 Accuracy 0.6641\n",
      "Epoch 13 Batch 250 Loss 0.9954 Accuracy 0.6647\n",
      "Epoch 13 Batch 300 Loss 0.9947 Accuracy 0.6648\n",
      "Epoch 13 Loss 0.9938 Accuracy 0.6650\n",
      "Time taken for 1 epoch: 82.59 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.9531 Accuracy 0.6817\n",
      "Epoch 14 Batch 50 Loss 0.9636 Accuracy 0.6738\n",
      "Epoch 14 Batch 100 Loss 0.9635 Accuracy 0.6743\n",
      "Epoch 14 Batch 150 Loss 0.9630 Accuracy 0.6747\n",
      "Epoch 14 Batch 200 Loss 0.9627 Accuracy 0.6748\n",
      "Epoch 14 Batch 250 Loss 0.9612 Accuracy 0.6751\n",
      "Epoch 14 Batch 300 Loss 0.9605 Accuracy 0.6754\n",
      "Epoch 14 Loss 0.9592 Accuracy 0.6757\n",
      "Time taken for 1 epoch: 82.68 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.9392 Accuracy 0.6783\n",
      "Epoch 15 Batch 50 Loss 0.9254 Accuracy 0.6863\n",
      "Epoch 15 Batch 100 Loss 0.9274 Accuracy 0.6860\n",
      "Epoch 15 Batch 150 Loss 0.9270 Accuracy 0.6859\n",
      "Epoch 15 Batch 200 Loss 0.9279 Accuracy 0.6855\n",
      "Epoch 15 Batch 250 Loss 0.9276 Accuracy 0.6857\n",
      "Epoch 15 Batch 300 Loss 0.9272 Accuracy 0.6856\n",
      "Epoch 15 Batch 0 Validation Loss 0.8981 Validation Accuracy 0.7014\n",
      "Epoch 15 Batch 50 Validation Loss 0.9070 Validation Accuracy 0.6935\n",
      "Epoch 15 Batch 100 Validation Loss 0.9082 Validation Accuracy 0.6932\n",
      "Epoch 15 Loss 0.9263 Accuracy 0.6860\n",
      "Time taken for 1 epoch: 110.25 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12699<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_200831-l32u04ge/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_200831-l32u04ge/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.92633</td></tr><tr><td>train_accuracy</td><td>0.68602</td></tr><tr><td>_runtime</td><td>1539</td></tr><tr><td>_timestamp</td><td>1622234050</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>0.90898</td></tr><tr><td>val_accuracy</td><td>0.69299</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▆▆▇▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">breezy-sweep-8</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/l32u04ge\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/l32u04ge</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2j6n9s1k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">morning-sweep-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/2j6n9s1k\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/2j6n9s1k</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_203414-2j6n9s1k</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.1076 Accuracy 0.0045\n",
      "Epoch 1 Batch 50 Loss 3.8819 Accuracy 0.1597\n",
      "Epoch 1 Batch 100 Loss 3.4748 Accuracy 0.1835\n",
      "Epoch 1 Batch 150 Loss 3.3180 Accuracy 0.1934\n",
      "Epoch 1 Batch 200 Loss 3.2340 Accuracy 0.1993\n",
      "Epoch 1 Batch 250 Loss 3.1817 Accuracy 0.2033\n",
      "Epoch 1 Batch 300 Loss 3.1434 Accuracy 0.2063\n",
      "Epoch 1 Loss 3.0962 Accuracy 0.2114\n",
      "Time taken for 1 epoch: 148.63 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.5008 Accuracy 0.2810\n",
      "Epoch 2 Batch 50 Loss 2.4176 Accuracy 0.2850\n",
      "Epoch 2 Batch 100 Loss 2.3130 Accuracy 0.3060\n",
      "Epoch 2 Batch 150 Loss 2.2507 Accuracy 0.3188\n",
      "Epoch 2 Batch 200 Loss 2.2059 Accuracy 0.3270\n",
      "Epoch 2 Batch 250 Loss 2.1714 Accuracy 0.3336\n",
      "Epoch 2 Batch 300 Loss 2.1401 Accuracy 0.3393\n",
      "Epoch 2 Loss 2.1234 Accuracy 0.3421\n",
      "Time taken for 1 epoch: 120.22 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.9642 Accuracy 0.3695\n",
      "Epoch 3 Batch 50 Loss 1.9353 Accuracy 0.3766\n",
      "Epoch 3 Batch 100 Loss 1.9200 Accuracy 0.3799\n",
      "Epoch 3 Batch 150 Loss 1.9038 Accuracy 0.3846\n",
      "Epoch 3 Batch 200 Loss 1.8842 Accuracy 0.3893\n",
      "Epoch 3 Batch 250 Loss 1.8644 Accuracy 0.3941\n",
      "Epoch 3 Batch 300 Loss 1.8468 Accuracy 0.3988\n",
      "Epoch 3 Loss 1.8363 Accuracy 0.4015\n",
      "Time taken for 1 epoch: 121.99 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.7330 Accuracy 0.4362\n",
      "Epoch 4 Batch 50 Loss 1.7121 Accuracy 0.4354\n",
      "Epoch 4 Batch 100 Loss 1.7033 Accuracy 0.4373\n",
      "Epoch 4 Batch 150 Loss 1.6964 Accuracy 0.4394\n",
      "Epoch 4 Batch 200 Loss 1.6886 Accuracy 0.4418\n",
      "Epoch 4 Batch 250 Loss 1.6789 Accuracy 0.4452\n",
      "Epoch 4 Batch 300 Loss 1.6692 Accuracy 0.4480\n",
      "Epoch 4 Loss 1.6630 Accuracy 0.4500\n",
      "Time taken for 1 epoch: 122.00 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.6060 Accuracy 0.4676\n",
      "Epoch 5 Batch 50 Loss 1.5893 Accuracy 0.4729\n",
      "Epoch 5 Batch 100 Loss 1.5813 Accuracy 0.4762\n",
      "Epoch 5 Batch 150 Loss 1.5723 Accuracy 0.4787\n",
      "Epoch 5 Batch 200 Loss 1.5641 Accuracy 0.4813\n",
      "Epoch 5 Batch 250 Loss 1.5574 Accuracy 0.4831\n",
      "Epoch 5 Batch 300 Loss 1.5500 Accuracy 0.4853\n",
      "Epoch 5 Batch 0 Validation Loss 1.4396 Validation Accuracy 0.5198\n",
      "Epoch 5 Batch 50 Validation Loss 1.4517 Validation Accuracy 0.5156\n",
      "Epoch 5 Batch 100 Validation Loss 1.4518 Validation Accuracy 0.5147\n",
      "Epoch 5 Loss 1.5455 Accuracy 0.4865\n",
      "Time taken for 1 epoch: 163.73 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.4910 Accuracy 0.5065\n",
      "Epoch 6 Batch 50 Loss 1.4862 Accuracy 0.5063\n",
      "Epoch 6 Batch 100 Loss 1.4857 Accuracy 0.5057\n",
      "Epoch 6 Batch 150 Loss 1.4788 Accuracy 0.5083\n",
      "Epoch 6 Batch 200 Loss 1.4729 Accuracy 0.5096\n",
      "Epoch 6 Batch 250 Loss 1.4651 Accuracy 0.5121\n",
      "Epoch 6 Batch 300 Loss 1.4593 Accuracy 0.5141\n",
      "Epoch 6 Loss 1.4558 Accuracy 0.5152\n",
      "Time taken for 1 epoch: 120.58 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.4494 Accuracy 0.5251\n",
      "Epoch 7 Batch 50 Loss 1.4093 Accuracy 0.5315\n",
      "Epoch 7 Batch 100 Loss 1.6006 Accuracy 0.4822\n",
      "Epoch 7 Batch 150 Loss 1.6012 Accuracy 0.4787\n",
      "Epoch 7 Batch 200 Loss 1.5586 Accuracy 0.4898\n",
      "Epoch 7 Batch 250 Loss 1.5253 Accuracy 0.4991\n",
      "Epoch 7 Batch 300 Loss 1.5003 Accuracy 0.5062\n",
      "Epoch 7 Loss 1.4879 Accuracy 0.5098\n",
      "Time taken for 1 epoch: 122.04 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.3900 Accuracy 0.5390\n",
      "Epoch 8 Batch 50 Loss 1.3646 Accuracy 0.5450\n",
      "Epoch 8 Batch 100 Loss 1.3567 Accuracy 0.5478\n",
      "Epoch 8 Batch 150 Loss 1.3502 Accuracy 0.5497\n",
      "Epoch 8 Batch 200 Loss 1.3436 Accuracy 0.5520\n",
      "Epoch 8 Batch 250 Loss 1.3375 Accuracy 0.5541\n",
      "Epoch 8 Batch 300 Loss 1.3322 Accuracy 0.5561\n",
      "Epoch 8 Loss 1.3291 Accuracy 0.5571\n",
      "Time taken for 1 epoch: 122.18 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.2798 Accuracy 0.5742\n",
      "Epoch 9 Batch 50 Loss 1.2810 Accuracy 0.5737\n",
      "Epoch 9 Batch 100 Loss 1.2740 Accuracy 0.5754\n",
      "Epoch 9 Batch 150 Loss 1.2718 Accuracy 0.5761\n",
      "Epoch 9 Batch 200 Loss 1.2677 Accuracy 0.5776\n",
      "Epoch 9 Batch 250 Loss 1.2652 Accuracy 0.5786\n",
      "Epoch 9 Batch 300 Loss 1.2604 Accuracy 0.5802\n",
      "Epoch 9 Loss 1.2588 Accuracy 0.5807\n",
      "Time taken for 1 epoch: 122.07 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.2413 Accuracy 0.5873\n",
      "Epoch 10 Batch 50 Loss 1.2186 Accuracy 0.5928\n",
      "Epoch 10 Batch 100 Loss 1.2149 Accuracy 0.5949\n",
      "Epoch 10 Batch 150 Loss 1.2122 Accuracy 0.5962\n",
      "Epoch 10 Batch 200 Loss 1.2112 Accuracy 0.5967\n",
      "Epoch 10 Batch 250 Loss 1.2092 Accuracy 0.5972\n",
      "Epoch 10 Batch 300 Loss 1.2060 Accuracy 0.5981\n",
      "Epoch 10 Batch 0 Validation Loss 1.1389 Validation Accuracy 0.6217\n",
      "Epoch 10 Batch 50 Validation Loss 1.1475 Validation Accuracy 0.6180\n",
      "Epoch 10 Batch 100 Validation Loss 1.1485 Validation Accuracy 0.6181\n",
      "Epoch 10 Loss 1.2037 Accuracy 0.5987\n",
      "Time taken for 1 epoch: 163.53 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.1917 Accuracy 0.6026\n",
      "Epoch 11 Batch 50 Loss 1.1762 Accuracy 0.6072\n",
      "Epoch 11 Batch 100 Loss 1.1728 Accuracy 0.6083\n",
      "Epoch 11 Batch 150 Loss 1.1695 Accuracy 0.6094\n",
      "Epoch 11 Batch 200 Loss 1.1682 Accuracy 0.6099\n",
      "Epoch 11 Batch 250 Loss 1.1664 Accuracy 0.6105\n",
      "Epoch 11 Batch 300 Loss 1.1645 Accuracy 0.6111\n",
      "Epoch 11 Loss 1.1631 Accuracy 0.6117\n",
      "Time taken for 1 epoch: 120.43 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.1055 Accuracy 0.6315\n",
      "Epoch 12 Batch 50 Loss 1.1398 Accuracy 0.6182\n",
      "Epoch 12 Batch 100 Loss 1.1369 Accuracy 0.6195\n",
      "Epoch 12 Batch 150 Loss 1.1338 Accuracy 0.6211\n",
      "Epoch 12 Batch 200 Loss 1.1324 Accuracy 0.6217\n",
      "Epoch 12 Batch 250 Loss 1.1318 Accuracy 0.6217\n",
      "Epoch 12 Batch 300 Loss 1.1316 Accuracy 0.6220\n",
      "Epoch 12 Loss 1.1307 Accuracy 0.6224\n",
      "Time taken for 1 epoch: 121.89 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.1622 Accuracy 0.6084\n",
      "Epoch 13 Batch 50 Loss 1.1092 Accuracy 0.6286\n",
      "Epoch 13 Batch 100 Loss 1.1054 Accuracy 0.6296\n",
      "Epoch 13 Batch 150 Loss 1.1065 Accuracy 0.6293\n",
      "Epoch 13 Batch 200 Loss 1.1034 Accuracy 0.6302\n",
      "Epoch 13 Batch 250 Loss 1.1022 Accuracy 0.6308\n",
      "Epoch 13 Batch 300 Loss 1.1002 Accuracy 0.6315\n",
      "Epoch 13 Loss 1.0992 Accuracy 0.6318\n",
      "Time taken for 1 epoch: 122.00 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.1045 Accuracy 0.6277\n",
      "Epoch 14 Batch 50 Loss 1.0727 Accuracy 0.6392\n",
      "Epoch 14 Batch 100 Loss 1.0746 Accuracy 0.6392\n",
      "Epoch 14 Batch 150 Loss 1.0765 Accuracy 0.6392\n",
      "Epoch 14 Batch 200 Loss 1.0772 Accuracy 0.6393\n",
      "Epoch 14 Batch 250 Loss 1.0732 Accuracy 0.6404\n",
      "Epoch 14 Batch 300 Loss 1.0713 Accuracy 0.6409\n",
      "Epoch 14 Loss 1.0697 Accuracy 0.6414\n",
      "Time taken for 1 epoch: 121.71 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.0212 Accuracy 0.6505\n",
      "Epoch 15 Batch 50 Loss 1.0491 Accuracy 0.6470\n",
      "Epoch 15 Batch 100 Loss 1.0433 Accuracy 0.6490\n",
      "Epoch 15 Batch 150 Loss 1.0413 Accuracy 0.6499\n",
      "Epoch 15 Batch 200 Loss 1.0404 Accuracy 0.6502\n",
      "Epoch 15 Batch 250 Loss 1.0399 Accuracy 0.6504\n",
      "Epoch 15 Batch 300 Loss 1.0390 Accuracy 0.6506\n",
      "Epoch 15 Batch 0 Validation Loss 1.0426 Validation Accuracy 0.6468\n",
      "Epoch 15 Batch 50 Validation Loss 1.0043 Validation Accuracy 0.6622\n",
      "Epoch 15 Batch 100 Validation Loss 1.0032 Validation Accuracy 0.6629\n",
      "Epoch 15 Loss 1.0393 Accuracy 0.6505\n",
      "Time taken for 1 epoch: 163.57 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14618<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/wandb/run-20210528_203414-2j6n9s1k/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/wandb/run-20210528_203414-2j6n9s1k/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>1.03931</td></tr><tr><td>train_accuracy</td><td>0.65046</td></tr><tr><td>_runtime</td><td>2273</td></tr><tr><td>_timestamp</td><td>1622236327</td></tr><tr><td>_step</td><td>15</td></tr><tr><td>val_loss</td><td>1.00302</td></tr><tr><td>val_accuracy</td><td>0.663</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▅▄▃▃▂▃▂▂▂▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">morning-sweep-9</strong>: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/2j6n9s1k\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/2j6n9s1k</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8fn5x3d8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">drawn-sweep-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/ohxcbbae</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/8fn5x3d8\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/8fn5x3d8</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210528_211211-8fn5x3d8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.7300 Accuracy 0.0176\n",
      "Epoch 1 Batch 50 Loss 3.8634 Accuracy 0.1671\n",
      "Epoch 1 Batch 100 Loss 3.4633 Accuracy 0.1901\n",
      "Epoch 1 Batch 150 Loss 3.2294 Accuracy 0.2104\n",
      "Epoch 1 Batch 200 Loss 2.9998 Accuracy 0.2400\n",
      "Epoch 1 Batch 250 Loss 2.8227 Accuracy 0.2625\n",
      "Epoch 1 Batch 300 Loss 2.6922 Accuracy 0.2790\n",
      "Epoch 1 Loss 2.6257 Accuracy 0.2874\n",
      "Time taken for 1 epoch: 59.84 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.9935 Accuracy 0.3744\n",
      "Epoch 2 Batch 50 Loss 1.9744 Accuracy 0.3708\n",
      "Epoch 2 Batch 100 Loss 1.9673 Accuracy 0.3715\n",
      "Epoch 2 Batch 150 Loss 1.9561 Accuracy 0.3738\n",
      "Epoch 2 Batch 200 Loss 1.9457 Accuracy 0.3761\n",
      "Epoch 2 Batch 250 Loss 1.9359 Accuracy 0.3785\n",
      "Epoch 2 Batch 300 Loss 1.9250 Accuracy 0.3810\n",
      "Epoch 2 Loss 1.9169 Accuracy 0.3830\n",
      "Time taken for 1 epoch: 50.34 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8489 Accuracy 0.4095\n",
      "Epoch 3 Batch 50 Loss 1.8173 Accuracy 0.4109\n",
      "Epoch 3 Batch 100 Loss 1.7998 Accuracy 0.4151\n",
      "Epoch 3 Batch 150 Loss 1.7828 Accuracy 0.4200\n",
      "Epoch 3 Batch 200 Loss 1.7658 Accuracy 0.4247\n",
      "Epoch 3 Batch 250 Loss 1.7476 Accuracy 0.4299\n",
      "Epoch 3 Batch 300 Loss 1.7306 Accuracy 0.4348\n",
      "Epoch 3 Loss 1.7200 Accuracy 0.4380\n",
      "Time taken for 1 epoch: 50.19 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.5965 Accuracy 0.4638\n",
      "Epoch 4 Batch 50 Loss 1.5948 Accuracy 0.4742\n",
      "Epoch 4 Batch 100 Loss 1.5811 Accuracy 0.4787\n",
      "Epoch 4 Batch 150 Loss 1.5709 Accuracy 0.4821\n",
      "Epoch 4 Batch 200 Loss 1.5583 Accuracy 0.4862\n",
      "Epoch 4 Batch 250 Loss 1.5461 Accuracy 0.4901\n",
      "Epoch 4 Batch 300 Loss 1.5350 Accuracy 0.4934\n",
      "Epoch 4 Loss 1.5280 Accuracy 0.4958\n",
      "Time taken for 1 epoch: 50.23 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4603 Accuracy 0.5114\n",
      "Epoch 5 Batch 50 Loss 1.4423 Accuracy 0.5211\n",
      "Epoch 5 Batch 100 Loss 1.4313 Accuracy 0.5247\n",
      "Epoch 5 Batch 150 Loss 1.4236 Accuracy 0.5275\n",
      "Epoch 5 Batch 200 Loss 1.4162 Accuracy 0.5297\n",
      "Epoch 5 Batch 250 Loss 1.4081 Accuracy 0.5325\n",
      "Epoch 5 Batch 300 Loss 1.4007 Accuracy 0.5348\n",
      "Epoch 5 Batch 0 Validation Loss 1.3007 Validation Accuracy 0.5655\n",
      "Epoch 5 Batch 50 Validation Loss 1.3053 Validation Accuracy 0.5652\n",
      "Epoch 5 Batch 100 Validation Loss 1.3017 Validation Accuracy 0.5663\n",
      "Epoch 5 Loss 1.3963 Accuracy 0.5363\n",
      "Time taken for 1 epoch: 65.43 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.3337 Accuracy 0.5495\n",
      "Epoch 6 Batch 50 Loss 1.3247 Accuracy 0.5592\n",
      "Epoch 6 Batch 100 Loss 1.3213 Accuracy 0.5607\n",
      "Epoch 6 Batch 150 Loss 1.3156 Accuracy 0.5623\n",
      "Epoch 6 Batch 200 Loss 1.3111 Accuracy 0.5640\n",
      "Epoch 6 Batch 250 Loss 1.3060 Accuracy 0.5658\n",
      "Epoch 6 Batch 300 Loss 1.2998 Accuracy 0.5678\n",
      "Epoch 6 Loss 1.2962 Accuracy 0.5691\n",
      "Time taken for 1 epoch: 50.01 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.2255 Accuracy 0.5807\n",
      "Epoch 7 Batch 50 Loss 1.2399 Accuracy 0.5865\n",
      "Epoch 7 Batch 100 Loss 1.2366 Accuracy 0.5875\n",
      "Epoch 7 Batch 150 Loss 1.2300 Accuracy 0.5898\n",
      "Epoch 7 Batch 200 Loss 1.2260 Accuracy 0.5915\n",
      "Epoch 7 Batch 250 Loss 1.2227 Accuracy 0.5926\n",
      "Epoch 7 Batch 300 Loss 1.2191 Accuracy 0.5939\n",
      "Epoch 7 Loss 1.2169 Accuracy 0.5946\n",
      "Time taken for 1 epoch: 50.76 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.2080 Accuracy 0.6091\n",
      "Epoch 8 Batch 50 Loss 1.1668 Accuracy 0.6126\n",
      "Epoch 8 Batch 100 Loss 1.1669 Accuracy 0.6119\n",
      "Epoch 8 Batch 150 Loss 1.1638 Accuracy 0.6122\n",
      "Epoch 8 Batch 200 Loss 1.1614 Accuracy 0.6130\n",
      "Epoch 8 Batch 250 Loss 1.1582 Accuracy 0.6140\n",
      "Epoch 8 Batch 300 Loss 1.1557 Accuracy 0.6146\n",
      "Epoch 8 Loss 1.1534 Accuracy 0.6153\n",
      "Time taken for 1 epoch: 50.66 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1370 Accuracy 0.6159\n",
      "Epoch 9 Batch 50 Loss 1.1133 Accuracy 0.6280\n",
      "Epoch 9 Batch 100 Loss 1.1100 Accuracy 0.6290\n",
      "Epoch 9 Batch 150 Loss 1.1099 Accuracy 0.6287\n",
      "Epoch 9 Batch 200 Loss 1.1077 Accuracy 0.6296\n",
      "Epoch 9 Batch 250 Loss 1.1061 Accuracy 0.6302\n",
      "Epoch 9 Batch 300 Loss 1.1040 Accuracy 0.6310\n",
      "Epoch 9 Loss 1.1027 Accuracy 0.6315\n",
      "Time taken for 1 epoch: 50.87 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.0752 Accuracy 0.6426\n",
      "Epoch 10 Batch 50 Loss 1.0660 Accuracy 0.6420\n",
      "Epoch 10 Batch 100 Loss 1.0664 Accuracy 0.6421\n",
      "Epoch 10 Batch 150 Loss 1.0653 Accuracy 0.6427\n",
      "Epoch 10 Batch 200 Loss 1.0644 Accuracy 0.6432\n",
      "Epoch 10 Batch 250 Loss 1.0635 Accuracy 0.6436\n",
      "Epoch 10 Batch 300 Loss 1.0615 Accuracy 0.6444\n",
      "Epoch 10 Batch 0 Validation Loss 1.0390 Validation Accuracy 0.6558\n",
      "Epoch 10 Batch 50 Validation Loss 1.0309 Validation Accuracy 0.6560\n",
      "Epoch 10 Batch 100 Validation Loss 1.0305 Validation Accuracy 0.6557\n",
      "Epoch 10 Loss 1.0602 Accuracy 0.6448\n",
      "Time taken for 1 epoch: 66.04 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.0378 Accuracy 0.6570\n",
      "Epoch 11 Batch 50 Loss 1.0237 Accuracy 0.6557\n",
      "Epoch 11 Batch 100 Loss 1.0240 Accuracy 0.6556\n",
      "Epoch 11 Batch 150 Loss 1.0249 Accuracy 0.6557\n",
      "Epoch 11 Batch 200 Loss 1.0253 Accuracy 0.6556\n",
      "Epoch 11 Batch 250 Loss 1.0246 Accuracy 0.6561\n",
      "Epoch 11 Batch 300 Loss 1.0215 Accuracy 0.6573\n",
      "Epoch 11 Loss 1.0196 Accuracy 0.6580\n",
      "Time taken for 1 epoch: 50.20 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.9743 Accuracy 0.6745\n",
      "Epoch 12 Batch 50 Loss 0.9720 Accuracy 0.6742\n",
      "Epoch 12 Batch 100 Loss 0.9678 Accuracy 0.6755\n",
      "Epoch 12 Batch 150 Loss 0.9657 Accuracy 0.6760\n",
      "Epoch 12 Batch 200 Loss 0.9638 Accuracy 0.6766\n"
     ]
    }
   ],
   "source": [
    "start_symbol = target_tokenizer.word_index[\"<GO>\"]\n",
    "stop_symbol = target_tokenizer.word_index[\"<EOV>\"]\n",
    "\n",
    "# Input for generation\n",
    "encoder_input = [input_text[0]]\n",
    "decoder_input = [target_text_tercet[0]]\n",
    "\n",
    "\n",
    "def sweep():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        dataset = make_dataset(input_train, target_train, batch_size=config[\"batch_size\"])\n",
    "        validation_dataset = make_dataset(input_val, target_val, batch_size=config[\"batch_size\"])\n",
    "        model, trainer = make_transformer_model(config, input_vocab_size, target_vocab_size, checkpoint_save_path=None)\n",
    "        trainer.train(dataset, config[\"epochs\"], log_wandb=True, validation_dataset=validation_dataset, validation_every=5)\n",
    "\n",
    "        result = generate(model, encoder_input, decoder_input, input_tokenizer, target_tokenizer, 27, start_symbol, stop_symbol)\n",
    "        result = strip_tokens(result)\n",
    "        result = '<br>'.join(result.split('\\n'))\n",
    "        wandb.log({\"generated\": wandb.Html(\"<pre>\"+result+\"</pre>\", inject=False)})\n",
    "        \n",
    "wandb.agent(sweep_id, function=sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PLTOETK4_m6"
   },
   "source": [
    "## 3. Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6v2e1bIcLRZi"
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(input_train, target_train)\n",
    "val_dataset = make_dataset(input_val, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-sGOf__BLZzQ"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_layers\" : 6,\n",
    "    \"d_model\" : 256,\n",
    "    \"num_heads\" : 4,\n",
    "    \"dff\" : 512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "miEcmOVmL0Rt"
   },
   "outputs": [],
   "source": [
    "transformer, transformer_trainer = make_transformer_model(config, input_vocab_size, target_vocab_size, checkpoint_save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QaR03YUNL_uF",
    "outputId": "2ef63442-189b-400a-d35c-bbfb0f062a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.4091 Accuracy 0.0008\n",
      "Epoch 1 Batch 50 Loss 4.2407 Accuracy 0.1238\n",
      "Epoch 1 Batch 100 Loss 3.6921 Accuracy 0.1638\n",
      "Epoch 1 Batch 150 Loss 3.4692 Accuracy 0.1800\n",
      "Epoch 1 Batch 200 Loss 3.2968 Accuracy 0.1976\n",
      "Epoch 1 Batch 250 Loss 3.1047 Accuracy 0.2225\n",
      "Epoch 1 Batch 300 Loss 2.9436 Accuracy 0.2433\n",
      "Epoch 1 Batch 0 Validation Loss 1.9496 Validation Accuracy 0.3826\n",
      "Epoch 1 Batch 50 Validation Loss 1.9754 Validation Accuracy 0.3752\n",
      "Epoch 1 Batch 100 Validation Loss 1.9726 Validation Accuracy 0.3754\n",
      "Epoch 1 Loss 2.8584 Accuracy 0.2542\n",
      "Time taken for 1 epoch: 96.52 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0470 Accuracy 0.3592\n",
      "Epoch 2 Batch 50 Loss 2.0151 Accuracy 0.3640\n",
      "Epoch 2 Batch 100 Loss 1.9988 Accuracy 0.3661\n",
      "Epoch 2 Batch 150 Loss 1.9869 Accuracy 0.3678\n",
      "Epoch 2 Batch 200 Loss 1.9747 Accuracy 0.3702\n",
      "Epoch 2 Batch 250 Loss 1.9627 Accuracy 0.3725\n",
      "Epoch 2 Batch 300 Loss 1.9501 Accuracy 0.3754\n",
      "Epoch 2 Batch 0 Validation Loss 1.8128 Validation Accuracy 0.4117\n",
      "Epoch 2 Batch 50 Validation Loss 1.7987 Validation Accuracy 0.4138\n",
      "Epoch 2 Batch 100 Validation Loss 1.7986 Validation Accuracy 0.4144\n",
      "Epoch 2 Loss 1.9414 Accuracy 0.3776\n",
      "Time taken for 1 epoch: 86.19 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8552 Accuracy 0.3988\n",
      "Epoch 3 Batch 50 Loss 1.8324 Accuracy 0.4043\n",
      "Epoch 3 Batch 100 Loss 1.8106 Accuracy 0.4100\n",
      "Epoch 3 Batch 150 Loss 1.7936 Accuracy 0.4142\n",
      "Epoch 3 Batch 200 Loss 1.7758 Accuracy 0.4191\n",
      "Epoch 3 Batch 250 Loss 1.7585 Accuracy 0.4241\n",
      "Epoch 3 Batch 300 Loss 1.7427 Accuracy 0.4286\n",
      "Epoch 3 Batch 0 Validation Loss 1.5741 Validation Accuracy 0.4841\n",
      "Epoch 3 Batch 50 Validation Loss 1.5734 Validation Accuracy 0.4806\n",
      "Epoch 3 Batch 100 Validation Loss 1.5729 Validation Accuracy 0.4806\n",
      "Epoch 3 Loss 1.7323 Accuracy 0.4317\n",
      "Time taken for 1 epoch: 85.97 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.6177 Accuracy 0.4642\n",
      "Epoch 4 Batch 50 Loss 1.6161 Accuracy 0.4670\n",
      "Epoch 4 Batch 100 Loss 1.6054 Accuracy 0.4720\n",
      "Epoch 4 Batch 150 Loss 1.5949 Accuracy 0.4750\n",
      "Epoch 4 Batch 200 Loss 1.5842 Accuracy 0.4781\n",
      "Epoch 4 Batch 250 Loss 1.5742 Accuracy 0.4811\n",
      "Epoch 4 Batch 300 Loss 1.5638 Accuracy 0.4842\n",
      "Epoch 4 Batch 0 Validation Loss 1.4406 Validation Accuracy 0.5180\n",
      "Epoch 4 Batch 50 Validation Loss 1.4323 Validation Accuracy 0.5234\n",
      "Epoch 4 Batch 100 Validation Loss 1.4345 Validation Accuracy 0.5224\n",
      "Epoch 4 Loss 1.5571 Accuracy 0.4863\n",
      "Time taken for 1 epoch: 86.16 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4798 Accuracy 0.5075\n",
      "Epoch 5 Batch 50 Loss 1.4758 Accuracy 0.5110\n",
      "Epoch 5 Batch 100 Loss 1.4679 Accuracy 0.5128\n",
      "Epoch 5 Batch 150 Loss 1.4606 Accuracy 0.5156\n",
      "Epoch 5 Batch 200 Loss 1.4518 Accuracy 0.5185\n",
      "Epoch 5 Batch 250 Loss 1.4450 Accuracy 0.5207\n",
      "Epoch 5 Batch 300 Loss 1.4384 Accuracy 0.5226\n",
      "Epoch 5 Batch 0 Validation Loss 1.3223 Validation Accuracy 0.5541\n",
      "Epoch 5 Batch 50 Validation Loss 1.3285 Validation Accuracy 0.5583\n",
      "Epoch 5 Batch 100 Validation Loss 1.3288 Validation Accuracy 0.5577\n",
      "Epoch 5 Loss 1.4345 Accuracy 0.5239\n",
      "Time taken for 1 epoch: 86.09 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.3859 Accuracy 0.5458\n",
      "Epoch 6 Batch 50 Loss 1.3742 Accuracy 0.5438\n",
      "Epoch 6 Batch 100 Loss 1.3687 Accuracy 0.5456\n",
      "Epoch 6 Batch 150 Loss 1.3616 Accuracy 0.5479\n",
      "Epoch 6 Batch 200 Loss 1.3547 Accuracy 0.5504\n",
      "Epoch 6 Batch 250 Loss 1.3490 Accuracy 0.5522\n",
      "Epoch 6 Batch 300 Loss 1.3425 Accuracy 0.5545\n",
      "Epoch 6 Batch 0 Validation Loss 1.2629 Validation Accuracy 0.5759\n",
      "Epoch 6 Batch 50 Validation Loss 1.2542 Validation Accuracy 0.5820\n",
      "Epoch 6 Batch 100 Validation Loss 1.2539 Validation Accuracy 0.5823\n",
      "Epoch 6 Loss 1.3381 Accuracy 0.5559\n",
      "Time taken for 1 epoch: 85.90 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.2719 Accuracy 0.5758\n",
      "Epoch 7 Batch 50 Loss 1.2825 Accuracy 0.5739\n",
      "Epoch 7 Batch 100 Loss 1.2796 Accuracy 0.5754\n",
      "Epoch 7 Batch 150 Loss 1.2749 Accuracy 0.5771\n",
      "Epoch 7 Batch 200 Loss 1.2692 Accuracy 0.5787\n",
      "Epoch 7 Batch 250 Loss 1.2639 Accuracy 0.5804\n",
      "Epoch 7 Batch 300 Loss 1.2589 Accuracy 0.5821\n",
      "Epoch 7 Batch 0 Validation Loss 1.1565 Validation Accuracy 0.6212\n",
      "Epoch 7 Batch 50 Validation Loss 1.1794 Validation Accuracy 0.6084\n",
      "Epoch 7 Batch 100 Validation Loss 1.1802 Validation Accuracy 0.6077\n",
      "Epoch 7 Loss 1.2561 Accuracy 0.5830\n",
      "Time taken for 1 epoch: 86.10 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.2217 Accuracy 0.5898\n",
      "Epoch 8 Batch 50 Loss 1.2074 Accuracy 0.5982\n",
      "Epoch 8 Batch 100 Loss 1.2060 Accuracy 0.5989\n",
      "Epoch 8 Batch 150 Loss 1.2037 Accuracy 0.5997\n",
      "Epoch 8 Batch 200 Loss 1.1998 Accuracy 0.6011\n",
      "Epoch 8 Batch 250 Loss 1.1956 Accuracy 0.6025\n",
      "Epoch 8 Batch 300 Loss 1.1930 Accuracy 0.6035\n",
      "Epoch 8 Batch 0 Validation Loss 1.1242 Validation Accuracy 0.6255\n",
      "Epoch 8 Batch 50 Validation Loss 1.1260 Validation Accuracy 0.6256\n",
      "Epoch 8 Batch 100 Validation Loss 1.1280 Validation Accuracy 0.6245\n",
      "Epoch 8 Loss 1.1916 Accuracy 0.6040\n",
      "Time taken for 1 epoch: 86.41 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1201 Accuracy 0.6320\n",
      "Epoch 9 Batch 50 Loss 1.1485 Accuracy 0.6181\n",
      "Epoch 9 Batch 100 Loss 1.1478 Accuracy 0.6182\n",
      "Epoch 9 Batch 150 Loss 1.1475 Accuracy 0.6184\n",
      "Epoch 9 Batch 200 Loss 1.1455 Accuracy 0.6188\n",
      "Epoch 9 Batch 250 Loss 1.1437 Accuracy 0.6195\n",
      "Epoch 9 Batch 300 Loss 1.1415 Accuracy 0.6201\n",
      "Epoch 9 Batch 0 Validation Loss 1.0852 Validation Accuracy 0.6369\n",
      "Epoch 9 Batch 50 Validation Loss 1.0899 Validation Accuracy 0.6378\n",
      "Epoch 9 Batch 100 Validation Loss 1.0858 Validation Accuracy 0.6386\n",
      "Epoch 9 Loss 1.1404 Accuracy 0.6205\n",
      "Time taken for 1 epoch: 85.89 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.0945 Accuracy 0.6348\n",
      "Epoch 10 Batch 50 Loss 1.1054 Accuracy 0.6307\n",
      "Epoch 10 Batch 100 Loss 1.1057 Accuracy 0.6306\n",
      "Epoch 10 Batch 150 Loss 1.1056 Accuracy 0.6306\n",
      "Epoch 10 Batch 200 Loss 1.1039 Accuracy 0.6313\n",
      "Epoch 10 Batch 250 Loss 1.1025 Accuracy 0.6319\n",
      "Epoch 10 Batch 300 Loss 1.1010 Accuracy 0.6323\n",
      "Epoch 10 Batch 0 Validation Loss 1.0533 Validation Accuracy 0.6494\n",
      "Epoch 10 Batch 50 Validation Loss 1.0601 Validation Accuracy 0.6451\n",
      "Epoch 10 Batch 100 Validation Loss 1.0642 Validation Accuracy 0.6441\n",
      "Epoch 10 Loss 1.0996 Accuracy 0.6328\n",
      "Time taken for 1 epoch: 86.49 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.0455 Accuracy 0.6507\n",
      "Epoch 11 Batch 50 Loss 1.0706 Accuracy 0.6415\n",
      "Epoch 11 Batch 100 Loss 1.0688 Accuracy 0.6419\n",
      "Epoch 11 Batch 150 Loss 1.0696 Accuracy 0.6419\n",
      "Epoch 11 Batch 200 Loss 1.0691 Accuracy 0.6418\n",
      "Epoch 11 Batch 250 Loss 1.0680 Accuracy 0.6423\n",
      "Epoch 11 Batch 300 Loss 1.0677 Accuracy 0.6424\n",
      "Epoch 11 Batch 0 Validation Loss 1.0090 Validation Accuracy 0.6556\n",
      "Epoch 11 Batch 50 Validation Loss 1.0311 Validation Accuracy 0.6538\n",
      "Epoch 11 Batch 100 Validation Loss 1.0287 Validation Accuracy 0.6545\n",
      "Epoch 11 Loss 1.0673 Accuracy 0.6427\n",
      "Time taken for 1 epoch: 86.40 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.0136 Accuracy 0.6597\n",
      "Epoch 12 Batch 50 Loss 1.0379 Accuracy 0.6517\n",
      "Epoch 12 Batch 100 Loss 1.0405 Accuracy 0.6510\n",
      "Epoch 12 Batch 150 Loss 1.0415 Accuracy 0.6508\n",
      "Epoch 12 Batch 200 Loss 1.0413 Accuracy 0.6511\n",
      "Epoch 12 Batch 250 Loss 1.0398 Accuracy 0.6514\n",
      "Epoch 12 Batch 300 Loss 1.0396 Accuracy 0.6515\n",
      "Epoch 12 Batch 0 Validation Loss 1.0035 Validation Accuracy 0.6535\n",
      "Epoch 12 Batch 50 Validation Loss 1.0118 Validation Accuracy 0.6608\n",
      "Epoch 12 Batch 100 Validation Loss 1.0123 Validation Accuracy 0.6610\n",
      "Epoch 12 Loss 1.0399 Accuracy 0.6514\n",
      "Time taken for 1 epoch: 86.27 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.0448 Accuracy 0.6523\n",
      "Epoch 13 Batch 50 Loss 1.0167 Accuracy 0.6593\n",
      "Epoch 13 Batch 100 Loss 1.0147 Accuracy 0.6598\n",
      "Epoch 13 Batch 150 Loss 1.0150 Accuracy 0.6594\n",
      "Epoch 13 Batch 200 Loss 1.0140 Accuracy 0.6598\n",
      "Epoch 13 Batch 250 Loss 1.0131 Accuracy 0.6600\n",
      "Epoch 13 Batch 300 Loss 1.0125 Accuracy 0.6601\n",
      "Epoch 13 Batch 0 Validation Loss 0.9784 Validation Accuracy 0.6660\n",
      "Epoch 13 Batch 50 Validation Loss 0.9805 Validation Accuracy 0.6702\n",
      "Epoch 13 Batch 100 Validation Loss 0.9782 Validation Accuracy 0.6712\n",
      "Epoch 13 Loss 1.0113 Accuracy 0.6605\n",
      "Time taken for 1 epoch: 86.13 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.9676 Accuracy 0.6689\n",
      "Epoch 14 Batch 50 Loss 0.9770 Accuracy 0.6713\n",
      "Epoch 14 Batch 100 Loss 0.9787 Accuracy 0.6705\n",
      "Epoch 14 Batch 150 Loss 0.9791 Accuracy 0.6704\n",
      "Epoch 14 Batch 200 Loss 0.9780 Accuracy 0.6709\n",
      "Epoch 14 Batch 250 Loss 0.9785 Accuracy 0.6706\n",
      "Epoch 14 Batch 300 Loss 0.9779 Accuracy 0.6709\n",
      "Epoch 14 Batch 0 Validation Loss 1.0210 Validation Accuracy 0.6610\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-88619704c870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, epochs, log_wandb, validation_dataset, validation_every)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidation_dataset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalidation_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mval_step\u001b[0;34m(self, inp, tar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         predictions, _ = self.transformer(\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    324\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         enc_output = self.encoder(\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         )  # (batch_size, inp_seq_len, d_model)\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/layers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/layers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4797\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4798\u001b[0m     \u001b[0ma_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4799\u001b[0;31m     \u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4800\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   4801\u001b[0m         b, b_axes, True)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_tensordot_reshape\u001b[0;34m(a, axes, flipped)\u001b[0m\n\u001b[1;32m   4724\u001b[0m         \u001b[0ma_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4725\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0ma_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4726\u001b[0;31m         \u001b[0mreshaped_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4727\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mreshaped_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_trans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8391\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8392\u001b[0m       return reshape_eager_fallback(\n\u001b[0;32m-> 8393\u001b[0;31m           tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8394\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8395\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8412\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreshape_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8413\u001b[0m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8414\u001b[0;31m   \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8415\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8416\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer_trainer.train(dataset, 30, validation_dataset=val_dataset, validation_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgDU7jfoe2UJ"
   },
   "source": [
    "## 4. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "gAvzChyle2UL"
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    transformer,\n",
    "    encoder_input,\n",
    "    decoder_input,\n",
    "    stop_symbol,\n",
    "    max_length=200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predicts the output of the model given the `input_sequence`.\n",
    "    The `input_sequence` is encoded by the Encoder, then its output is fed to the Decoder,\n",
    "    whose output is fed back into the Decoder until the `stop_symbol` token is produced.\n",
    "\n",
    "    This function works with a batch of inputs and stops when all outputs include a stop symbol.\n",
    "    \"\"\"\n",
    "\n",
    "    output = decoder_input\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output\n",
    "    )\n",
    "\n",
    "    enc_output = transformer.encoder(\n",
    "        encoder_input, False, enc_padding_mask\n",
    "    )  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output\n",
    "        )\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, _ = transformer.decoder(\n",
    "            output, enc_output, False, combined_mask, dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = transformer.final_layer(dec_output)\n",
    "\n",
    "        # select the last character from the seq_len dimension\n",
    "        predicted_ids = tf.argmax(predictions[:, -1:, :], axis=-1)\n",
    "\n",
    "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
    "        output = tf.concat(\n",
    "            [\n",
    "                tf.cast(output, dtype=tf.int32),\n",
    "                tf.cast(predicted_ids, dtype=tf.int32),\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "                \n",
    "        if sum(output.numpy()[0] == stop_symbol) == 4:\n",
    "            return output\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EXC7XrTle2UU"
   },
   "outputs": [],
   "source": [
    "def generate(transformer, input_sequence, target_sequence, input_tokenizer, target_tokenizer, steps, start_symbol, stop_symbol):\n",
    "\n",
    "    result = target_tokenizer.sequences_to_texts(target_sequence)[0]\n",
    "    \n",
    "    encoder_input = input_sequence\n",
    "    decoder_input = target_sequence\n",
    "\n",
    "    for _ in range(steps):\n",
    "\n",
    "        encoder_input = tf.convert_to_tensor(encoder_input)\n",
    "        decoder_input = tf.convert_to_tensor(decoder_input)\n",
    "        output = evaluate(transformer, encoder_input, decoder_input, stop_symbol)\n",
    "\n",
    "        generated_text = target_tokenizer.sequences_to_texts(output.numpy())[0]\n",
    "        \n",
    "        verses = [line.lstrip() + '<EOV> ' for line in generated_text.split('<EOV>') if line.strip() != '']\n",
    "        \n",
    "        result = ''.join([result, verses[-1]])\n",
    "                \n",
    "        verses = ''.join(verses[-3:])\n",
    "        \n",
    "        decoder_input = target_tokenizer.texts_to_sequences([verses])\n",
    "        \n",
    "        verses = remove_syll_token(verses)\n",
    "        verses = re.sub(r\"[ ]+\", \"\", verses)\n",
    "        verses = re.sub(\"<[^>]*>\", \" \\g<0> \", verses)\n",
    "        verses = re.sub(\"<EOV>  <GO>\", \"<EOV> <GO>\", verses)\n",
    "        verses = verses.strip()\n",
    "\n",
    "        encoder_input = input_tokenizer.texts_to_sequences([verses])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMSbfxwae2UW",
    "outputId": "a219af16-126e-4977-9a13-7a86dfb570bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "start_symbol = target_tokenizer.word_index[\"<GO>\"]\n",
    "stop_symbol = target_tokenizer.word_index[\"<EOV>\"]\n",
    "\n",
    "encoder_input = [input_text[0]]\n",
    "decoder_input = [target_text_tercet[0]]\n",
    "\n",
    "result = generate(transformer, encoder_input, decoder_input, input_tokenizer, target_tokenizer, 10, start_symbol, stop_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1uAYbYDe2UX",
    "outputId": "7ec8539e-c959-4cc0-d1c6-6da99b595617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Nel |mez|zo |del |cam|min |di |no|stra |vi|ta\n",
      "|mi |ri|tro|vai |per |u|na |sel|va o|scu|ra,\n",
      "|ché |la |di|rit|ta |via |e|ra |smar|ri|ta.\n",
      "|E |io |a |la |mia |di|stin|ta |di |so|pra\n",
      "|e |dis|si:« |Vien |che |son |di |so|pra |se|sta\n",
      "|la |mia |se|gui|ta |di |mia |se|gui|ta,\n",
      "|che |di |mil|le |mia |di |mi|se|ria |sciol|ta.\n",
      "|E |io |mi |fui |di |mil|le |di |mil|le |schia|mi\n",
      "|di |quel |che |di |mio |di |mil|le |si |mo|ve\n",
      "|di |mil|le |di |mil|le |di |mil|le |spi|ri.\n",
      "|E |io |dis|si:« |Vien |che |tu |di |mil|le |spal|le\n",
      "|di |quel |che |di |mio |di |mil|le |si |spi|ri\n",
      "|di |mil|le |di |mil|le |di |mil|le |spa|da,\n"
     ]
    }
   ],
   "source": [
    "print(strip_tokens(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5MorsDLe2UY"
   },
   "source": [
    "## 5. Syllabification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbBb0fLTe2UY"
   },
   "outputs": [],
   "source": [
    "start_symbol = target_tokenizer.word_index[\"<GO>\"]\n",
    "stop_symbol = target_tokenizer.word_index[\"<EOV>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huknwnsde2UZ"
   },
   "outputs": [],
   "source": [
    "encoder_input = tf.convert_to_tensor([input_text[0]])\n",
    "decoder_input = tf.convert_to_tensor([[start_symbol]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxTgAWrpe2Ua",
    "outputId": "a00ceade-6cc3-4ac2-8b12-4a51c5491143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "syll_output = evaluate(transformer, encoder_input, decoder_input, stop_symbol, max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDqwIrMee2Ua",
    "outputId": "ae315695-cdc1-4428-fdf9-83fbf8c13212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<GO> | c h e <SEP> | d i <SEP> | p e n | s i e r <SEP> | m i <SEP> | s t a | v a <SEP> i n <SEP> | u | n o <SEP> | s t r a | l e , <EOV> <GO> | e <SEP> | d i | c o <SEP> | d i <SEP> | g e n | t e <SEP> a l | t r o <SEP> | c h e <SEP> | p i ù <SEP> | d o l | c e » . <EOV> <GO> | N o i <SEP> | e | r a | v a m <SEP> | n e l <SEP> | s u o <SEP> | a | s p e t | t o <SEP> | b a n | d o <EOV> <GO> | c h e <SEP> | l ’ <SEP> a | n i | m a <SEP> | s u a <SEP> | a v | v e n | t a <SEP> | d i | s t a n | t e , <EOV>']\n"
     ]
    }
   ],
   "source": [
    "print(target_tokenizer.sequences_to_texts(syll_output.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXMfBSRTe2Ub"
   },
   "source": [
    "Potrebbe essere underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzPwlV9ae2Uc"
   },
   "source": [
    "## 6. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfTkQfWle2Uc"
   },
   "outputs": [],
   "source": [
    "transformer.save_weights('models/w2c-gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acIj_s75e2Ue"
   },
   "outputs": [],
   "source": [
    "new_transformer = Transformer(\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        d_model=config[\"d_model\"],\n",
    "        num_heads=config[\"num_heads\"],\n",
    "        dff=config[\"dff\"],\n",
    "        input_vocab_size=input_vocab_size,\n",
    "        target_vocab_size=target_vocab_size,\n",
    "        pe_input=1000,\n",
    "        pe_target=1000,\n",
    "        rate=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKj4qsd6e2Ue"
   },
   "outputs": [],
   "source": [
    "# In order to load the new weights the model should be called once for the variables to be initialized\n",
    "\n",
    "# Any inp, tar is ok here\n",
    "inp = tf.convert_to_tensor([[start_symbol]])\n",
    "tar = tf.convert_to_tensor([[start_symbol]])\n",
    "\n",
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "\n",
    "new_transformer(inp, tar, False, enc_padding_mask, look_ahead_mask, dec_padding_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9IMbvrte2Uf"
   },
   "outputs": [],
   "source": [
    "new_transformer.load_weights('models/w2c-gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEpPqSJRe2Uf",
    "outputId": "3d2f2647-6032-4194-cc94-cb2f286dbb39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "encoder_input = [input_text[0]]\n",
    "decoder_input = [target_text_tercet[0]]\n",
    "\n",
    "result = generate(new_transformer, encoder_input, decoder_input, input_tokenizer, target_tokenizer, 6, start_symbol, stop_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOZR_Zd6e2Ug",
    "outputId": "ede37c97-bd43-4d6c-886d-8cee47ab03e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<GO> | N e l <SEP> | m e z | z o <SEP> | d e l <SEP> | c a m | m i n <SEP> | d i <SEP> | n o | s t r a <SEP> | v i | t a <EOV> <GO> | m i <SEP> | r i | t r o | v a i <SEP> | p e r <SEP> | u | n a <SEP> | s e l | v a <SEP> o | s c u | r a , <EOV> <GO> | c h é <SEP> | l a <SEP> | d i | r i t | t a <SEP> | v i a <SEP> | e | r a <SEP> | s m a r | r i | t a . <EOV><GO> | E l | l a <SEP> | s o | p r a <SEP> | c h e <SEP> ’ l <SEP> | v i | s o <SEP> a <SEP> | q u e l | l a <SEP> | g e n | t e <EOV> <GO> | c h e <SEP> | p e r <SEP> | l o <SEP> | s u o <SEP> | a v | v e r | s a | r i o <SEP> a l | t r u i <SEP> | m a n | t o , <EOV> <GO> | e <SEP> | a l | t r a <SEP> | v o | c e <SEP> | m i <SEP> | p a | r e a <SEP> | p i ù <SEP> | r a t | t a . <EOV> <GO> « <SEP> | O <SEP> | t u <SEP> | c h e <SEP> | s e ’ <SEP> | c h e <SEP> | s ì <SEP> | p r e s | s o <SEP> | d i | s c i o l | t a » , <EOV> <GO> | d i s | s e <SEP> ’ l <SEP> | m a | e | s t r o , « <SEP> | q u a n | t o <SEP> | p o s | s o <SEP> | p o | c o , <EOV> <GO> | s e <SEP> | n o n <SEP> | c h e <SEP> | t u <SEP> | s e ’ <SEP> | t e m | p i o n <SEP> | f a r <SEP> | n o n <SEP> | l a | t i , <EOV> '"
      ]
     },
     "execution_count": 320,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TgDU7jfoe2UJ",
    "k5MorsDLe2UY"
   ],
   "name": "Word2Char transformer generation-WORKING.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
