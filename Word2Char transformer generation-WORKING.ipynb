{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SybxOt22fBmE",
    "outputId": "f3482536-c8cb-45a5-d8ee-3a4133c8faa1"
   },
   "outputs": [],
   "source": [
    "!pip install wandb strsimpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZFNtyeMfmnp",
    "outputId": "6e9f12ff-da81-4814-acce-3cc52c333438"
   },
   "outputs": [],
   "source": [
    "!tar zxvf deepcomedy.tar.gz\n",
    "!tar zxvf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YcDazsVbL_tS"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {},
    "id": "54j16swJY1dW"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from deepcomedy.models.transformer import *\n",
    "from deepcomedy.preprocessing import *\n",
    "from deepcomedy.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RuMqNB4ujuT",
    "tags": []
   },
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jH7n29oxB0z4"
   },
   "outputs": [],
   "source": [
    "raw_text = open(\"./data/divina_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
    "raw_syll_text = (\n",
    "    open(\"./data/divina_syll_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
    ")\n",
    "syll_text = preprocess_text(raw_syll_text, end_of_tercet='')\n",
    "text = preprocess_text(raw_text, end_of_tercet='', word_level= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ASHyaMBC84V"
   },
   "source": [
    "Split preprocessed text into verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-IF6sE6FC_4J"
   },
   "outputs": [],
   "source": [
    "sep = \"<EOV>\"\n",
    "input_tercets = [x.lstrip() + sep for x in text.split(sep)][:-1]\n",
    "target_tercets = [x.lstrip() + sep for x in syll_text.split(sep)][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdUmYhUKDEuj"
   },
   "source": [
    "Encode with input and target tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-mob1kOzDD4z"
   },
   "outputs": [],
   "source": [
    "input_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=False, filters=\"\", lower=False\n",
    ")\n",
    "input_tokenizer.fit_on_texts(input_tercets)\n",
    "\n",
    "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=False, filters=\"\", lower=False\n",
    ")\n",
    "target_tokenizer.fit_on_texts(target_tercets)\n",
    "\n",
    "enc_input_tercets = input_tokenizer.texts_to_sequences(input_tercets)\n",
    "enc_target_tercets = target_tokenizer.texts_to_sequences(target_tercets)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xDKv92yAL_t8"
   },
   "outputs": [],
   "source": [
    "input_text = []\n",
    "target_text = []\n",
    "target_text_tercet = []\n",
    "\n",
    "for line in range(len(enc_input_tercets) - 2):\n",
    "    input_text.append(list(chain(*enc_input_tercets[line : line + 3])))\n",
    "    target_text_tercet.append(list(chain(*enc_target_tercets[line : line + 3])))\n",
    "    target_text.append(list(chain(*enc_target_tercets[line : line + 4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY44HP5lKz2-"
   },
   "source": [
    "Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Pq34y57yK3wd"
   },
   "outputs": [],
   "source": [
    "padded_input_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    input_text, padding=\"post\"\n",
    ")\n",
    "padded_target_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    target_text, padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LdFUuDTcf0Mr"
   },
   "outputs": [],
   "source": [
    "input_train, input_val, target_train, target_val = train_test_split(padded_input_text, padded_target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GVc41zvvdR9"
   },
   "source": [
    "## 2. Create model and datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6v2e1bIcLRZi"
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(input_train, target_train)\n",
    "val_dataset = make_dataset(input_val, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-sGOf__BLZzQ"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_layers\" : 6,\n",
    "    \"d_model\" : 256,\n",
    "    \"num_heads\" : 4,\n",
    "    \"dff\" : 512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "miEcmOVmL0Rt"
   },
   "outputs": [],
   "source": [
    "transformer, transformer_trainer = make_transformer_model(config, input_vocab_size, target_vocab_size, checkpoint_save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYBcAQRsr4zX"
   },
   "source": [
    "## 3. Hyperparameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OnTScmSr7-z",
    "outputId": "1bd59626-9a78-402d-9e1c-f5390280e574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 9tpf0l8k\n",
      "Sweep URL: https://wandb.ai/deepcomedy/deepcomedy/sweeps/9tpf0l8k\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"sweep-test-1\",\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"value\": 32},\n",
    "        \"epochs\": {\"value\": 30},\n",
    "        \"num_layers\": {\"values\": [4, 8, 12]},\n",
    "        \"num_heads\": {\"values\": [4, 8]},\n",
    "        \"d_model\": {\"value\": 256},\n",
    "        \"dff\": {\"value\": 1024},\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='deepcomedy', entity='deepcomedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "uXhx10XysCwB",
    "outputId": "585399be-6080-407d-de51-c0e73c8b9744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p5bfkk4q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdff: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malessandropacielli\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/alessandro/Desktop/DL/deepcomedy/.venv/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vague-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/sweeps/9tpf0l8k\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/sweeps/9tpf0l8k</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/deepcomedy/deepcomedy/runs/p5bfkk4q\" target=\"_blank\">https://wandb.ai/deepcomedy/deepcomedy/runs/p5bfkk4q</a><br/>\n",
       "                Run data is saved locally in <code>/home/alessandro/Desktop/DL/deepcomedy/wandb/run-20210528_180919-p5bfkk4q</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Epoch 1 Batch 0 Loss 5.6970 Accuracy 0.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "def sweep():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        print('OK')\n",
    "        dataset = make_dataset(input_train, target_train, batch_size=config[\"batch_size\"])\n",
    "        validation_dataset = make_dataset(input_val, target_val, batch_size=config[\"batch_size\"])\n",
    "        model, trainer = make_transformer_model(config, input_vocab_size, target_vocab_size, checkpoint_save_path=None)\n",
    "        trainer.train(dataset, config[\"epochs\"], log_wandb=True, validation_dataset=validation_dataset, validation_every=1)\n",
    "\n",
    "wandb.agent(sweep_id, function=sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PLTOETK4_m6"
   },
   "source": [
    "## 3. Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QaR03YUNL_uF",
    "outputId": "2ef63442-189b-400a-d35c-bbfb0f062a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.4091 Accuracy 0.0008\n",
      "Epoch 1 Batch 50 Loss 4.2407 Accuracy 0.1238\n",
      "Epoch 1 Batch 100 Loss 3.6921 Accuracy 0.1638\n",
      "Epoch 1 Batch 150 Loss 3.4692 Accuracy 0.1800\n",
      "Epoch 1 Batch 200 Loss 3.2968 Accuracy 0.1976\n",
      "Epoch 1 Batch 250 Loss 3.1047 Accuracy 0.2225\n",
      "Epoch 1 Batch 300 Loss 2.9436 Accuracy 0.2433\n",
      "Epoch 1 Batch 0 Validation Loss 1.9496 Validation Accuracy 0.3826\n",
      "Epoch 1 Batch 50 Validation Loss 1.9754 Validation Accuracy 0.3752\n",
      "Epoch 1 Batch 100 Validation Loss 1.9726 Validation Accuracy 0.3754\n",
      "Epoch 1 Loss 2.8584 Accuracy 0.2542\n",
      "Time taken for 1 epoch: 96.52 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0470 Accuracy 0.3592\n",
      "Epoch 2 Batch 50 Loss 2.0151 Accuracy 0.3640\n",
      "Epoch 2 Batch 100 Loss 1.9988 Accuracy 0.3661\n",
      "Epoch 2 Batch 150 Loss 1.9869 Accuracy 0.3678\n",
      "Epoch 2 Batch 200 Loss 1.9747 Accuracy 0.3702\n",
      "Epoch 2 Batch 250 Loss 1.9627 Accuracy 0.3725\n",
      "Epoch 2 Batch 300 Loss 1.9501 Accuracy 0.3754\n",
      "Epoch 2 Batch 0 Validation Loss 1.8128 Validation Accuracy 0.4117\n",
      "Epoch 2 Batch 50 Validation Loss 1.7987 Validation Accuracy 0.4138\n",
      "Epoch 2 Batch 100 Validation Loss 1.7986 Validation Accuracy 0.4144\n",
      "Epoch 2 Loss 1.9414 Accuracy 0.3776\n",
      "Time taken for 1 epoch: 86.19 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8552 Accuracy 0.3988\n",
      "Epoch 3 Batch 50 Loss 1.8324 Accuracy 0.4043\n",
      "Epoch 3 Batch 100 Loss 1.8106 Accuracy 0.4100\n",
      "Epoch 3 Batch 150 Loss 1.7936 Accuracy 0.4142\n",
      "Epoch 3 Batch 200 Loss 1.7758 Accuracy 0.4191\n",
      "Epoch 3 Batch 250 Loss 1.7585 Accuracy 0.4241\n",
      "Epoch 3 Batch 300 Loss 1.7427 Accuracy 0.4286\n",
      "Epoch 3 Batch 0 Validation Loss 1.5741 Validation Accuracy 0.4841\n",
      "Epoch 3 Batch 50 Validation Loss 1.5734 Validation Accuracy 0.4806\n",
      "Epoch 3 Batch 100 Validation Loss 1.5729 Validation Accuracy 0.4806\n",
      "Epoch 3 Loss 1.7323 Accuracy 0.4317\n",
      "Time taken for 1 epoch: 85.97 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.6177 Accuracy 0.4642\n",
      "Epoch 4 Batch 50 Loss 1.6161 Accuracy 0.4670\n",
      "Epoch 4 Batch 100 Loss 1.6054 Accuracy 0.4720\n",
      "Epoch 4 Batch 150 Loss 1.5949 Accuracy 0.4750\n",
      "Epoch 4 Batch 200 Loss 1.5842 Accuracy 0.4781\n",
      "Epoch 4 Batch 250 Loss 1.5742 Accuracy 0.4811\n",
      "Epoch 4 Batch 300 Loss 1.5638 Accuracy 0.4842\n",
      "Epoch 4 Batch 0 Validation Loss 1.4406 Validation Accuracy 0.5180\n",
      "Epoch 4 Batch 50 Validation Loss 1.4323 Validation Accuracy 0.5234\n",
      "Epoch 4 Batch 100 Validation Loss 1.4345 Validation Accuracy 0.5224\n",
      "Epoch 4 Loss 1.5571 Accuracy 0.4863\n",
      "Time taken for 1 epoch: 86.16 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4798 Accuracy 0.5075\n",
      "Epoch 5 Batch 50 Loss 1.4758 Accuracy 0.5110\n",
      "Epoch 5 Batch 100 Loss 1.4679 Accuracy 0.5128\n",
      "Epoch 5 Batch 150 Loss 1.4606 Accuracy 0.5156\n",
      "Epoch 5 Batch 200 Loss 1.4518 Accuracy 0.5185\n",
      "Epoch 5 Batch 250 Loss 1.4450 Accuracy 0.5207\n",
      "Epoch 5 Batch 300 Loss 1.4384 Accuracy 0.5226\n",
      "Epoch 5 Batch 0 Validation Loss 1.3223 Validation Accuracy 0.5541\n",
      "Epoch 5 Batch 50 Validation Loss 1.3285 Validation Accuracy 0.5583\n",
      "Epoch 5 Batch 100 Validation Loss 1.3288 Validation Accuracy 0.5577\n",
      "Epoch 5 Loss 1.4345 Accuracy 0.5239\n",
      "Time taken for 1 epoch: 86.09 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.3859 Accuracy 0.5458\n",
      "Epoch 6 Batch 50 Loss 1.3742 Accuracy 0.5438\n",
      "Epoch 6 Batch 100 Loss 1.3687 Accuracy 0.5456\n",
      "Epoch 6 Batch 150 Loss 1.3616 Accuracy 0.5479\n",
      "Epoch 6 Batch 200 Loss 1.3547 Accuracy 0.5504\n",
      "Epoch 6 Batch 250 Loss 1.3490 Accuracy 0.5522\n",
      "Epoch 6 Batch 300 Loss 1.3425 Accuracy 0.5545\n",
      "Epoch 6 Batch 0 Validation Loss 1.2629 Validation Accuracy 0.5759\n",
      "Epoch 6 Batch 50 Validation Loss 1.2542 Validation Accuracy 0.5820\n",
      "Epoch 6 Batch 100 Validation Loss 1.2539 Validation Accuracy 0.5823\n",
      "Epoch 6 Loss 1.3381 Accuracy 0.5559\n",
      "Time taken for 1 epoch: 85.90 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.2719 Accuracy 0.5758\n",
      "Epoch 7 Batch 50 Loss 1.2825 Accuracy 0.5739\n",
      "Epoch 7 Batch 100 Loss 1.2796 Accuracy 0.5754\n",
      "Epoch 7 Batch 150 Loss 1.2749 Accuracy 0.5771\n",
      "Epoch 7 Batch 200 Loss 1.2692 Accuracy 0.5787\n",
      "Epoch 7 Batch 250 Loss 1.2639 Accuracy 0.5804\n",
      "Epoch 7 Batch 300 Loss 1.2589 Accuracy 0.5821\n",
      "Epoch 7 Batch 0 Validation Loss 1.1565 Validation Accuracy 0.6212\n",
      "Epoch 7 Batch 50 Validation Loss 1.1794 Validation Accuracy 0.6084\n",
      "Epoch 7 Batch 100 Validation Loss 1.1802 Validation Accuracy 0.6077\n",
      "Epoch 7 Loss 1.2561 Accuracy 0.5830\n",
      "Time taken for 1 epoch: 86.10 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.2217 Accuracy 0.5898\n",
      "Epoch 8 Batch 50 Loss 1.2074 Accuracy 0.5982\n",
      "Epoch 8 Batch 100 Loss 1.2060 Accuracy 0.5989\n",
      "Epoch 8 Batch 150 Loss 1.2037 Accuracy 0.5997\n",
      "Epoch 8 Batch 200 Loss 1.1998 Accuracy 0.6011\n",
      "Epoch 8 Batch 250 Loss 1.1956 Accuracy 0.6025\n",
      "Epoch 8 Batch 300 Loss 1.1930 Accuracy 0.6035\n",
      "Epoch 8 Batch 0 Validation Loss 1.1242 Validation Accuracy 0.6255\n",
      "Epoch 8 Batch 50 Validation Loss 1.1260 Validation Accuracy 0.6256\n",
      "Epoch 8 Batch 100 Validation Loss 1.1280 Validation Accuracy 0.6245\n",
      "Epoch 8 Loss 1.1916 Accuracy 0.6040\n",
      "Time taken for 1 epoch: 86.41 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1201 Accuracy 0.6320\n",
      "Epoch 9 Batch 50 Loss 1.1485 Accuracy 0.6181\n",
      "Epoch 9 Batch 100 Loss 1.1478 Accuracy 0.6182\n",
      "Epoch 9 Batch 150 Loss 1.1475 Accuracy 0.6184\n",
      "Epoch 9 Batch 200 Loss 1.1455 Accuracy 0.6188\n",
      "Epoch 9 Batch 250 Loss 1.1437 Accuracy 0.6195\n",
      "Epoch 9 Batch 300 Loss 1.1415 Accuracy 0.6201\n",
      "Epoch 9 Batch 0 Validation Loss 1.0852 Validation Accuracy 0.6369\n",
      "Epoch 9 Batch 50 Validation Loss 1.0899 Validation Accuracy 0.6378\n",
      "Epoch 9 Batch 100 Validation Loss 1.0858 Validation Accuracy 0.6386\n",
      "Epoch 9 Loss 1.1404 Accuracy 0.6205\n",
      "Time taken for 1 epoch: 85.89 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.0945 Accuracy 0.6348\n",
      "Epoch 10 Batch 50 Loss 1.1054 Accuracy 0.6307\n",
      "Epoch 10 Batch 100 Loss 1.1057 Accuracy 0.6306\n",
      "Epoch 10 Batch 150 Loss 1.1056 Accuracy 0.6306\n",
      "Epoch 10 Batch 200 Loss 1.1039 Accuracy 0.6313\n",
      "Epoch 10 Batch 250 Loss 1.1025 Accuracy 0.6319\n",
      "Epoch 10 Batch 300 Loss 1.1010 Accuracy 0.6323\n",
      "Epoch 10 Batch 0 Validation Loss 1.0533 Validation Accuracy 0.6494\n",
      "Epoch 10 Batch 50 Validation Loss 1.0601 Validation Accuracy 0.6451\n",
      "Epoch 10 Batch 100 Validation Loss 1.0642 Validation Accuracy 0.6441\n",
      "Epoch 10 Loss 1.0996 Accuracy 0.6328\n",
      "Time taken for 1 epoch: 86.49 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.0455 Accuracy 0.6507\n",
      "Epoch 11 Batch 50 Loss 1.0706 Accuracy 0.6415\n",
      "Epoch 11 Batch 100 Loss 1.0688 Accuracy 0.6419\n",
      "Epoch 11 Batch 150 Loss 1.0696 Accuracy 0.6419\n",
      "Epoch 11 Batch 200 Loss 1.0691 Accuracy 0.6418\n",
      "Epoch 11 Batch 250 Loss 1.0680 Accuracy 0.6423\n",
      "Epoch 11 Batch 300 Loss 1.0677 Accuracy 0.6424\n",
      "Epoch 11 Batch 0 Validation Loss 1.0090 Validation Accuracy 0.6556\n",
      "Epoch 11 Batch 50 Validation Loss 1.0311 Validation Accuracy 0.6538\n",
      "Epoch 11 Batch 100 Validation Loss 1.0287 Validation Accuracy 0.6545\n",
      "Epoch 11 Loss 1.0673 Accuracy 0.6427\n",
      "Time taken for 1 epoch: 86.40 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.0136 Accuracy 0.6597\n",
      "Epoch 12 Batch 50 Loss 1.0379 Accuracy 0.6517\n",
      "Epoch 12 Batch 100 Loss 1.0405 Accuracy 0.6510\n",
      "Epoch 12 Batch 150 Loss 1.0415 Accuracy 0.6508\n",
      "Epoch 12 Batch 200 Loss 1.0413 Accuracy 0.6511\n",
      "Epoch 12 Batch 250 Loss 1.0398 Accuracy 0.6514\n",
      "Epoch 12 Batch 300 Loss 1.0396 Accuracy 0.6515\n",
      "Epoch 12 Batch 0 Validation Loss 1.0035 Validation Accuracy 0.6535\n",
      "Epoch 12 Batch 50 Validation Loss 1.0118 Validation Accuracy 0.6608\n",
      "Epoch 12 Batch 100 Validation Loss 1.0123 Validation Accuracy 0.6610\n",
      "Epoch 12 Loss 1.0399 Accuracy 0.6514\n",
      "Time taken for 1 epoch: 86.27 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.0448 Accuracy 0.6523\n",
      "Epoch 13 Batch 50 Loss 1.0167 Accuracy 0.6593\n",
      "Epoch 13 Batch 100 Loss 1.0147 Accuracy 0.6598\n",
      "Epoch 13 Batch 150 Loss 1.0150 Accuracy 0.6594\n",
      "Epoch 13 Batch 200 Loss 1.0140 Accuracy 0.6598\n",
      "Epoch 13 Batch 250 Loss 1.0131 Accuracy 0.6600\n",
      "Epoch 13 Batch 300 Loss 1.0125 Accuracy 0.6601\n",
      "Epoch 13 Batch 0 Validation Loss 0.9784 Validation Accuracy 0.6660\n",
      "Epoch 13 Batch 50 Validation Loss 0.9805 Validation Accuracy 0.6702\n",
      "Epoch 13 Batch 100 Validation Loss 0.9782 Validation Accuracy 0.6712\n",
      "Epoch 13 Loss 1.0113 Accuracy 0.6605\n",
      "Time taken for 1 epoch: 86.13 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.9676 Accuracy 0.6689\n",
      "Epoch 14 Batch 50 Loss 0.9770 Accuracy 0.6713\n",
      "Epoch 14 Batch 100 Loss 0.9787 Accuracy 0.6705\n",
      "Epoch 14 Batch 150 Loss 0.9791 Accuracy 0.6704\n",
      "Epoch 14 Batch 200 Loss 0.9780 Accuracy 0.6709\n",
      "Epoch 14 Batch 250 Loss 0.9785 Accuracy 0.6706\n",
      "Epoch 14 Batch 300 Loss 0.9779 Accuracy 0.6709\n",
      "Epoch 14 Batch 0 Validation Loss 1.0210 Validation Accuracy 0.6610\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-88619704c870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, epochs, log_wandb, validation_dataset, validation_every)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidation_dataset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalidation_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mval_step\u001b[0;34m(self, inp, tar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         predictions, _ = self.transformer(\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    324\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         enc_output = self.encoder(\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         )  # (batch_size, inp_seq_len, d_model)\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/transformer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/layers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/deepcomedy/models/layers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4797\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4798\u001b[0m     \u001b[0ma_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4799\u001b[0;31m     \u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4800\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   4801\u001b[0m         b, b_axes, True)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_tensordot_reshape\u001b[0;34m(a, axes, flipped)\u001b[0m\n\u001b[1;32m   4724\u001b[0m         \u001b[0ma_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4725\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0ma_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4726\u001b[0;31m         \u001b[0mreshaped_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4727\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mreshaped_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_trans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8391\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8392\u001b[0m       return reshape_eager_fallback(\n\u001b[0;32m-> 8393\u001b[0;31m           tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8394\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8395\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8412\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreshape_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8413\u001b[0m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8414\u001b[0;31m   \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8415\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8416\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer_trainer.train(dataset, 30, validation_dataset=val_dataset, validation_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgDU7jfoe2UJ"
   },
   "source": [
    "## 4. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "gAvzChyle2UL"
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    transformer,\n",
    "    encoder_input,\n",
    "    decoder_input,\n",
    "    stop_symbol,\n",
    "    max_length=200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predicts the output of the model given the `input_sequence`.\n",
    "    The `input_sequence` is encoded by the Encoder, then its output is fed to the Decoder,\n",
    "    whose output is fed back into the Decoder until the `stop_symbol` token is produced.\n",
    "\n",
    "    This function works with a batch of inputs and stops when all outputs include a stop symbol.\n",
    "    \"\"\"\n",
    "\n",
    "    output = decoder_input\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output\n",
    "    )\n",
    "\n",
    "    enc_output = transformer.encoder(\n",
    "        encoder_input, False, enc_padding_mask\n",
    "    )  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output\n",
    "        )\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, _ = transformer.decoder(\n",
    "            output, enc_output, False, combined_mask, dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = transformer.final_layer(dec_output)\n",
    "\n",
    "        # select the last character from the seq_len dimension\n",
    "        predicted_ids = tf.argmax(predictions[:, -1:, :], axis=-1)\n",
    "\n",
    "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
    "        output = tf.concat(\n",
    "            [\n",
    "                tf.cast(output, dtype=tf.int32),\n",
    "                tf.cast(predicted_ids, dtype=tf.int32),\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "                \n",
    "        if sum(output.numpy()[0] == stop_symbol) == 4:\n",
    "            print('Stopped')\n",
    "            return output\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "EXC7XrTle2UU"
   },
   "outputs": [],
   "source": [
    "def generate(transformer, input_sequence, target_sequence, input_tokenizer, target_tokenizer, steps, start_symbol, stop_symbol):\n",
    "\n",
    "    result = target_tokenizer.sequences_to_texts(target_sequence)[0]\n",
    "    \n",
    "    encoder_input = input_sequence\n",
    "    decoder_input = target_sequence\n",
    "\n",
    "    for _ in range(steps):\n",
    "\n",
    "        encoder_input = tf.convert_to_tensor(encoder_input)\n",
    "        decoder_input = tf.convert_to_tensor(decoder_input)\n",
    "        output = evaluate(transformer, encoder_input, decoder_input, stop_symbol)\n",
    "\n",
    "        generated_text = target_tokenizer.sequences_to_texts(output.numpy())[0]\n",
    "        \n",
    "        verses = [line.lstrip() + '<EOV> ' for line in generated_text.split('<EOV>') if line.strip() != '']\n",
    "        \n",
    "        result = ''.join([result, verses[-1]])\n",
    "                \n",
    "        verses = ''.join(verses[-3:])\n",
    "        \n",
    "        decoder_input = target_tokenizer.texts_to_sequences([verses])\n",
    "        \n",
    "        verses = remove_syll_token(verses)\n",
    "        verses = re.sub(r\"[ ]+\", \"\", verses)\n",
    "        verses = re.sub(\"<[^>]*>\", \" \\g<0> \", verses)\n",
    "        verses = re.sub(\"<EOV>  <GO>\", \"<EOV> <GO>\", verses)\n",
    "        verses = verses.strip()\n",
    "\n",
    "        encoder_input = input_tokenizer.texts_to_sequences([verses])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMSbfxwae2UW",
    "outputId": "a219af16-126e-4977-9a13-7a86dfb570bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "start_symbol = target_tokenizer.word_index[\"<GO>\"]\n",
    "stop_symbol = target_tokenizer.word_index[\"<EOV>\"]\n",
    "\n",
    "encoder_input = [input_text[0]]\n",
    "decoder_input = [target_text_tercet[0]]\n",
    "\n",
    "result = generate(transformer, encoder_input, decoder_input, input_tokenizer, target_tokenizer, 10, start_symbol, stop_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1uAYbYDe2UX",
    "outputId": "7ec8539e-c959-4cc0-d1c6-6da99b595617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Nel |mez|zo |del |cam|min |di |no|stra |vi|ta\n",
      "|mi |ri|tro|vai |per |u|na |sel|va o|scu|ra,\n",
      "|ché |la |di|rit|ta |via |e|ra |smar|ri|ta.\n",
      "|E |io |a |la |mia |di|stin|ta |di |so|pra\n",
      "|e |dis|si:« |Vien |che |son |di |so|pra |se|sta\n",
      "|la |mia |se|gui|ta |di |mia |se|gui|ta,\n",
      "|che |di |mil|le |mia |di |mi|se|ria |sciol|ta.\n",
      "|E |io |mi |fui |di |mil|le |di |mil|le |schia|mi\n",
      "|di |quel |che |di |mio |di |mil|le |si |mo|ve\n",
      "|di |mil|le |di |mil|le |di |mil|le |spi|ri.\n",
      "|E |io |dis|si:« |Vien |che |tu |di |mil|le |spal|le\n",
      "|di |quel |che |di |mio |di |mil|le |si |spi|ri\n",
      "|di |mil|le |di |mil|le |di |mil|le |spa|da,\n"
     ]
    }
   ],
   "source": [
    "print(strip_tokens(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5MorsDLe2UY"
   },
   "source": [
    "## 5. Syllabification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbBb0fLTe2UY"
   },
   "outputs": [],
   "source": [
    "start_symbol = target_tokenizer.word_index[\"<GO>\"]\n",
    "stop_symbol = target_tokenizer.word_index[\"<EOV>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huknwnsde2UZ"
   },
   "outputs": [],
   "source": [
    "encoder_input = tf.convert_to_tensor([input_text[0]])\n",
    "decoder_input = tf.convert_to_tensor([[start_symbol]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxTgAWrpe2Ua",
    "outputId": "a00ceade-6cc3-4ac2-8b12-4a51c5491143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "syll_output = evaluate(transformer, encoder_input, decoder_input, stop_symbol, max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDqwIrMee2Ua",
    "outputId": "ae315695-cdc1-4428-fdf9-83fbf8c13212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<GO> | c h e <SEP> | d i <SEP> | p e n | s i e r <SEP> | m i <SEP> | s t a | v a <SEP> i n <SEP> | u | n o <SEP> | s t r a | l e , <EOV> <GO> | e <SEP> | d i | c o <SEP> | d i <SEP> | g e n | t e <SEP> a l | t r o <SEP> | c h e <SEP> | p i ù <SEP> | d o l | c e » . <EOV> <GO> | N o i <SEP> | e | r a | v a m <SEP> | n e l <SEP> | s u o <SEP> | a | s p e t | t o <SEP> | b a n | d o <EOV> <GO> | c h e <SEP> | l ’ <SEP> a | n i | m a <SEP> | s u a <SEP> | a v | v e n | t a <SEP> | d i | s t a n | t e , <EOV>']\n"
     ]
    }
   ],
   "source": [
    "print(target_tokenizer.sequences_to_texts(syll_output.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXMfBSRTe2Ub"
   },
   "source": [
    "Potrebbe essere underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzPwlV9ae2Uc"
   },
   "source": [
    "## 6. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfTkQfWle2Uc"
   },
   "outputs": [],
   "source": [
    "transformer.save_weights('models/w2c-gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acIj_s75e2Ue"
   },
   "outputs": [],
   "source": [
    "new_transformer = Transformer(\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        d_model=config[\"d_model\"],\n",
    "        num_heads=config[\"num_heads\"],\n",
    "        dff=config[\"dff\"],\n",
    "        input_vocab_size=input_vocab_size,\n",
    "        target_vocab_size=target_vocab_size,\n",
    "        pe_input=1000,\n",
    "        pe_target=1000,\n",
    "        rate=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKj4qsd6e2Ue"
   },
   "outputs": [],
   "source": [
    "# In order to load the new weights the model should be called once for the variables to be initialized\n",
    "\n",
    "# Any inp, tar is ok here\n",
    "inp = tf.convert_to_tensor([[start_symbol]])\n",
    "tar = tf.convert_to_tensor([[start_symbol]])\n",
    "\n",
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "\n",
    "new_transformer(inp, tar, False, enc_padding_mask, look_ahead_mask, dec_padding_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9IMbvrte2Uf"
   },
   "outputs": [],
   "source": [
    "new_transformer.load_weights('models/w2c-gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEpPqSJRe2Uf",
    "outputId": "3d2f2647-6032-4194-cc94-cb2f286dbb39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n",
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "encoder_input = [input_text[0]]\n",
    "decoder_input = [target_text_tercet[0]]\n",
    "\n",
    "result = generate(new_transformer, encoder_input, decoder_input, input_tokenizer, target_tokenizer, 6, start_symbol, stop_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOZR_Zd6e2Ug",
    "outputId": "ede37c97-bd43-4d6c-886d-8cee47ab03e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<GO> | N e l <SEP> | m e z | z o <SEP> | d e l <SEP> | c a m | m i n <SEP> | d i <SEP> | n o | s t r a <SEP> | v i | t a <EOV> <GO> | m i <SEP> | r i | t r o | v a i <SEP> | p e r <SEP> | u | n a <SEP> | s e l | v a <SEP> o | s c u | r a , <EOV> <GO> | c h é <SEP> | l a <SEP> | d i | r i t | t a <SEP> | v i a <SEP> | e | r a <SEP> | s m a r | r i | t a . <EOV><GO> | E l | l a <SEP> | s o | p r a <SEP> | c h e <SEP> ’ l <SEP> | v i | s o <SEP> a <SEP> | q u e l | l a <SEP> | g e n | t e <EOV> <GO> | c h e <SEP> | p e r <SEP> | l o <SEP> | s u o <SEP> | a v | v e r | s a | r i o <SEP> a l | t r u i <SEP> | m a n | t o , <EOV> <GO> | e <SEP> | a l | t r a <SEP> | v o | c e <SEP> | m i <SEP> | p a | r e a <SEP> | p i ù <SEP> | r a t | t a . <EOV> <GO> « <SEP> | O <SEP> | t u <SEP> | c h e <SEP> | s e ’ <SEP> | c h e <SEP> | s ì <SEP> | p r e s | s o <SEP> | d i | s c i o l | t a » , <EOV> <GO> | d i s | s e <SEP> ’ l <SEP> | m a | e | s t r o , « <SEP> | q u a n | t o <SEP> | p o s | s o <SEP> | p o | c o , <EOV> <GO> | s e <SEP> | n o n <SEP> | c h e <SEP> | t u <SEP> | s e ’ <SEP> | t e m | p i o n <SEP> | f a r <SEP> | n o n <SEP> | l a | t i , <EOV> '"
      ]
     },
     "execution_count": 320,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TgDU7jfoe2UJ",
    "k5MorsDLe2UY"
   ],
   "name": "Word2Char transformer generation-WORKING.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
