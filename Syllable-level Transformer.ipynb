{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Syllable-level Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "54j16swJY1dW"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRKGBdAtVIfZ"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/syllablelevel\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "8RuMqNB4ujuT"
      },
      "source": [
        "## 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "lsuXc5StY1dY"
      },
      "source": [
        "file = \"data/divina_syll_textonly.txt\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "ACAEUyITY1dY",
        "outputId": "d9f37c05-1b08-475a-9426-604b76da3712"
      },
      "source": [
        "text_raw = open(file, \"rb\").read().decode(encoding=\"utf-8\")\n",
        "print(\"Length of text: {} characters\".format(len(text_raw)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 892871 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "RDRNHkB-VIfc"
      },
      "source": [
        "def preprocess(text):\n",
        "    \"\"\"\n",
        "    For each line in the file, add start symbol \"^\" in the beginning and end symbol \"$\" in the end\n",
        "    \"\"\"\n",
        "    return [\"^ \" + line.strip() + \" $\" for line in text.split(\"\\n\") if line.strip() != \"\"]\n",
        "\n",
        "text_prepr = preprocess(text_raw)\n",
        "text_prepr = list(map(lambda x: re.sub('\\|', ' ', x), text_prepr))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "vgFtCA9wVIfe"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\", split=' ', lower=False, oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(text_prepr)\n",
        "\n",
        "text_lines_enc = tokenizer.texts_to_sequences(text_prepr)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "qu_z0ozzVIff"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "p-w27LhpY1db",
        "outputId": "435bb7a8-f48c-418c-f3a9-6b2ebde742a4"
      },
      "source": [
        "print(\"Vocab size: {}\".format(vocab_size))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 4191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4bfzvcNvT-y"
      },
      "source": [
        "Padding is required in order to have a non-ragged tensor to feed to the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "MBOh9LQeY1dg"
      },
      "source": [
        "def pad(x):\n",
        "    return tf.keras.preprocessing.sequence.pad_sequences(x, padding=\"post\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "9zV0xz48Y1dh"
      },
      "source": [
        "text = pad(text_lines_enc)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GVc41zvvdR9"
      },
      "source": [
        "## 2. The Transformer model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "FE_LiRvcVIfi"
      },
      "source": [
        "input_text_ = []\n",
        "target_text_ = []\n",
        "\n",
        "for line_number in range(0, len(text) - 4):\n",
        "    \n",
        "    input_verses = []\n",
        "    target_verses = []\n",
        "    \n",
        "    for i in range(4):\n",
        "        input_verses += list(text[line_number + i])\n",
        "        target_verses += list(text[line_number + i])\n",
        "    \n",
        "    input_text_.append(input_verses)\n",
        "    target_text_.append(target_verses)\n",
        "    \n",
        "input_text_ = np.array(input_text_)\n",
        "target_text_ = np.array(target_text_)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "7xGxZmlPY1dk"
      },
      "source": [
        "input_train, input_test, target_train, target_test = train_test_split(\n",
        "    input_text_, target_text_\n",
        "    )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IN8x175vimK"
      },
      "source": [
        "The dataset is created by grouping the lines in batches and by shuffling them.\n",
        "\n",
        "Each input's line is in correspondence with its target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "tZWLq7g3Y1dl"
      },
      "source": [
        "BUFFER_SIZE = len(input_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
        "\n",
        "vocab_size = (\n",
        "    len(tokenizer.word_index) + 1\n",
        ")  # the +1 is added to take into account the id 0 of the padding\n",
        "\n",
        "max_length = text.shape[1]\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(\n",
        "    BUFFER_SIZE\n",
        ")\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RHNAazT5Rs_"
      },
      "source": [
        "We define the positional encoding to add to the embedding.\n",
        "\n",
        "This allows to take into account the order of the characters in the input sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "f200V0QnkBBS"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "OvnGjGhvkD9R"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
        "    )\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "500eU4tu6n-g"
      },
      "source": [
        "We define two masks: \n",
        "\n",
        "one is used to mask the padding added to the sequences in the preprocessing step; \n",
        "\n",
        "the other one is used to mask the positions following the current one and not predicted yet;\n",
        "\n",
        "The first mask is used from both the encoder and the decoder, while the last mask is used only in the self-attention of the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "OVwx6Y4Tku1V"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "3p1-yIYimnvB"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "R-Q4J7EzfuLH"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxzWROrTM9ib"
      },
      "source": [
        "The *scaled_dot_product_attention* gets the attention weights by applying the softmax to the rescaled dot product between the query matrix and the key matrix, while the output is obtained by multiplying the value matrix for those attention weights.\n",
        "\n",
        "The query, key and value matrices are built by multiplying the embedding matrix with the query, key and value weight matrices, which initially are randomly initialized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "RoFZK1S3mtI5"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"\n",
        "    Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "      q: query shape == (..., seq_len_q, depth)\n",
        "      k: key shape == (..., seq_len_k, depth)\n",
        "      v: value shape == (..., seq_len_v, depth_v)\n",
        "      mask: Float tensor with shape broadcastable\n",
        "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "      output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += mask * -1e9\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
        "    attention_weights = tf.nn.softmax(\n",
        "        scaled_attention_logits, axis=-1\n",
        "    )  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlA3inNYQO89"
      },
      "source": [
        "The multi-headed attention allows to improve the performance of the attention mechanism by working with multiple sets of query, key and value weight matrices.\n",
        "\n",
        "These heads work in parallel and process at the same time all the lines of each batch.\n",
        "\n",
        "At the end, the results of all the attention heads are concatenated and multiplied by an additional weight matrix, to adjust the dimension before passing through the final *point_wise_feed_forward_network*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "_UpdBWkVnK02"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"\n",
        "        Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask\n",
        "        )\n",
        "\n",
        "        scaled_attention = tf.transpose(\n",
        "            scaled_attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(\n",
        "            scaled_attention, (batch_size, -1, self.d_model)\n",
        "        )  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "LkMP7DDAok4y"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Dense(dff, activation=\"relu\"),  # (batch_size, seq_len, dff)\n",
        "            tf.keras.layers.Dense(d_model),  # (batch_size, seq_len, d_model)\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO6yyZPWUON7"
      },
      "source": [
        "Each encoder is constituted by a multi-headed self-attention layer and by a final feed forward layer. \n",
        "\n",
        "Both sub-layers have a residual connection around them and are followed by a layer-normalization step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "Dat64C18otwC"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(\n",
        "            out1 + ffn_output\n",
        "        )  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GZslNuSZOKp"
      },
      "source": [
        "The decoder equals the encoder, a part from the fact that it contains a slightly different self-attention layer and an additional attention layer.\n",
        "\n",
        "Indeed, the decoder is characterized by a self-attention layer which focuses only on earlier positions in its input sequence, not looking at the positions which have not been predicted yet.\n",
        "\n",
        "What's more the decoder is also characterized by an attention layer which obtains its key and value matrices from the output of the encoder, while the query matrix is obtained from the output of the previous self-attention in the decoder.\n",
        "\n",
        "The encoder-decoder attention helps the decoder to focus on appropriate positions in the input sequence of the encoder during the translation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "7Vp44lQepI_P"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(\n",
        "            x, x, x, look_ahead_mask\n",
        "        )  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask\n",
        "        )  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(\n",
        "            ffn_output + out2\n",
        "        )  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_DyJiybrOr"
      },
      "source": [
        "The encoding component is a stack of encoders and the decoding component is a stack of decoders of the same number.\n",
        "\n",
        "At the beginning, in the encoding, each input character is turned into a vector using an embedding algorithm and adding the positional encoding to it.\n",
        "\n",
        "This happens only in the bottom-most encoder, while the following encoders take the output of the encoder which is directly below.\n",
        "\n",
        "The same for the decoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "awl9kiESpWBh"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        input_vocab_size,\n",
        "        maximum_position_encoding,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "47tQAEMwpnUj"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        target_vocab_size,\n",
        "        maximum_position_encoding,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [\n",
        "            DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
        "        ]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](\n",
        "                x, enc_output, training, look_ahead_mask, padding_mask\n",
        "            )\n",
        "\n",
        "            attention_weights[f\"decoder_layer{i+1}_block1\"] = block1\n",
        "            attention_weights[f\"decoder_layer{i+1}_block2\"] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TosN_TpKk1eN"
      },
      "source": [
        "In the transformer, the output of the encoding is passed to the stack of decoders and the output of the decoding is projected by a feed forward network into a vector of logits of dimension equal to the one of the target's vocabulary.\n",
        "\n",
        "Obviously this is done for each character of each line of each batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "qCNKKsQ-p99k"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        input_vocab_size,\n",
        "        target_vocab_size,\n",
        "        pe_input,\n",
        "        pe_target,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "            num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate\n",
        "        )\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(\n",
        "        self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask\n",
        "    ):\n",
        "\n",
        "        enc_output = self.encoder(\n",
        "            inp, training, enc_padding_mask\n",
        "        )  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask\n",
        "        )\n",
        "\n",
        "        final_output = self.final_layer(\n",
        "            dec_output\n",
        "        )  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLTOETK4_m6"
      },
      "source": [
        "## 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "LrdL396xqOL4"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 256\n",
        "dff = 1024\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "JFCVQIDjqQHv"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "1R9MlFs0qc5U"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcmLAk1Ut8vG"
      },
      "source": [
        "The loss is calculated using Sparse Categorical Crossentropy and the loss of the padding is masked.\n",
        "\n",
        "The same is done for the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "TBAaRBPsqkuo"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
        ")\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "31R26t9wqlLD"
      },
      "source": [
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.cast(tf.argmax(pred, axis=2), dtype=tf.int32))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "SkVkWvL7qoYu"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.Mean(name=\"train_accuracy\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "5UE3cWGVqvnS"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=vocab_size,\n",
        "    target_vocab_size=vocab_size,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate,\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64MejGX2Lbk1",
        "outputId": "bf5d9338-4a31-480d-c157-6236e2e445c4"
      },
      "source": [
        "!tar zxvf checkpoints.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints/\n",
            "checkpoints/wordlevel/\n",
            "checkpoints/wordlevel/ckpt-6.index\n",
            "checkpoints/wordlevel/ckpt-6.data-00000-of-00001\n",
            "checkpoints/wordlevel/checkpoint\n",
            "checkpoints/wordlevel/ckpt-3.index\n",
            "checkpoints/wordlevel/ckpt-4.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-2.index\n",
            "checkpoints/wordlevel/ckpt-5.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-4.index\n",
            "checkpoints/wordlevel/ckpt-3.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-2.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-5.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "nSE2Rh-_qzo7"
      },
      "source": [
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITVGgP8Su9MH"
      },
      "source": [
        "To train the decoder we use teacher forcing, calculating the loss between the predicted logits and the real id of the character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "n_VPs6ZOva15"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "1ce0FAOivleY",
        "outputId": "fa43f72e-4476-47cf-9d60-a87625003925"
      },
      "source": [
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}\"\n",
        "            )\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print(f\"Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}\"\n",
        "    )\n",
        "\n",
        "    print(f\"Time taken for 1 epoch: {time.time() - start:.2f} secs\\n\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.4319 Accuracy 0.0003\n",
            "Epoch 1 Batch 50 Loss 8.2271 Accuracy 0.0276\n",
            "Epoch 1 Batch 100 Loss 7.9627 Accuracy 0.0495\n",
            "Epoch 1 Batch 150 Loss 7.7360 Accuracy 0.0569\n",
            "Epoch 1 Loss 7.6651 Accuracy 0.0583\n",
            "Time taken for 1 epoch: 71.75 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 6.8777 Accuracy 0.0772\n",
            "Epoch 2 Batch 50 Loss 6.5389 Accuracy 0.1205\n",
            "Epoch 2 Batch 100 Loss 6.2466 Accuracy 0.1232\n",
            "Epoch 2 Batch 150 Loss 6.0371 Accuracy 0.1280\n",
            "Epoch 2 Loss 5.9879 Accuracy 0.1303\n",
            "Time taken for 1 epoch: 58.26 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 5.4475 Accuracy 0.1623\n",
            "Epoch 3 Batch 50 Loss 5.3982 Accuracy 0.1617\n",
            "Epoch 3 Batch 100 Loss 5.3339 Accuracy 0.1676\n",
            "Epoch 3 Batch 150 Loss 5.2649 Accuracy 0.1743\n",
            "Epoch 3 Loss 5.2442 Accuracy 0.1764\n",
            "Time taken for 1 epoch: 57.76 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 5.0318 Accuracy 0.1942\n",
            "Epoch 4 Batch 50 Loss 4.9120 Accuracy 0.2073\n",
            "Epoch 4 Batch 100 Loss 4.8369 Accuracy 0.2148\n",
            "Epoch 4 Batch 150 Loss 4.7665 Accuracy 0.2217\n",
            "Epoch 4 Loss 4.7458 Accuracy 0.2236\n",
            "Time taken for 1 epoch: 58.14 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 4.4946 Accuracy 0.2431\n",
            "Epoch 5 Batch 50 Loss 4.4294 Accuracy 0.2528\n",
            "Epoch 5 Batch 100 Loss 4.3737 Accuracy 0.2588\n",
            "Epoch 5 Batch 150 Loss 4.3117 Accuracy 0.2664\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/syllablelevel/ckpt-1\n",
            "Epoch 5 Loss 4.2899 Accuracy 0.2693\n",
            "Time taken for 1 epoch: 58.40 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 4.0161 Accuracy 0.3054\n",
            "Epoch 6 Batch 50 Loss 3.8974 Accuracy 0.3293\n",
            "Epoch 6 Batch 100 Loss 3.6991 Accuracy 0.3688\n",
            "Epoch 6 Batch 150 Loss 3.4086 Accuracy 0.4241\n",
            "Epoch 6 Loss 3.3111 Accuracy 0.4418\n",
            "Time taken for 1 epoch: 58.20 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 2.2075 Accuracy 0.6484\n",
            "Epoch 7 Batch 50 Loss 1.8357 Accuracy 0.7018\n",
            "Epoch 7 Batch 100 Loss 1.5602 Accuracy 0.7521\n",
            "Epoch 7 Batch 150 Loss 1.3539 Accuracy 0.7886\n",
            "Epoch 7 Loss 1.2992 Accuracy 0.7981\n",
            "Time taken for 1 epoch: 57.84 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.7193 Accuracy 0.8978\n",
            "Epoch 8 Batch 50 Loss 0.6272 Accuracy 0.9125\n",
            "Epoch 8 Batch 100 Loss 0.5546 Accuracy 0.9233\n",
            "Epoch 8 Batch 150 Loss 0.5007 Accuracy 0.9311\n",
            "Epoch 8 Loss 0.4863 Accuracy 0.9333\n",
            "Time taken for 1 epoch: 58.20 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.3443 Accuracy 0.9526\n",
            "Epoch 9 Batch 50 Loss 0.2950 Accuracy 0.9603\n",
            "Epoch 9 Batch 100 Loss 0.2718 Accuracy 0.9634\n",
            "Epoch 9 Batch 150 Loss 0.2510 Accuracy 0.9663\n",
            "Epoch 9 Loss 0.2454 Accuracy 0.9671\n",
            "Time taken for 1 epoch: 57.74 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1785 Accuracy 0.9766\n",
            "Epoch 10 Batch 50 Loss 0.1668 Accuracy 0.9776\n",
            "Epoch 10 Batch 100 Loss 0.1586 Accuracy 0.9786\n",
            "Epoch 10 Batch 150 Loss 0.1503 Accuracy 0.9797\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/syllablelevel/ckpt-2\n",
            "Epoch 10 Loss 0.1481 Accuracy 0.9800\n",
            "Time taken for 1 epoch: 58.67 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.1271 Accuracy 0.9804\n",
            "Epoch 11 Batch 50 Loss 0.1071 Accuracy 0.9855\n",
            "Epoch 11 Batch 100 Loss 0.1030 Accuracy 0.9861\n",
            "Epoch 11 Batch 150 Loss 0.0993 Accuracy 0.9865\n",
            "Epoch 11 Loss 0.0986 Accuracy 0.9866\n",
            "Time taken for 1 epoch: 57.89 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0785 Accuracy 0.9893\n",
            "Epoch 12 Batch 50 Loss 0.0727 Accuracy 0.9903\n",
            "Epoch 12 Batch 100 Loss 0.0724 Accuracy 0.9904\n",
            "Epoch 12 Batch 150 Loss 0.0694 Accuracy 0.9908\n",
            "Epoch 12 Loss 0.0682 Accuracy 0.9910\n",
            "Time taken for 1 epoch: 58.13 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0507 Accuracy 0.9955\n",
            "Epoch 13 Batch 50 Loss 0.0531 Accuracy 0.9932\n",
            "Epoch 13 Batch 100 Loss 0.0536 Accuracy 0.9930\n",
            "Epoch 13 Batch 150 Loss 0.0528 Accuracy 0.9929\n",
            "Epoch 13 Loss 0.0523 Accuracy 0.9930\n",
            "Time taken for 1 epoch: 57.88 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0367 Accuracy 0.9947\n",
            "Epoch 14 Batch 50 Loss 0.0415 Accuracy 0.9945\n",
            "Epoch 14 Batch 100 Loss 0.0420 Accuracy 0.9943\n",
            "Epoch 14 Batch 150 Loss 0.0407 Accuracy 0.9945\n",
            "Epoch 14 Loss 0.0412 Accuracy 0.9944\n",
            "Time taken for 1 epoch: 58.06 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0368 Accuracy 0.9941\n",
            "Epoch 15 Batch 50 Loss 0.0343 Accuracy 0.9949\n",
            "Epoch 15 Batch 100 Loss 0.0351 Accuracy 0.9948\n",
            "Epoch 15 Batch 150 Loss 0.0340 Accuracy 0.9950\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/syllablelevel/ckpt-3\n",
            "Epoch 15 Loss 0.0341 Accuracy 0.9949\n",
            "Time taken for 1 epoch: 58.21 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0174 Accuracy 0.9969\n",
            "Epoch 16 Batch 50 Loss 0.0356 Accuracy 0.9944\n",
            "Epoch 16 Batch 100 Loss 0.0335 Accuracy 0.9948\n",
            "Epoch 16 Batch 150 Loss 0.0327 Accuracy 0.9950\n",
            "Epoch 16 Loss 0.0320 Accuracy 0.9951\n",
            "Time taken for 1 epoch: 58.21 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0234 Accuracy 0.9972\n",
            "Epoch 17 Batch 50 Loss 0.0302 Accuracy 0.9953\n",
            "Epoch 17 Batch 100 Loss 0.0305 Accuracy 0.9953\n",
            "Epoch 17 Batch 150 Loss 0.0314 Accuracy 0.9951\n",
            "Epoch 17 Loss 0.0314 Accuracy 0.9951\n",
            "Time taken for 1 epoch: 57.69 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0218 Accuracy 0.9955\n",
            "Epoch 18 Batch 50 Loss 0.0263 Accuracy 0.9959\n",
            "Epoch 18 Batch 100 Loss 0.0256 Accuracy 0.9960\n",
            "Epoch 18 Batch 150 Loss 0.0260 Accuracy 0.9959\n",
            "Epoch 18 Loss 0.0265 Accuracy 0.9959\n",
            "Time taken for 1 epoch: 58.14 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0390 Accuracy 0.9952\n",
            "Epoch 19 Batch 50 Loss 0.0264 Accuracy 0.9959\n",
            "Epoch 19 Batch 100 Loss 0.0284 Accuracy 0.9956\n",
            "Epoch 19 Batch 150 Loss 0.0275 Accuracy 0.9958\n",
            "Epoch 19 Loss 0.0271 Accuracy 0.9958\n",
            "Time taken for 1 epoch: 57.76 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0339 Accuracy 0.9952\n",
            "Epoch 20 Batch 50 Loss 0.0255 Accuracy 0.9960\n",
            "Epoch 20 Batch 100 Loss 0.0273 Accuracy 0.9958\n",
            "Epoch 20 Batch 150 Loss 0.0280 Accuracy 0.9957\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/syllablelevel/ckpt-4\n",
            "Epoch 20 Loss 0.0276 Accuracy 0.9958\n",
            "Time taken for 1 epoch: 58.56 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vbeVUzwtoTE",
        "outputId": "8381c219-b80d-4fb4-9de3-5365d60447a6"
      },
      "source": [
        "!tar chvfz checkpoints.tar.gz checkpoints"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints/\n",
            "checkpoints/wordlevel/\n",
            "checkpoints/wordlevel/checkpoint\n",
            "checkpoints/wordlevel/ckpt-20.index\n",
            "checkpoints/wordlevel/ckpt-19.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-17.index\n",
            "checkpoints/wordlevel/ckpt-17.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-16.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-18.index\n",
            "checkpoints/wordlevel/ckpt-20.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-18.data-00000-of-00001\n",
            "checkpoints/wordlevel/ckpt-19.index\n",
            "checkpoints/wordlevel/ckpt-16.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz4YwsF04YEI"
      },
      "source": [
        "## 4. Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O44l1saVuebS"
      },
      "source": [
        "We define the *evaluate* function to preprocess the sentence in input to the encoder and to get the predicted ids of the translation.\n",
        "\n",
        "The ids of the translation are obtained by applying *argmax* to the predicted logits of the decoder.\n",
        "\n",
        "We begin feeding the decoder with the id of the start symbol and, at each new step, we pass to the decoder the sequence it has just thrown out.\n",
        "\n",
        "The translation stops when the end symbol is reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh7X-rIaJHyl",
        "outputId": "d8b530ee-fe8b-4551-a273-493a51edbc1c"
      },
      "source": [
        "sentence = \"quanto disobediendo intese ir suso;\"\n",
        "encoder_input = preprocess(sentence)\n",
        "encoder_input = input_tokenizer.texts_to_sequences(encoder_input)\n",
        "encoder_input = pad(encoder_input)\n",
        "print(encoder_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    2    87 17042  3716   870  1319     3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "BSNaKtSkvxcJ"
      },
      "source": [
        "def evaluate(sentence, max_length=200):\n",
        "\n",
        "    #encoder_input = preprocess(sentence)\n",
        "    encoder_input = tokenizer.texts_to_sequences(sentence)\n",
        "    encoder_input = [x for l in encoder_input for x in l]\n",
        "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        [encoder_input], maxlen=max_length, padding=\"post\"\n",
        "    )\n",
        "    encoder_input = tf.convert_to_tensor(encoder_input)\n",
        "\n",
        "    output = tf.convert_to_tensor([tokenizer.word_index[\"^\"]])\n",
        "    output = tf.expand_dims(output, 0)\n",
        "    result = \"\"\n",
        "\n",
        "    for i in range(600):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output\n",
        "        )\n",
        "\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask,\n",
        "        )\n",
        "\n",
        "        # select the last character from the seq_len dimension\n",
        "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
        "        output = tf.concat(\n",
        "            [tf.cast(output, dtype=tf.int32), tf.cast(predicted_id, dtype=tf.int32)],\n",
        "            axis=-1,\n",
        "        )\n",
        "        result += tokenizer.index_word[predicted_id.numpy()[0][0]] + \" \"\n",
        "\n",
        "        if predicted_id == tokenizer.word_index[\"$\"]:\n",
        "          result += \"\\n\"\n",
        "        if result.count(\"$\") == 6:\n",
        "          break\n",
        "\n",
        "    # output.shape (1, tokens)\n",
        "\n",
        "    return result, attention_weights"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "PkCDxGdeyF9f"
      },
      "source": [
        "def print_translation(sentence, result, ground_truth):\n",
        "    print(f'{\"Input:\":15s}: {sentence}')\n",
        "    print(f'{\"Prediction\":15s}: {result}')\n",
        "    print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbKZbzeL000f",
        "outputId": "23f54d8c-818f-4c3d-a4f0-9e524a6e62e8"
      },
      "source": [
        "sentence = \"^\"\n",
        "ground_truth = \"\"\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : ^\n",
            "Prediction     : sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï sï \n",
            "Ground truth   : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlPsnGGTX5Dq",
        "outputId": "b56ca2c4-f51c-442b-f3db-276ed5235cf6"
      },
      "source": [
        "sentence = \"quanto disobediendo intese ir suso;\"\n",
        "ground_truth = \"|quan|to |di|so|be|dien|do in|te|se ir |su|so;\"\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : quanto disobediendo intese ir suso;\n",
            "Prediction     : et a scu guan o scu i no o le; e ar e $ \n",
            "$ \n",
            "$ \n",
            "$ \n",
            "^ e vra vra le; e i ra!»; u u zar o bli te, e u ra!»; e o bli no i dea, e o l’ e ra!»; u no a o spe e ar le; e a sé o pre e ar zo o no oh, on sé e i van rï e ar le; e i zar o na e ar le; $ \n",
            "$ \n",
            "\n",
            "Ground truth   : |quan|to |di|so|be|dien|do in|te|se ir |su|so;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "V33sFY3iyLLE",
        "outputId": "ae1d906c-c3c0-40f5-a322-19a47a542f54"
      },
      "source": [
        "sentence = \"Buonasera a tutti\"\n",
        "ground_truth = \"\"\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : Buonasera a tutti\n",
            "Prediction     : u o pre a ver’ e van a a Dio u u u no i $ \n",
            "$ \n",
            "$ \n",
            "$ \n",
            "i o o pre a u no van a a Dio u te, $ \n",
            "$ \n",
            "\n",
            "Ground truth   : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPLXjcQVriKf",
        "outputId": "329710bc-deb8-4c0a-bbd0-8ca3d752a0c6"
      },
      "source": [
        "sentence = \"Io non so ben ridir com’ i’ v’intrai,\"\n",
        "ground_truth = \"|Io |non |so |ben |ri|dir |com’ |i’ |v’ in|trai,\"\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : Io non so ben ridir com’ i’ v’intrai,\n",
            "Prediction     : I no o pre Az o no e no scen i no i no $ \n",
            "$ \n",
            "$ \n",
            "$ \n",
            "^ ’ no ’ i te, te, e a i Ghi i te, e van dea, $ \n",
            "$ \n",
            "\n",
            "Ground truth   : |Io |non |so |ben |ri|dir |com’ |i’ |v’ in|trai,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7hFuQB_wD-z",
        "outputId": "ddfdfcd6-21b4-4451-c80e-2770dc9075b1"
      },
      "source": [
        "sentence = \"quanto disobediendo intese ir suso; \\n Io non so ben ridir com’ i’ v’intrai,\"\n",
        "ground_truth = \"\"\n",
        "\n",
        "translated_text, attention_weights = evaluate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:         : quanto disobediendo intese ir suso; \n",
            " Io non so ben ridir com’ i’ v’intrai,\n",
            "Prediction     : et a scu sti o le; i van o le; e u i e scu zar e i le; e le e e i ra!»; e u zar o sté I I o $ \n",
            "Ground truth   : \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}