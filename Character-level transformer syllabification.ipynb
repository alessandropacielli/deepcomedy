{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Character_level_transformer_syllabification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "lPKMpW3A33wu",
        "outputId": "101c291d-e16b-4fc9-f59b-99e81cfcc8f5"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import files\n",
        "    \n",
        "    files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc0c8bf6-1ced-4c2e-aacc-5069d13e23ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc0c8bf6-1ced-4c2e-aacc-5069d13e23ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving deepcomedy.zip to deepcomedy.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWNmhelZbEAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d693688-aee3-42c7-ee9b-de5934e23a2a"
      },
      "source": [
        "!pip install wandb\n",
        "#!tar zxvf deepcomedy.tar.gz\n",
        "!unzip deepcomedy.zip\n",
        "#!tar zxvf data.tar.gz\n",
        "!unzip data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 13.7MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 29.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=570cfc076ee80c0bf3e0543e6f56b35b088bc22eaf5ae7b7ec7ff3a5878213e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=bf1fe0fc6b95ce1117e0fb3e2fce6fa677e6f1c5d1b3bd1256ab45fee94cf1b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: pathtools, configparser, shortuuid, smmap, gitdb, GitPython, docker-pycreds, subprocess32, sentry-sdk, wandb\n",
            "Successfully installed GitPython-3.1.17 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.30\n",
            "Archive:  deepcomedy.zip\n",
            "   creating: deepcomedy/models/\n",
            "  inflating: deepcomedy/models/layers.py  \n",
            "  inflating: deepcomedy/models/transformer.py  \n",
            "  inflating: deepcomedy/preprocessing.py  \n",
            "   creating: deepcomedy/util/\n",
            "  inflating: deepcomedy/util/predicate.py  \n",
            "Archive:  data.zip\n",
            "  inflating: data/divina_syll_textonly.txt  \n",
            "  inflating: data/divina_textonly.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "54j16swJY1dW"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "from deepcomedy.models.transformer import *\n",
        "from deepcomedy.preprocessing import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RuMqNB4ujuT"
      },
      "source": [
        "## 1. Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "lsuXc5StY1dY"
      },
      "source": [
        "raw_text = open(\"./data/divina_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
        "raw_syll_text = (\n",
        "    open(\"./data/divina_syll_textonly.txt\", \"rb\").read().decode(encoding=\"utf-8\")\n",
        ")\n",
        "syll_text = preprocess_text(raw_syll_text, end_of_tercet=\"\")\n",
        "text = preprocess_text(raw_text, end_of_tercet=\"\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGpbut2Vb_fU"
      },
      "source": [
        "Split preprocessed text into verses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avfk31uHblz8"
      },
      "source": [
        "sep = \"<EOV>\"\n",
        "input_verses = [x + sep for x in text.split(sep)][:-1]\n",
        "target_verses = [x + sep for x in syll_text.split(sep)][:-1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVxwIU4gcGQe"
      },
      "source": [
        "Encode with tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUvF7DRscJTo"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    char_level=False, filters=\"\", lower=False\n",
        ")\n",
        "tokenizer.fit_on_texts(target_verses)\n",
        "enc_input_verses = tokenizer.texts_to_sequences(input_verses)\n",
        "enc_target_verses = tokenizer.texts_to_sequences(target_verses)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMv3NIsNcQ-d"
      },
      "source": [
        "Pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAn-XqEFcT5h"
      },
      "source": [
        "input_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    enc_input_verses, padding=\"post\"\n",
        ")\n",
        "target_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    enc_target_verses, padding=\"post\"\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kX2bojP72Vq"
      },
      "source": [
        "input_train, input_test, target_train, target_test = train_test_split(\n",
        "    input_text, target_text\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GVc41zvvdR9"
      },
      "source": [
        "## 2. The Transformer model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IN8x175vimK"
      },
      "source": [
        "The dataset is created by grouping the lines in batches and by shuffling them.\n",
        "\n",
        "Each input's line is in correspondence with its target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P714zEjaccVK"
      },
      "source": [
        "def make_dataset(input_verses, target_verses, batch_size):\n",
        "    buffer_size = len(input_verses)\n",
        "\n",
        "    steps_per_epoch = len(input_verses) // batch_size\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (input_train, target_train)\n",
        "    ).shuffle(buffer_size)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD3PC0ZL33ci"
      },
      "source": [
        "batch_size = 32\n",
        "dataset = make_dataset(input_train, target_train, batch_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZDnKc6QdicW"
      },
      "source": [
        "def make_model(config, vocab_size, checkpoint_save_path = None):\n",
        "    transformer = Transformer(\n",
        "        num_layers=config[\"num_layers\"],\n",
        "        d_model=config[\"d_model\"],\n",
        "        num_heads=config[\"num_heads\"],\n",
        "        dff=config[\"dff\"],\n",
        "        input_vocab_size=vocab_size,\n",
        "        target_vocab_size=vocab_size,\n",
        "        pe_input=1000,\n",
        "        pe_target=1000,\n",
        "        rate=0.1,\n",
        "    )\n",
        "    transformer_trainer = TransformerTrainer(transformer, checkpoint_save_path)\n",
        "\n",
        "    return transformer, transformer_trainer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKZkpevHghxD"
      },
      "source": [
        "config = {\n",
        "    \"num_layers\" : 6,\n",
        "    \"d_model\" : 256,\n",
        "    \"num_heads\" : 8,\n",
        "    \"dff\" : 1024\n",
        "}\n",
        "\n",
        "checkpoint_save_path = \"./checkpoints/char-level-syll\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZmAO5JHhP9G"
      },
      "source": [
        "transformer, transformer_trainer = make_model(config, vocab_size) # checkpoint_save_path"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLTOETK4_m6"
      },
      "source": [
        "## 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaKKUqB726YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c447512-5078-4c7a-9021-c1f233fd8def"
      },
      "source": [
        "transformer_trainer.train(dataset, 10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 6.0993 Accuracy 0.0006\n",
            "Epoch 1 Batch 50 Loss 4.5459 Accuracy 0.1048\n",
            "Epoch 1 Batch 100 Loss 3.8027 Accuracy 0.1580\n",
            "Epoch 1 Batch 150 Loss 3.5138 Accuracy 0.1788\n",
            "Epoch 1 Batch 200 Loss 3.2762 Accuracy 0.2061\n",
            "Epoch 1 Batch 250 Loss 3.0547 Accuracy 0.2380\n",
            "Epoch 1 Batch 300 Loss 2.8792 Accuracy 0.2645\n",
            "Epoch 1 Loss 2.7856 Accuracy 0.2789\n",
            "Time taken for 1 epoch: 85.60 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.8671 Accuracy 0.4147\n",
            "Epoch 2 Batch 50 Loss 1.8407 Accuracy 0.4226\n",
            "Epoch 2 Batch 100 Loss 1.8092 Accuracy 0.4292\n",
            "Epoch 2 Batch 150 Loss 1.7736 Accuracy 0.4386\n",
            "Epoch 2 Batch 200 Loss 1.7432 Accuracy 0.4465\n",
            "Epoch 2 Batch 250 Loss 1.7144 Accuracy 0.4540\n",
            "Epoch 2 Batch 300 Loss 1.6864 Accuracy 0.4606\n",
            "Epoch 2 Loss 1.6695 Accuracy 0.4649\n",
            "Time taken for 1 epoch: 68.43 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.4952 Accuracy 0.5052\n",
            "Epoch 3 Batch 50 Loss 1.4940 Accuracy 0.5119\n",
            "Epoch 3 Batch 100 Loss 1.4707 Accuracy 0.5172\n",
            "Epoch 3 Batch 150 Loss 1.4539 Accuracy 0.5212\n",
            "Epoch 3 Batch 200 Loss 1.4391 Accuracy 0.5251\n",
            "Epoch 3 Batch 250 Loss 1.4252 Accuracy 0.5294\n",
            "Epoch 3 Batch 300 Loss 1.4131 Accuracy 0.5332\n",
            "Epoch 3 Loss 1.4048 Accuracy 0.5353\n",
            "Time taken for 1 epoch: 68.45 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.2999 Accuracy 0.5607\n",
            "Epoch 4 Batch 50 Loss 1.2956 Accuracy 0.5648\n",
            "Epoch 4 Batch 100 Loss 1.2926 Accuracy 0.5673\n",
            "Epoch 4 Batch 150 Loss 1.2833 Accuracy 0.5698\n",
            "Epoch 4 Batch 200 Loss 1.2770 Accuracy 0.5722\n",
            "Epoch 4 Batch 250 Loss 1.2681 Accuracy 0.5747\n",
            "Epoch 4 Batch 300 Loss 1.2590 Accuracy 0.5778\n",
            "Epoch 4 Loss 1.2544 Accuracy 0.5791\n",
            "Time taken for 1 epoch: 68.34 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.1480 Accuracy 0.6153\n",
            "Epoch 5 Batch 50 Loss 1.1775 Accuracy 0.6038\n",
            "Epoch 5 Batch 100 Loss 1.1685 Accuracy 0.6064\n",
            "Epoch 5 Batch 150 Loss 1.1636 Accuracy 0.6083\n",
            "Epoch 5 Batch 200 Loss 1.1574 Accuracy 0.6102\n",
            "Epoch 5 Batch 250 Loss 1.1555 Accuracy 0.6103\n",
            "Epoch 5 Batch 300 Loss 1.1493 Accuracy 0.6126\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 1.1453 Accuracy 0.6140\n",
            "Time taken for 1 epoch: 69.08 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.0588 Accuracy 0.6332\n",
            "Epoch 6 Batch 50 Loss 1.0758 Accuracy 0.6355\n",
            "Epoch 6 Batch 100 Loss 1.0435 Accuracy 0.6458\n",
            "Epoch 6 Batch 150 Loss 1.0115 Accuracy 0.6556\n",
            "Epoch 6 Batch 200 Loss 0.9833 Accuracy 0.6643\n",
            "Epoch 6 Batch 250 Loss 0.9586 Accuracy 0.6716\n",
            "Epoch 6 Batch 300 Loss 0.9316 Accuracy 0.6804\n",
            "Epoch 6 Loss 0.9068 Accuracy 0.6888\n",
            "Time taken for 1 epoch: 68.32 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.6392 Accuracy 0.7905\n",
            "Epoch 7 Batch 50 Loss 0.5550 Accuracy 0.8097\n",
            "Epoch 7 Batch 100 Loss 0.4988 Accuracy 0.8285\n",
            "Epoch 7 Batch 150 Loss 0.4601 Accuracy 0.8414\n",
            "Epoch 7 Batch 200 Loss 0.4254 Accuracy 0.8534\n",
            "Epoch 7 Batch 250 Loss 0.4035 Accuracy 0.8612\n",
            "Epoch 7 Batch 300 Loss 0.3791 Accuracy 0.8693\n",
            "Epoch 7 Loss 0.3680 Accuracy 0.8732\n",
            "Time taken for 1 epoch: 68.39 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.4065 Accuracy 0.8666\n",
            "Epoch 8 Batch 50 Loss 0.2358 Accuracy 0.9203\n",
            "Epoch 8 Batch 100 Loss 0.2177 Accuracy 0.9259\n",
            "Epoch 8 Batch 150 Loss 0.2118 Accuracy 0.9281\n",
            "Epoch 8 Batch 200 Loss 0.2037 Accuracy 0.9308\n",
            "Epoch 8 Batch 250 Loss 0.2054 Accuracy 0.9306\n",
            "Epoch 8 Batch 300 Loss 0.1950 Accuracy 0.9342\n",
            "Epoch 8 Loss 0.1909 Accuracy 0.9356\n",
            "Time taken for 1 epoch: 68.35 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1467 Accuracy 0.9545\n",
            "Epoch 9 Batch 50 Loss 0.1564 Accuracy 0.9480\n",
            "Epoch 9 Batch 100 Loss 0.1447 Accuracy 0.9524\n",
            "Epoch 9 Batch 150 Loss 0.1386 Accuracy 0.9548\n",
            "Epoch 9 Batch 200 Loss 0.1343 Accuracy 0.9564\n",
            "Epoch 9 Batch 250 Loss 0.1314 Accuracy 0.9574\n",
            "Epoch 9 Batch 300 Loss 0.1343 Accuracy 0.9568\n",
            "Epoch 9 Loss 0.1300 Accuracy 0.9582\n",
            "Time taken for 1 epoch: 68.19 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0887 Accuracy 0.9712\n",
            "Epoch 10 Batch 50 Loss 0.0999 Accuracy 0.9687\n",
            "Epoch 10 Batch 100 Loss 0.0902 Accuracy 0.9717\n",
            "Epoch 10 Batch 150 Loss 0.0934 Accuracy 0.9708\n",
            "Epoch 10 Batch 200 Loss 0.0913 Accuracy 0.9717\n",
            "Epoch 10 Batch 250 Loss 0.0934 Accuracy 0.9714\n",
            "Epoch 10 Batch 300 Loss 0.0926 Accuracy 0.9718\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 0.0905 Accuracy 0.9724\n",
            "Time taken for 1 epoch: 68.88 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz4YwsF04YEI"
      },
      "source": [
        "## 4. Syllabification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O44l1saVuebS"
      },
      "source": [
        "We define the *translate* function to preprocess the sentence in input to the encoder and to get the predicted ids of the translation.\n",
        "\n",
        "The ids of the translation are obtained by applying *argmax* to the predicted logits of the decoder.\n",
        "\n",
        "We begin feeding the decoder with the id of the GO symbol and, at each new step, we pass to the decoder the sequence it has just thrown out.\n",
        "\n",
        "The translation stops when the EOV symbol is reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbWmAt8b26YJ"
      },
      "source": [
        "def translate(sentence, max_length=200):\n",
        "\n",
        "    encoder_input = preprocess_text(sentence, end_of_tercet=\"\")\n",
        "    encoder_input = tokenizer.texts_to_sequences([encoder_input])\n",
        "    print(encoder_input)\n",
        "    encoder_input = tf.convert_to_tensor(encoder_input)\n",
        "\n",
        "    output = tf.convert_to_tensor([tokenizer.word_index[\"<GO>\"]])\n",
        "    output = tf.expand_dims(output, 0)\n",
        "    result = \"\"\n",
        "\n",
        "    for i in range(max_length):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output\n",
        "        )\n",
        "\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask,\n",
        "        )\n",
        "\n",
        "        # select the last character from the seq_len dimension\n",
        "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
        "        output = tf.concat(\n",
        "            [tf.cast(output, dtype=tf.int32), tf.cast(predicted_id, dtype=tf.int32)],\n",
        "            axis=-1,\n",
        "        )\n",
        "        result += tokenizer.index_word[predicted_id.numpy()[0][0]] + \" \"\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == tokenizer.word_index[\"<EOV>\"]:\n",
        "            break\n",
        "\n",
        "    # output.shape (1, tokens)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "PkCDxGdeyF9f"
      },
      "source": [
        "def print_translation(sentence, result, ground_truth):\n",
        "    print(f'{\"Input:\":15s}: {sentence}')\n",
        "    print(f'{\"Prediction\":15s}: {result}')\n",
        "    print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5cULw_54F8w",
        "outputId": "bbd941d2-f5d9-49d1-ab13-5caafdb1943d"
      },
      "source": [
        "sentence = \"E come l’aere, quand’ è ben pïorno,\"\n",
        "ground_truth = \"|E |co|me |l’ ae|re, |quan|d’ è |ben |pï|or|no,\"\n",
        "\n",
        "translated_text = translate(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14, 39, 2, 12, 6, 17, 3, 2, 9, 21, 4, 3, 8, 3, 19, 2, 26, 16, 4, 7, 13, 21, 2, 36, 2, 27, 3, 7, 2, 18, 43, 6, 8, 7, 6, 19, 15]]\n",
            "Input:         : E come l’aere, quand’ è ben pïorno,\n",
            "Prediction     : | E <SEP> | c o | m e <SEP> | l ’ <SEP> a | e | r e , <SEP> | q u a n | d ’ <SEP> è <SEP> | b e n <SEP> | p ï | o r | n o , <EOV> \n",
            "Ground truth   : |E |co|me |l’ ae|re, |quan|d’ è |ben |pï|or|no,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNkUD09hbEAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e88ec45-94e8-4ae4-89b5-577062e47569"
      },
      "source": [
        "!tar zcvf checkpoints.tar.gz checkpoints"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints/\n",
            "checkpoints/train/\n",
            "checkpoints/train/checkpoint\n",
            "checkpoints/train/ckpt-2.data-00000-of-00001\n",
            "checkpoints/train/ckpt-2.index\n",
            "checkpoints/train/ckpt-1.data-00000-of-00001\n",
            "checkpoints/train/ckpt-1.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Rv7YiHz_7Z8W",
        "outputId": "9289fa61-da49-40ca-8231-0383fa35b612"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    files.download('checkpoints.tar.gz')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_70bf74fd-7b16-49b8-864e-17172a9732e7\", \"checkpoints.tar.gz\", 245257744)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}