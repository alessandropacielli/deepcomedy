{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Char-level GRU syllabification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "54j16swJY1dW"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RltDojL4d0tf"
      },
      "source": [
        "## 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "lsuXc5StY1dY"
      },
      "source": [
        "input_file = \"data/divina_textonly.txt\"\n",
        "target_file = \"data/divina_syll_textonly.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "ACAEUyITY1dY",
        "outputId": "89358535-5775-44d3-ba95-11b44a8c5883"
      },
      "source": [
        "input_text_raw = open(input_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
        "target_text_raw = open(target_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
        "print(\"Length of input text: {} characters\".format(len(input_text_raw)))\n",
        "print(\"Length of target text: {} characters\".format(len(target_text_raw)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of input text: 578077 characters\n",
            "Length of target text: 892871 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "l1G45yR9Y1da"
      },
      "source": [
        "input_vocab = sorted(set(input_text_raw))\n",
        "target_vocab = sorted(set(target_text_raw))\n",
        "input_vocab_size = len(input_vocab)\n",
        "target_vocab_size = len(target_vocab)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gradient": {},
        "id": "p-w27LhpY1db",
        "outputId": "3f68dfc7-5fdf-4498-d0fc-42d9da84cc8b"
      },
      "source": [
        "print(\"Input vocab size: {}\".format(input_vocab_size))\n",
        "print(\"Target vocab size: {}\".format(target_vocab_size))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input vocab size: 80\n",
            "Target vocab size: 81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I2Y3wtQ7teq"
      },
      "source": [
        "The *preprocess* function adds the start and end symbols to each line and eliminates the empty ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "SUsvn6SqY1dd"
      },
      "source": [
        "def preprocess(text):\n",
        "    \"\"\"\n",
        "    For each line in the file, add start symbol \"^\" in the beginning and end symbol \"$\" in the end\n",
        "    \"\"\"\n",
        "    return [\"^\" + line.strip() + \"$\" for line in text.split(\"\\n\") if line.strip() != \"\"]\n",
        "\n",
        "input_text_prepr = preprocess(input_text_raw)\n",
        "target_text_prepr = preprocess(target_text_raw)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqkNvgp_d0tl"
      },
      "source": [
        "The tokenizer encodes each line into a tensor of char-indexes and for simplicity fits only on the target's vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "ABb_2K6DY1de"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\", char_level=True, lower=False)\n",
        "tokenizer.fit_on_texts(target_text_prepr)\n",
        "\n",
        "input_text_lines_enc = tokenizer.texts_to_sequences(input_text_prepr)\n",
        "target_text_lines_enc = tokenizer.texts_to_sequences(target_text_prepr)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdBeRajgd0tm"
      },
      "source": [
        "Padding is required in order to have a non-ragged tensor to feed to the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "MBOh9LQeY1dg"
      },
      "source": [
        "def pad(x):\n",
        "    return tf.keras.preprocessing.sequence.pad_sequences(x, padding=\"post\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "9zV0xz48Y1dh"
      },
      "source": [
        "input_text = pad(input_text_lines_enc)\n",
        "target_text = pad(target_text_lines_enc)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCRLEr63d0tp"
      },
      "source": [
        "## 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "7xGxZmlPY1dk"
      },
      "source": [
        "input_train, input_test, target_train, target_test = train_test_split(input_text, target_text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfoNEMJ3-nWv"
      },
      "source": [
        "The dataset is created by grouping the lines in batches and by shuffling them.\n",
        "\n",
        "Each input's line is in correspondence with its target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "tZWLq7g3Y1dl"
      },
      "source": [
        "BUFFER_SIZE = len(input_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_size = len(tokenizer.word_index) + 1 # the +1 is added to take into account the id 0 of the padding\n",
        "\n",
        "max_length_targ, max_length_inp = target_text.shape[1], input_text.shape[1]\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MpnDIrbAoHw"
      },
      "source": [
        "The encoder and decoder are constituted of an embedding layer, followed by a GRU.\n",
        "\n",
        "The decoder takes the final hidden state of the encoder as its initial hidden state and outputs logits of size equal to the one of the target's vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QqdYfsxQ2VX"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units, return_state=True)\n",
        "\n",
        "    def call(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        if hidden is None:\n",
        "            hidden = self.gru.get_initial_state(x)\n",
        "\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "\n",
        "        return output, state\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(         \n",
        "            self.dec_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer=\"glorot_uniform\",\n",
        "            )\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, enc_hidden):\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x, initial_state=enc_hidden)\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZM32bQPRS00"
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSH22jIoETMs"
      },
      "source": [
        "The loss is calculated using Sparse Categorical Crossentropy and the loss of the padding is masked.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "v9HRGDuGY1dn"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eZpCkLXZabl"
      },
      "source": [
        "checkpoint_dir = \"./training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTNxHTjzvQ6h"
      },
      "source": [
        "We use teacher forcing feeding the target as the next input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em0w__8gYiO4"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        _, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([tokenizer.word_index[\"^\"]] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = loss / int(targ.shape[1])\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwhkVtOWZGOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0abd42c6-166e-4c87-e3a7-3aeec330d10d"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    enc_hidden = None\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}\")\n",
        "    # saving (checkpoint) the model every 2 epochs\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}\")\n",
        "    print(f\"Time taken for 1 epoch {time.time()-start:.2f} sec\\n\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.2395\n",
            "Epoch 1 Batch 100 Loss 1.3291\n",
            "Epoch 1 Loss 1.5451\n",
            "Time taken for 1 epoch 69.52 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.2653\n",
            "Epoch 2 Batch 100 Loss 1.1384\n",
            "Epoch 2 Loss 1.1502\n",
            "Time taken for 1 epoch 25.84 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0949\n",
            "Epoch 3 Batch 100 Loss 1.0737\n",
            "Epoch 3 Loss 1.0515\n",
            "Time taken for 1 epoch 25.52 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.0180\n",
            "Epoch 4 Batch 100 Loss 0.9723\n",
            "Epoch 4 Loss 0.9806\n",
            "Time taken for 1 epoch 25.29 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.9435\n",
            "Epoch 5 Batch 100 Loss 0.9448\n",
            "Epoch 5 Loss 0.9251\n",
            "Time taken for 1 epoch 25.42 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.8646\n",
            "Epoch 6 Batch 100 Loss 0.9172\n",
            "Epoch 6 Loss 0.8785\n",
            "Time taken for 1 epoch 25.65 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.8393\n",
            "Epoch 7 Batch 100 Loss 0.8494\n",
            "Epoch 7 Loss 0.8420\n",
            "Time taken for 1 epoch 25.55 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.7956\n",
            "Epoch 8 Batch 100 Loss 0.8193\n",
            "Epoch 8 Loss 0.8095\n",
            "Time taken for 1 epoch 25.74 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.7669\n",
            "Epoch 9 Batch 100 Loss 0.7755\n",
            "Epoch 9 Loss 0.7767\n",
            "Time taken for 1 epoch 25.32 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.7273\n",
            "Epoch 10 Batch 100 Loss 0.7501\n",
            "Epoch 10 Loss 0.7507\n",
            "Time taken for 1 epoch 26.26 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.7123\n",
            "Epoch 11 Batch 100 Loss 0.7358\n",
            "Epoch 11 Loss 0.7210\n",
            "Time taken for 1 epoch 25.42 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.6664\n",
            "Epoch 12 Batch 100 Loss 0.7065\n",
            "Epoch 12 Loss 0.6937\n",
            "Time taken for 1 epoch 25.70 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.6562\n",
            "Epoch 13 Batch 100 Loss 0.6881\n",
            "Epoch 13 Loss 0.6613\n",
            "Time taken for 1 epoch 25.42 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.5818\n",
            "Epoch 14 Batch 100 Loss 0.6337\n",
            "Epoch 14 Loss 0.6293\n",
            "Time taken for 1 epoch 25.23 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.5684\n",
            "Epoch 15 Batch 100 Loss 0.6142\n",
            "Epoch 15 Loss 0.5943\n",
            "Time taken for 1 epoch 25.25 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.5232\n",
            "Epoch 16 Batch 100 Loss 0.5408\n",
            "Epoch 16 Loss 0.5614\n",
            "Time taken for 1 epoch 25.38 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.5187\n",
            "Epoch 17 Batch 100 Loss 0.5216\n",
            "Epoch 17 Loss 0.5226\n",
            "Time taken for 1 epoch 25.39 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.4617\n",
            "Epoch 18 Batch 100 Loss 0.4937\n",
            "Epoch 18 Loss 0.4858\n",
            "Time taken for 1 epoch 25.52 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.4357\n",
            "Epoch 19 Batch 100 Loss 0.4389\n",
            "Epoch 19 Loss 0.4512\n",
            "Time taken for 1 epoch 25.48 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.3917\n",
            "Epoch 20 Batch 100 Loss 0.4229\n",
            "Epoch 20 Loss 0.4176\n",
            "Time taken for 1 epoch 25.27 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxEjvoVLG3ZE"
      },
      "source": [
        "## 3. Translation and Attention Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FV5YkbPHDb5"
      },
      "source": [
        "We define the *evaluate* function to preprocess the sentence in input and to get the predicted ids of the translation.\n",
        "\n",
        "The ids of the translation are obtained by applying *argmax* to the predicted logits of the decoder.\n",
        "\n",
        "We begin with the id of the start symbol and, at each new step, we pass to the decoder the id it has just output.\n",
        "\n",
        "The translation stops when the end symbol is reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTjMRKjoZvPb"
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((target_text.shape[1], input_text.shape[1]))\n",
        "\n",
        "    inputs = [tokenizer.word_index[i] for i in list(map(str, sentence))]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding=\"post\")\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = \"\"\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index[\"^\"]], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights= decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1,))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += tokenizer.index_word[predicted_id] + \" \"\n",
        "\n",
        "        if tokenizer.index_word[predicted_id] == \"$\":\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdkpT6B3rG62"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap=\"viridis\")\n",
        "\n",
        "    fontdict = {\"fontsize\": 14}\n",
        "\n",
        "    ax.set_xticklabels([\"\"] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([\"\"] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhMAvmdurIsA"
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print(\"Input:\", sentence)\n",
        "    print(\"Predicted translation:\", result)\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')),:len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvcZiKlt-kwE"
      },
      "source": [
        "translate(\"^ Nel mezzo del cammin di nostra vita $\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}