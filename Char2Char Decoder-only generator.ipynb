{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0s4fGtV0qJj",
        "outputId": "9f8773d7-3e7f-43c2-e33a-40f4ed2ce1ef"
      },
      "source": [
        "!tar zxvf data.tar.gz\n",
        "!tar zxvf deepcomedy.tar.gz"
      ],
      "id": "D0s4fGtV0qJj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/\n",
            "data/orlando.txt\n",
            "data/divina_textonly.txt\n",
            "data/divina.txt\n",
            "data/divina_syll_textonly.txt\n",
            "data/orlando-textonly.txt\n",
            "data/divina_syll.txt\n",
            "data/.ipynb_checkpoints/\n",
            "data/.ipynb_checkpoints/orlando-checkpoint.txt\n",
            "data/.ipynb_checkpoints/orlando-textonly-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina_textonly-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina_syll-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina-checkpoint.txt\n",
            "data/.ipynb_checkpoints/divina_syll_textonly-checkpoint.txt\n",
            "deepcomedy/\n",
            "deepcomedy/util/\n",
            "deepcomedy/util/predicate.py\n",
            "deepcomedy/util/__pycache__/\n",
            "deepcomedy/util/__pycache__/predicate.cpython-37.pyc\n",
            "deepcomedy/util/__pycache__/__init__.cpython-37.pyc\n",
            "deepcomedy/util/__init__.py\n",
            "deepcomedy/util/.ipynb_checkpoints/\n",
            "deepcomedy/util/.ipynb_checkpoints/predicate-checkpoint.py\n",
            "deepcomedy/models/\n",
            "deepcomedy/models/layers.py\n",
            "deepcomedy/models/transformer.py\n",
            "deepcomedy/models/__pycache__/\n",
            "deepcomedy/models/__pycache__/layers.cpython-37.pyc\n",
            "deepcomedy/models/__pycache__/__init__.cpython-37.pyc\n",
            "deepcomedy/models/__pycache__/transformer.cpython-37.pyc\n",
            "deepcomedy/models/__init__.py\n",
            "deepcomedy/models/.ipynb_checkpoints/\n",
            "deepcomedy/models/.ipynb_checkpoints/transformer-checkpoint.py\n",
            "deepcomedy/preprocessing.py\n",
            "deepcomedy/__pycache__/\n",
            "deepcomedy/__pycache__/__init__.cpython-37.pyc\n",
            "deepcomedy/__pycache__/preprocessing.cpython-37.pyc\n",
            "deepcomedy/metrics.py\n",
            "deepcomedy/__init__.py\n",
            "deepcomedy/.ipynb_checkpoints/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab77d807-5ddb-4f07-bd31-fc7b1ddd41aa"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "id": "ab77d807-5ddb-4f07-bd31-fc7b1ddd41aa",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac3e544f-fd84-4cd5-9df6-8679f6f72163"
      },
      "source": [
        "from deepcomedy.models.transformer import *\n",
        "from deepcomedy.preprocessing import load_verses\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "id": "ac3e544f-fd84-4cd5-9df6-8679f6f72163",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b20eefb5-a51b-43c9-bcd2-da484163dffe"
      },
      "source": [
        "corpus_path = \"data/divina_syll_textonly.txt\"\n",
        "raw_corpus = open(corpus_path, \"rb\").read().decode(encoding=\"utf-8\")"
      ],
      "id": "b20eefb5-a51b-43c9-bcd2-da484163dffe",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a1e96e4-6893-4793-9863-1631b11f77ab"
      },
      "source": [
        "raw_corpus = raw_corpus.strip()"
      ],
      "id": "6a1e96e4-6893-4793-9863-1631b11f77ab",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6aaacbc-7cee-437d-aa46-b567370d3a2e"
      },
      "source": [
        "corpus = '\\n'.join([line.strip()[1:] for line in raw_corpus.split('\\n')])\n",
        "corpus = re.sub(r'(.)', r'\\1 ', corpus).strip()\n",
        "corpus = re.sub(r'  ', ' <SEP> ', corpus)\n",
        "corpus = re.sub(r'\\n{2,}', ' <EOT> ', corpus)\n",
        "corpus = re.sub(r'\\n', ' <EOV> ', corpus)\n",
        "corpus = re.sub(r' {2,}', ' ', corpus)\n",
        "corpus = corpus + ' <EOT>'"
      ],
      "id": "a6aaacbc-7cee-437d-aa46-b567370d3a2e",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5456e688-0aa4-4089-ba34-862ad1449ccd"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=False, filters='', lower=False)\n",
        "tokenizer.fit_on_texts([corpus])\n",
        "enc_corpus = tokenizer.texts_to_sequences([corpus])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "id": "5456e688-0aa4-4089-ba34-862ad1449ccd",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au6BTJXm19pR",
        "outputId": "6c800876-ff6b-4147-cf95-e15673b7b14c"
      },
      "source": [
        "\n",
        "len(enc_corpus)"
      ],
      "id": "au6BTJXm19pR",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "671248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "167c2758-3af8-49a8-a7fe-03861e47c784"
      },
      "source": [
        "window_size = 100\n",
        "corpus_windows = []\n",
        "\n",
        "for i in range(0, len(enc_corpus) - window_size, window_size):\n",
        "    corpus_windows.append(enc_corpus[i:i+window_size])\n",
        "\n",
        "corpus_windows = tf.convert_to_tensor(corpus_windows)"
      ],
      "id": "167c2758-3af8-49a8-a7fe-03861e47c784",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc8f49a8-9e37-481a-bec1-0cb182c9e8ae"
      },
      "source": [
        "BUFFER_SIZE = len(corpus_windows)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(corpus_windows) // BATCH_SIZE\n",
        "\n",
        "max_length_targ = corpus_windows.shape[1]\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(corpus_windows).shuffle(\n",
        "    BUFFER_SIZE\n",
        ")\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "id": "cc8f49a8-9e37-481a-bec1-0cb182c9e8ae",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3be8ada4-e1fb-4b40-a18c-289e0ba70075"
      },
      "source": [
        "epochs = 10\n",
        "num_layers = 12\n",
        "d_model = 256\n",
        "num_heads = 8\n",
        "dff = 1024"
      ],
      "id": "3be8ada4-e1fb-4b40-a18c-289e0ba70075",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f44a1c97-1f80-48b5-a607-724de51c755f"
      },
      "source": [
        "decoder = DecoderOnlyModel(num_layers, d_model, num_heads, dff, vocab_size, 1000)\n",
        "decoderTrainer = DecoderOnlyTrainer(decoder, checkpoint_save_path='checkpoints/decoder-only-12')"
      ],
      "id": "f44a1c97-1f80-48b5-a607-724de51c755f",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55ed90a3-21ff-4485-93cd-32d5ea0419b5",
        "outputId": "f52e778f-25ad-4879-f28a-647831d376b1"
      },
      "source": [
        "decoderTrainer.train(dataset, epochs * 2)"
      ],
      "id": "55ed90a3-21ff-4485-93cd-32d5ea0419b5",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.9504 Accuracy 0.6711\n",
            "Epoch 1 Batch 50 Loss 0.9473 Accuracy 0.6760\n",
            "Epoch 1 Batch 100 Loss 0.9609 Accuracy 0.6713\n",
            "Epoch 1 Loss 0.9613 Accuracy 0.6712\n",
            "Time taken for 1 epoch: 21.88 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9208 Accuracy 0.6837\n",
            "Epoch 2 Batch 50 Loss 0.9352 Accuracy 0.6799\n",
            "Epoch 2 Batch 100 Loss 0.9489 Accuracy 0.6755\n",
            "Epoch 2 Loss 0.9493 Accuracy 0.6754\n",
            "Time taken for 1 epoch: 22.00 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.9309 Accuracy 0.6832\n",
            "Epoch 3 Batch 50 Loss 0.9241 Accuracy 0.6824\n",
            "Epoch 3 Batch 100 Loss 0.9366 Accuracy 0.6786\n",
            "Epoch 3 Loss 0.9375 Accuracy 0.6784\n",
            "Time taken for 1 epoch: 21.23 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.9070 Accuracy 0.6888\n",
            "Epoch 4 Batch 50 Loss 0.9135 Accuracy 0.6866\n",
            "Epoch 4 Batch 100 Loss 0.9258 Accuracy 0.6823\n",
            "Epoch 4 Loss 0.9265 Accuracy 0.6820\n",
            "Time taken for 1 epoch: 21.27 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.8753 Accuracy 0.6955\n",
            "Epoch 5 Batch 50 Loss 0.9018 Accuracy 0.6901\n",
            "Epoch 5 Batch 100 Loss 0.9146 Accuracy 0.6860\n",
            "Saving checkpoint for epoch 5 at checkpoints/decoder-only-12/ckpt-11\n",
            "Epoch 5 Loss 0.9155 Accuracy 0.6857\n",
            "Time taken for 1 epoch: 22.01 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.8584 Accuracy 0.7030\n",
            "Epoch 6 Batch 50 Loss 0.8850 Accuracy 0.6955\n",
            "Epoch 6 Batch 100 Loss 0.9014 Accuracy 0.6901\n",
            "Epoch 6 Loss 0.9023 Accuracy 0.6898\n",
            "Time taken for 1 epoch: 21.58 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.8656 Accuracy 0.7058\n",
            "Epoch 7 Batch 50 Loss 0.8756 Accuracy 0.6991\n",
            "Epoch 7 Batch 100 Loss 0.8909 Accuracy 0.6935\n",
            "Epoch 7 Loss 0.8914 Accuracy 0.6934\n",
            "Time taken for 1 epoch: 21.38 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.8593 Accuracy 0.7038\n",
            "Epoch 8 Batch 50 Loss 0.8630 Accuracy 0.7026\n",
            "Epoch 8 Batch 100 Loss 0.8777 Accuracy 0.6979\n",
            "Epoch 8 Loss 0.8786 Accuracy 0.6977\n",
            "Time taken for 1 epoch: 21.38 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.8322 Accuracy 0.7151\n",
            "Epoch 9 Batch 50 Loss 0.8536 Accuracy 0.7061\n",
            "Epoch 9 Batch 100 Loss 0.8690 Accuracy 0.7007\n",
            "Epoch 9 Loss 0.8695 Accuracy 0.7004\n",
            "Time taken for 1 epoch: 21.46 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.8213 Accuracy 0.7195\n",
            "Epoch 10 Batch 50 Loss 0.8386 Accuracy 0.7122\n",
            "Epoch 10 Batch 100 Loss 0.8560 Accuracy 0.7058\n",
            "Saving checkpoint for epoch 10 at checkpoints/decoder-only-12/ckpt-12\n",
            "Epoch 10 Loss 0.8566 Accuracy 0.7055\n",
            "Time taken for 1 epoch: 21.91 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.8019 Accuracy 0.7243\n",
            "Epoch 11 Batch 50 Loss 0.8258 Accuracy 0.7161\n",
            "Epoch 11 Batch 100 Loss 0.8445 Accuracy 0.7095\n",
            "Epoch 11 Loss 0.8454 Accuracy 0.7092\n",
            "Time taken for 1 epoch: 21.50 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.8034 Accuracy 0.7240\n",
            "Epoch 12 Batch 50 Loss 0.8157 Accuracy 0.7186\n",
            "Epoch 12 Batch 100 Loss 0.8329 Accuracy 0.7129\n",
            "Epoch 12 Loss 0.8335 Accuracy 0.7127\n",
            "Time taken for 1 epoch: 21.43 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.7909 Accuracy 0.7266\n",
            "Epoch 13 Batch 50 Loss 0.8064 Accuracy 0.7218\n",
            "Epoch 13 Batch 100 Loss 0.8218 Accuracy 0.7161\n",
            "Epoch 13 Loss 0.8228 Accuracy 0.7158\n",
            "Time taken for 1 epoch: 21.44 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.7632 Accuracy 0.7397\n",
            "Epoch 14 Batch 50 Loss 0.7949 Accuracy 0.7253\n",
            "Epoch 14 Batch 100 Loss 0.8120 Accuracy 0.7192\n",
            "Epoch 14 Loss 0.8130 Accuracy 0.7188\n",
            "Time taken for 1 epoch: 21.42 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.7591 Accuracy 0.7360\n",
            "Epoch 15 Batch 50 Loss 0.7857 Accuracy 0.7290\n",
            "Epoch 15 Batch 100 Loss 0.8031 Accuracy 0.7228\n",
            "Saving checkpoint for epoch 15 at checkpoints/decoder-only-12/ckpt-13\n",
            "Epoch 15 Loss 0.8042 Accuracy 0.7223\n",
            "Time taken for 1 epoch: 21.81 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.7674 Accuracy 0.7317\n",
            "Epoch 16 Batch 50 Loss 0.7756 Accuracy 0.7325\n",
            "Epoch 16 Batch 100 Loss 0.7916 Accuracy 0.7265\n",
            "Epoch 16 Loss 0.7922 Accuracy 0.7263\n",
            "Time taken for 1 epoch: 21.42 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.7483 Accuracy 0.7432\n",
            "Epoch 17 Batch 50 Loss 0.7606 Accuracy 0.7371\n",
            "Epoch 17 Batch 100 Loss 0.7797 Accuracy 0.7303\n",
            "Epoch 17 Loss 0.7806 Accuracy 0.7300\n",
            "Time taken for 1 epoch: 21.39 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.7661 Accuracy 0.7380\n",
            "Epoch 18 Batch 50 Loss 0.7559 Accuracy 0.7384\n",
            "Epoch 18 Batch 100 Loss 0.7702 Accuracy 0.7337\n",
            "Epoch 18 Loss 0.7711 Accuracy 0.7333\n",
            "Time taken for 1 epoch: 21.39 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.7300 Accuracy 0.7426\n",
            "Epoch 19 Batch 50 Loss 0.7425 Accuracy 0.7433\n",
            "Epoch 19 Batch 100 Loss 0.7616 Accuracy 0.7365\n",
            "Epoch 19 Loss 0.7622 Accuracy 0.7363\n",
            "Time taken for 1 epoch: 21.40 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.7258 Accuracy 0.7429\n",
            "Epoch 20 Batch 50 Loss 0.7336 Accuracy 0.7467\n",
            "Epoch 20 Batch 100 Loss 0.7483 Accuracy 0.7413\n",
            "Saving checkpoint for epoch 20 at checkpoints/decoder-only-12/ckpt-14\n",
            "Epoch 20 Loss 0.7491 Accuracy 0.7410\n",
            "Time taken for 1 epoch: 21.97 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA7BSjAq3a7Q"
      },
      "source": [
        "def generate_greedy(input):\n",
        "    input = tf.expand_dims(input, 0)\n",
        "    result = \"\"\n",
        "\n",
        "    for i in range(400):\n",
        "        _, combined_mask, _ = create_masks(\n",
        "            input, input\n",
        "        )\n",
        "\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions = decoder(\n",
        "            input,\n",
        "            False,\n",
        "            combined_mask\n",
        "        )\n",
        "        # select the last character from the seq_len dimension\n",
        "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.random.categorical(tf.reshape(predictions, (-1, vocab_size)), 1)\n",
        "\n",
        "        # concatenate the predicted_id to the output which is given to the decoder as its input.\n",
        "        input = tf.concat(\n",
        "            [tf.cast(input, dtype=tf.int32), tf.cast(predicted_id, dtype=tf.int32)],\n",
        "            axis=-1,\n",
        "        )\n",
        "        \n",
        "        result += tokenizer.index_word[predicted_id.numpy()[0][0]] + \" \"\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == tokenizer.word_index[\"<EOT>\"]:\n",
        "            return result\n",
        "    return result"
      ],
      "id": "cA7BSjAq3a7Q",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSHfrQpW39K1"
      },
      "source": [
        "input = tokenizer.texts_to_sequences(['<EOV>'])"
      ],
      "id": "dSHfrQpW39K1",
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "i3jISJvL5BX6",
        "outputId": "c0668544-1d44-45cc-83c6-9d2c9c6f468d"
      },
      "source": [
        "generate_greedy(input[0])"
      ],
      "id": "i3jISJvL5BX6",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'c o m ’ <SEP> | i o <SEP> | v i | d i , <SEP> i l <SEP> | t u o <SEP> | v a | l o r <SEP> | m i <SEP> | r i | s p o n | d o , <EOV> c h e <SEP> | s e m | p r e <SEP> | v a | l o | r e <SEP> a l <SEP> | c a | p o <SEP> | s e | d e r | n o . <EOT> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    }
  ]
}